{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "deepXplore_for_kaggle_model_new.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isshii/de4test/blob/master/deepXplore_for_kaggle_model_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4lP4POGn5Xj",
        "colab_type": "code",
        "outputId": "57b16cc6-f3b5-4ce3-f941-c24933c734e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCfRJ3ykfcZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###########################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDY8sDVBqxmK",
        "colab_type": "code",
        "outputId": "ca49352c-96c9-4a03-a410-f5997a4aeae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import argparse\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "# from keras.applications.mobilenet import MobileNet\n",
        "# from keras.applications.densenet import DenseNet201\n",
        "# from keras.applications.nasnet import NASNetMobile\n",
        "\n",
        "\n",
        "from keras.layers import Input\n",
        "#from scipy.misc import imsave  \n",
        "import imageio\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "\n",
        "#from utils import *\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSpOOYXi8Kf7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiGGwQVElJNH",
        "colab_type": "code",
        "outputId": "2714b8be-e644-4f0a-a0fb-bcc8aee391ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 13809135235432608505, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 14830336018363494975\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 81958342282542278\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15956099072\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 2440277145442589903\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWQ2M_8glJNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the parameter\n",
        "# argument parsing\n",
        "parser = argparse.ArgumentParser(description='Main function for difference-inducing input generation in MNIST dataset')\n",
        "parser.add_argument('transformation', help=\"realistic transformation type\", choices=['light', 'occl', 'blackout'])\n",
        "parser.add_argument('weight_diff', help=\"weight hyperparm to control differential behavior\", type=float)\n",
        "parser.add_argument('weight_nc', help=\"weight hyperparm to control neuron coverage\", type=float)\n",
        "parser.add_argument('step', help=\"step size of gradient descent\", type=float)\n",
        "parser.add_argument('seeds', help=\"number of seeds of input\", type=int)\n",
        "parser.add_argument('grad_iterations', help=\"number of iterations of gradient descent\", type=int)\n",
        "parser.add_argument('threshold', help=\"threshold for determining neuron activated\", type=float)\n",
        "parser.add_argument('-t', '--target_model', help=\"target model that we want it predicts differently\",\n",
        "                    choices=[0, 1, 2], default=0, type=int)\n",
        "parser.add_argument('-sp', '--start_point', help=\"occlusion upper left corner coordinate\", default=(0, 0), type=tuple)\n",
        "parser.add_argument('-occl_size', '--occlusion_size', help=\"occlusion size\", default=(10, 10), type=tuple)\n",
        "\n",
        "#args = parser.parse_args([])\n",
        "args = parser.parse_args([\"occl\", \"0.1\", \"0.1\", \"1\", \"100\", \"100\", \"0.1\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tTYrllplJNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "import os, re\n",
        "\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    input_img_data = image.img_to_array(img)\n",
        "    input_img_data = np.expand_dims(input_img_data, axis=0)\n",
        "    input_img_data = preprocess_input(input_img_data)  # final input shape = (1,224,224,3)\n",
        "    return input_img_data\n",
        "\n",
        "\n",
        "def deprocess_image(x):\n",
        "    x = x.reshape((224, 224, 3))\n",
        "    # Remove zero-center by mean pixel\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "\n",
        "def decode_label(pred):\n",
        "    return decode_predictions(pred)[0][0][1]\n",
        "\n",
        "\n",
        "def normalize(x):\n",
        "    # utility function to normalize a tensor by its L2 norm\n",
        "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
        "\n",
        "\n",
        "def constraint_occl(gradients, start_point, rect_shape):\n",
        "    new_grads = np.zeros_like(gradients)\n",
        "    new_grads[:, start_point[0]:start_point[0] + rect_shape[0],\n",
        "    start_point[1]:start_point[1] + rect_shape[1]] = gradients[:, start_point[0]:start_point[0] + rect_shape[0],\n",
        "                                                     start_point[1]:start_point[1] + rect_shape[1]]\n",
        "    return new_grads\n",
        "\n",
        "\n",
        "def constraint_light(gradients):\n",
        "    new_grads = np.ones_like(gradients)\n",
        "    grad_mean = 1e4 * np.mean(gradients)\n",
        "    return grad_mean * new_grads\n",
        "\n",
        "\n",
        "def constraint_black(gradients, rect_shape=(10, 10)):\n",
        "    start_point = (\n",
        "        random.randint(0, gradients.shape[1] - rect_shape[0]), random.randint(0, gradients.shape[2] - rect_shape[1]))\n",
        "    new_grads = np.zeros_like(gradients)\n",
        "    patch = gradients[:, start_point[0]:start_point[0] + rect_shape[0], start_point[1]:start_point[1] + rect_shape[1]]\n",
        "    if np.mean(patch) < 0:\n",
        "        new_grads[:, start_point[0]:start_point[0] + rect_shape[0],\n",
        "        start_point[1]:start_point[1] + rect_shape[1]] = -np.ones_like(patch)\n",
        "    return new_grads\n",
        "\n",
        "\n",
        "def init_coverage_tables(model1, model2, model3):\n",
        "    model_layer_dict1 = defaultdict(bool)\n",
        "    model_layer_dict2 = defaultdict(bool)\n",
        "    model_layer_dict3 = defaultdict(bool)\n",
        "    init_dict(model1, model_layer_dict1)\n",
        "    init_dict(model2, model_layer_dict2)\n",
        "    init_dict(model3, model_layer_dict3)\n",
        "    return model_layer_dict1, model_layer_dict2, model_layer_dict3\n",
        "\n",
        "\n",
        "def init_dict(model, model_layer_dict):\n",
        "    for layer in model.layers:\n",
        "        if 'flatten' in layer.name or 'input' in layer.name:\n",
        "            continue\n",
        "        for index in range(layer.output_shape[-1]):\n",
        "            model_layer_dict[(layer.name, index)] = False\n",
        "\n",
        "\n",
        "def neuron_to_cover(model_layer_dict):\n",
        "    not_covered = [(layer_name, index) for (layer_name, index), v in list(model_layer_dict.items()) if not v]\n",
        "    if not_covered:\n",
        "        layer_name, index = random.choice(not_covered)\n",
        "    else:\n",
        "        layer_name, index = random.choice(list(model_layer_dict.keys()))\n",
        "    return layer_name, index\n",
        "\n",
        "\n",
        "def neuron_covered(model_layer_dict):\n",
        "    covered_neurons = len([v for v in list(model_layer_dict.values()) if v])\n",
        "    total_neurons = len(model_layer_dict)\n",
        "    return covered_neurons, total_neurons, covered_neurons / float(total_neurons)\n",
        "\n",
        "\n",
        "def scale(intermediate_layer_output, rmax=1, rmin=0):\n",
        "    X_std = (intermediate_layer_output - intermediate_layer_output.min()) / (\n",
        "        intermediate_layer_output.max() - intermediate_layer_output.min())\n",
        "    X_scaled = X_std * (rmax - rmin) + rmin\n",
        "    return X_scaled\n",
        "\n",
        "\n",
        "def update_coverage(input_data, model, model_layer_dict, threshold=0):\n",
        "    layer_names = [layer.name for layer in model.layers if\n",
        "                   'flatten' not in layer.name and 'input' not in layer.name]\n",
        "\n",
        "    intermediate_layer_model = Model(inputs=model.input,\n",
        "                                     outputs=[model.get_layer(layer_name).output for layer_name in layer_names])\n",
        "    intermediate_layer_outputs = intermediate_layer_model.predict(input_data)\n",
        "\n",
        "    for i, intermediate_layer_output in enumerate(intermediate_layer_outputs):\n",
        "        scaled = scale(intermediate_layer_output[0])\n",
        "        for num_neuron in range(scaled.shape[-1]):\n",
        "            if np.mean(scaled[..., num_neuron]) > threshold and not model_layer_dict[(layer_names[i], num_neuron)]:\n",
        "                model_layer_dict[(layer_names[i], num_neuron)] = True\n",
        "\n",
        "\n",
        "def full_coverage(model_layer_dict):\n",
        "    if False in list(model_layer_dict.values()):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def fired(model, layer_name, index, input_data, threshold=0):\n",
        "    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "    intermediate_layer_output = intermediate_layer_model.predict(input_data)[0]\n",
        "    scaled = scale(intermediate_layer_output)\n",
        "    if np.mean(scaled[..., index]) > threshold:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def diverged(predictions1, predictions2, predictions3, target):\n",
        "    #     if predictions2 == predictions3 == target and predictions1 != target:\n",
        "    if not predictions1 == predictions2 == predictions3:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "#add\n",
        "def list_pictures(directory, ext='jpg|jpeg|bmp|png|ppm'):\n",
        "    return [os.path.join(root, f)\n",
        "            for root, _, files in os.walk(directory) for f in files\n",
        "            if re.match(r'([\\w]+\\.(?:' + ext + '))', f.lower())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtjZJPO8z6bG",
        "colab_type": "code",
        "outputId": "accc98c5-e7c5-4097-f982-5895f37e6752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 224, 224\n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "input_tensor = Input(shape=input_shape)\n",
        "\n",
        "vggmodel = VGG16(weights='imagenet', include_top=True)\n",
        "\n",
        "for layers in (vggmodel.layers)[:19]:\n",
        "    print(layers)\n",
        "    layers.trainable = False\n",
        "X= vggmodel.layers[-2].output\n",
        "predictions = Dense(2, activation=\"softmax\")(X)\n",
        "model1 = Model(input = vggmodel.input, output = predictions)\n",
        "model1.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f9c2adf96d8>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9c2ad956a0>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9c2ad956d8>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f9c2ad9b550>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9c2ad9ce80>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9c2ada0da0>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f9c2ada7c88>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9c2adb5b38>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9c2adbb390>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9c2ad42208>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f9c2ad48ba8>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9c2ad56a58>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9c2ad5c2e8>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9c2ad61080>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f9c2ad69a58>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9c2ad75978>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9c2ad7b1d0>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9c2ad025c0>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f9c2ad09860>\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_30 (InputLayer)        (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 119,554,050\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "CPU times: user 1.75 s, sys: 256 ms, total: 2.01 s\n",
            "Wall time: 2.01 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ1QKoBmgA_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_weights = '/content/gdrive/My Drive/deepxplore/models/good_vgg16.h5'\n",
        "\n",
        "# model1 = VGG19(weights=vgg19_weights)\n",
        "# model2 = VGG16(weights=vgg16_weights)\n",
        "# model3 = ResNet50(weights=resnet50_weights)\n",
        "\n",
        "#model1 = VGG19(weights=vgg19_weights,input_tensor=input_tensor)\n",
        "model1.load_weights(vgg16_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLGaAmNyvC1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start gen inputs\n",
        "#img_paths = image.list_pictures('./seeds', ext='JPEG')\n",
        "img_paths = list_pictures('./gdrive/My Drive/deepxplore/ImageNet/seeds')\n",
        "gen_img = preprocess_image(random.choice(img_paths))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8Iy-u1DvRrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred1 = model1.predict(gen_img)\n",
        "label1 = np.argmax(pred1[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhoBSDSji7LK",
        "colab_type": "code",
        "outputId": "4538e34b-aa76-48d1-b14d-080b612b02cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(pred1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.30713782 0.69286215]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUTnIFGxmHx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqlGKyc_mIS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to2AnsjJmIgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA0BBWHllpi-",
        "colab_type": "code",
        "outputId": "1b3c5c88-a36d-4a83-ea3e-fa414d6930ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 224, 224\n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "input_tensor = Input(shape=input_shape)\n",
        "\n",
        "vggmodel1 = VGG16(weights='imagenet',input_tensor=input_tensor,include_top=True)\n",
        "\n",
        "for layers in (vggmodel1.layers)[:19]:\n",
        "    print(layers)\n",
        "    layers.trainable = False\n",
        "X= vggmodel1.layers[-2].output\n",
        "predictions1 = Dense(2, activation=\"softmax\")(X)\n",
        "model1 = Model(input = vggmodel1.input, output = predictions1)\n",
        "model1.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
        "model1.summary()\n",
        "\n",
        "#vgg16_weights = '/content/gdrive/My Drive/deepxplore/models/good_vgg16.h5'\n",
        "#model1.load_weights(vgg16_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7fa8fcd571d0>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcd572b0>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcd57438>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fcd582b0>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcd59518>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fab543a7828>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fcd68748>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcd70f98>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcd75dd8>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcd7cc88>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fcd8a668>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcc50ba8>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcc57cc0>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcc5cb70>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fcc6b550>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcc70a90>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcc76be0>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcc7ba20>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fcc8a470>\n",
            "Model: \"model_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 119,554,050\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "CPU times: user 1.95 s, sys: 266 ms, total: 2.22 s\n",
            "Wall time: 2.2 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZGtXSb0mCQQ",
        "colab_type": "code",
        "outputId": "123be044-75fb-41c6-ff9e-799846172bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "vggmodel2 = VGG16(weights='imagenet',input_tensor=input_tensor, include_top=True)\n",
        "\n",
        "for layers in (vggmodel2.layers)[:19]:\n",
        "    print(layers)\n",
        "    layers.trainable = False\n",
        "X= vggmodel2.layers[-2].output\n",
        "predictions2 = Dense(2, activation=\"softmax\")(X)\n",
        "model2 = Model(input = vggmodel2.input, output = predictions2)\n",
        "model2.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
        "model2.summary()\n",
        "\n",
        "vgg16_weights = '/content/gdrive/My Drive/deepxplore/models/good_vgg16.h5'\n",
        "model2.load_weights(vgg16_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7fa8fcd571d0>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcbaa630>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcbaa7b8>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fcd60208>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcbafb00>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcbb9c50>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fcbbea90>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcbca9e8>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcb50278>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcb56630>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fcb5d9b0>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcb6b908>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcb6bf98>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcb77550>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fcb7f9b0>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcb8c828>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcb8ce48>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcb194a8>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fcb208d0>\n",
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 119,554,050\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.7 s, sys: 555 ms, total: 3.25 s\n",
            "Wall time: 3.72 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKFgXMFDmE-T",
        "colab_type": "code",
        "outputId": "413d5cc7-d1bc-4710-d065-953f68ee7750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "vggmodel3 = VGG16(weights='imagenet',input_tensor=input_tensor, include_top=True)\n",
        "\n",
        "for layers in (vggmodel3.layers)[:19]:\n",
        "    print(layers)\n",
        "    layers.trainable = False\n",
        "X= vggmodel3.layers[-2].output\n",
        "predictions3 = Dense(2, activation=\"softmax\")(X)\n",
        "model3 = Model(input = vggmodel3.input, output = predictions3)\n",
        "model3.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
        "model3.summary()\n",
        "\n",
        "vgg16_weights = '/content/gdrive/My Drive/deepxplore/models/good_vgg16.h5'\n",
        "model3.load_weights(vgg16_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7fa8fcd571d0>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcabec50>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fcac74e0>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fcacc320>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fca59d68>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fca5e5c0>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fca684e0>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fca6da20>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fca72b70>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fca78a90>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fca86400>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fca0f940>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fca13a90>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fca199b0>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fca26320>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fca2d860>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fca349b0>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8fca3c8d0>\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8fca47240>\n",
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 119,554,050\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.79 s, sys: 500 ms, total: 3.29 s\n",
            "Wall time: 3.79 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4luLW_qAonns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.set_learning_phase(0)\n",
        "model_layer_dict1, model_layer_dict2, model_layer_dict3 = init_coverage_tables(model1, model2, model3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD6cHroNl43Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start gen inputs\n",
        "#img_paths = image.list_pictures('./seeds', ext='JPEG')\n",
        "img_paths = list_pictures('./gdrive/My Drive/deepxplore/ImageNet/seeds')\n",
        "gen_img = preprocess_image(random.choice(img_paths))\n",
        "# print(gen_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_2JFUREo-zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_img = preprocess_image(random.choice(img_paths))\n",
        "orig_img = gen_img.copy()\n",
        "# first check if input already induces differences\n",
        "pred1, pred2, pred3 = model1.predict(gen_img), model2.predict(gen_img), model3.predict(gen_img)\n",
        "label1, label2, label3 = np.argmax(pred1[0]), np.argmax(pred2[0]), np.argmax(pred3[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he0VcigjpD5q",
        "colab_type": "code",
        "outputId": "9cd8d40f-902e-45cc-ce8d-ca9d517ff56d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(label1, label2, label3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo_-gjYopyDs",
        "colab_type": "code",
        "outputId": "a7c0d041-7d21-4558-d5e7-5e706b3ef829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('input already causes different outputs: {}, {}, {}'.format(label1, label2 ,label3) + bcolors.ENDC)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input already causes different outputs: 1, 1, 1\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RsgNg9lpZcn",
        "colab_type": "code",
        "outputId": "d7a9db25-5292-425c-fa0b-b2ec813dfb41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "######################## 摂動を加えなくても予測が3つのモデルで異なる場合の処理 Start ########################\n",
        "print('input already causes different outputs: {}, {}, {}'.format(label1, label2 ,label3) + bcolors.ENDC) \n",
        "\n",
        "update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "\n",
        "print(bcolors.OKGREEN + 'covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'\n",
        "#        print('covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'\n",
        "      % (len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
        "          neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n",
        "          neuron_covered(model_layer_dict3)[2]) + bcolors.ENDC)\n",
        "#                 neuron_covered(model_layer_dict3)[2]))\n",
        "\n",
        "averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                neuron_covered(model_layer_dict3)[0]) / float(\n",
        "    neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "    neuron_covered(model_layer_dict3)[\n",
        "        1])\n",
        "print(bcolors.OKGREEN + 'averaged covered neurons %.3f' % averaged_nc + bcolors.ENDC)\n",
        "print('averaged covered neurons %.3f' % averaged_nc)\n",
        "\n",
        "gen_img_deprocessed = deprocess_image(gen_img)\n",
        "\n",
        "# save the result to disk\n",
        "#imsave('./generated_inputs/' + 'already_differ_' + decode_label(pred1) + '_' + decode_label(\n",
        "imageio.imwrite('./gdrive/My Drive/deepxplore/ImageNet/generated_inputs/' + 'already_differ_' + str(label1) + '_' + str(label2) + '_' + str(label3) + '.png',\n",
        "        gen_img_deprocessed)\n",
        "continue\n",
        "######################## 摂動を加えなくても予測が3つのモデルで異なる場合の処理END ########################"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input already causes different outputs: 1, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.143, 13890 neurons 0.143, 13890 neurons 0.143\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.143\u001b[0m\n",
            "averaged covered neurons 0.143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-7d612618d003>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    continue\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'continue' not properly in loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P668AWABwCwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "orig_label = label1\n",
        "layer_name1, index1 = neuron_to_cover(model_layer_dict1)\n",
        "layer_name2, index2 = neuron_to_cover(model_layer_dict2)\n",
        "layer_name3, index3 = neuron_to_cover(model_layer_dict3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbUBVqf1wInT",
        "colab_type": "code",
        "outputId": "7c634e6b-b25c-4529-95d9-be958326bea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(orig_label,layer_name1, index1)\n",
        "print(orig_label,layer_name2, index2)\n",
        "print(orig_label,layer_name3, index3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 fc2 2957\n",
            "1 block5_conv3 278\n",
            "1 block3_conv3 236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL1dSvuHykqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_output = (loss1 + loss2 + loss3) + args.weight_nc * (loss1_neuron + loss2_neuron + loss3_neuron) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sBgJ5Qfy74s",
        "colab_type": "code",
        "outputId": "35ff30c8-ccab-4c3b-aab3-47441c59a96a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "layer_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'add_45:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jaUjGgzzBlG",
        "colab_type": "code",
        "outputId": "1ad24484-cee5-4070-d779-a53728063380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# for adversarial image generation\n",
        "final_loss = K.mean(layer_output)\n",
        "\n",
        "# we compute the gradient of the input picture wrt this loss\n",
        "grads = normalize(K.gradients(final_loss, input_tensor)[0])#####  エラー箇所\n",
        "print(grads)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"truediv_7:0\", shape=(?, 224, 224, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XksqUfvisPCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################## 予測が3つのモデルで同じ場合の処理 Start ########################\n",
        "# if all label agrees\n",
        "orig_label = label1\n",
        "layer_name1, index1 = neuron_to_cover(model_layer_dict1)\n",
        "layer_name2, index2 = neuron_to_cover(model_layer_dict2)\n",
        "layer_name3, index3 = neuron_to_cover(model_layer_dict3)\n",
        "# construct joint loss function\n",
        "if args.target_model == 0:\n",
        "    loss1 = -args.weight_diff * K.mean(model1.get_layer('dense_7').output[..., orig_label])\n",
        "    loss2 = K.mean(model2.get_layer('dense_8').output[..., orig_label])\n",
        "    loss3 = K.mean(model3.get_layer('dense_9').output[..., orig_label])\n",
        "elif args.target_model == 1:\n",
        "    loss1 = K.mean(model1.get_layer('dense_7').output[..., orig_label])\n",
        "    loss2 = -args.weight_diff * K.mean(model2.get_layer('dense_8').output[..., orig_label])\n",
        "    loss3 = K.mean(model3.get_layer('dense_9').output[..., orig_label])\n",
        "elif args.target_model == 2:\n",
        "    loss1 = K.mean(model1.get_layer('dense_7').output[..., label1])\n",
        "    loss2 = K.mean(model2.get_layer('dense_8').output[..., orig_label])\n",
        "    loss3 = -args.weight_diff * K.mean(model3.get_layer('dense_9').output[..., orig_label])\n",
        "loss1_neuron = K.mean(model1.get_layer(layer_name1).output[..., index1])\n",
        "loss2_neuron = K.mean(model2.get_layer(layer_name2).output[..., index2])\n",
        "loss3_neuron = K.mean(model3.get_layer(layer_name3).output[..., index3])\n",
        "layer_output = (loss1 + loss2 + loss3) + args.weight_nc * (loss1_neuron + loss2_neuron + loss3_neuron)    \n",
        "\n",
        "# for adversarial image generation\n",
        "final_loss = K.mean(layer_output)\n",
        "\n",
        "# we compute the gradient of the input picture wrt this loss\n",
        "grads = normalize(K.gradients(final_loss, input_tensor)[0])#####  エラー箇所\n",
        "##本来は K.gradients(final_loss, input_tensor)[0] = Tensor(\"gradients_8/AddN_18:0\", shape=(?, 224, 224, 3), dtype=float32) みたいな値を返すっぽい\n",
        "\n",
        "# this function returns the loss and grads given the input picture\n",
        "iterate = K.function([input_tensor], [loss1, loss2, loss3, loss1_neuron, loss2_neuron, loss3_neuron, grads])\n",
        "\n",
        "# we run gradient ascent for 20 steps\n",
        "for iters in range(args.grad_iterations):\n",
        "    loss_value1, loss_value2, loss_value3, loss_neuron1, loss_neuron2, loss_neuron3, grads_value = iterate(\n",
        "        [gen_img])\n",
        "    if args.transformation == 'light':\n",
        "        grads_value = constraint_light(grads_value)  # constraint the gradients value\n",
        "    elif args.transformation == 'occl':\n",
        "        grads_value = constraint_occl(grads_value, args.start_point,\n",
        "                                      args.occlusion_size)  # constraint the gradients value\n",
        "    elif args.transformation == 'blackout':\n",
        "        grads_value = constraint_black(grads_value)  # constraint the gradients value\n",
        "\n",
        "    gen_img += grads_value * args.step\n",
        "    pred1, pred2, pred3 = model1.predict(gen_img), model2.predict(gen_img), model3.predict(gen_img)\n",
        "    label1, label2, label3 = np.argmax(pred1[0]), np.argmax(pred2[0]), np.argmax(pred3[0])\n",
        "\n",
        "    if not label1 == label2 == label3:\n",
        "        update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "        update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "        update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "\n",
        "        print(bcolors.OKGREEN + 'covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'\n",
        "              % (len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
        "                  neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n",
        "                  neuron_covered(model_layer_dict3)[2]) + bcolors.ENDC)\n",
        "        averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                        neuron_covered(model_layer_dict3)[0]) / float(\n",
        "            neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "            neuron_covered(model_layer_dict3)[\n",
        "                1])\n",
        "        print(bcolors.OKGREEN + 'averaged covered neurons %.3f' % averaged_nc + bcolors.ENDC)\n",
        "        print('averaged covered neurons %.3f' % averaged_nc)\n",
        "\n",
        "        gen_img_deprocessed = deprocess_image(gen_img)\n",
        "        orig_img_deprocessed = deprocess_image(orig_img)\n",
        "\n",
        "        # save the result to disk\n",
        "        #imsave('./generated_inputs/' + args.transformation + '_' + decode_label(pred1) + '_' + decode_label(\n",
        "        imageio.imwrite('./gdrive/My Drive/deepxplore/ImageNet/generated_inputs/' + args.transformation + '_' + decode_label(pred1) + '_' + decode_label(\n",
        "            pred2) + '_' + decode_label(pred3) + '.png', gen_img_deprocessed)\n",
        "        #imsave('./generated_inputs/' + args.transformation + '_' + decode_label(pred1) + '_' + decode_label(\n",
        "        imageio.imwrite('./gdrive/My Drive/deepxplore/ImageNet/generated_inputs/' + args.transformation + '_' + decode_label(pred1) + '_' + decode_label(\n",
        "          pred2) + '_' + decode_label(pred3) + '_orig.png', orig_img_deprocessed)\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAlRvfDXwFB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkfdTZi4mUPf",
        "colab_type": "code",
        "outputId": "b16ffe77-d57e-4a9c-cdc2-a6d1ab8a61e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "for _ in range(args.seeds):\n",
        "    gen_img = preprocess_image(random.choice(img_paths))\n",
        "    orig_img = gen_img.copy()\n",
        "    # first check if input already induces differences\n",
        "    pred1, pred2, pred3 = model1.predict(gen_img), model2.predict(gen_img), model3.predict(gen_img)\n",
        "    label1, label2, label3 = np.argmax(pred1[0]), np.argmax(pred2[0]), np.argmax(pred3[0])\n",
        "    \n",
        "    if not label1 == label2 == label3:\n",
        "      ######################## 摂動を加えなくても予測が3つのモデルで異なる場合の処理 Start ########################\n",
        "      print('input already causes different outputs: {}, {}, {}'.format(label1, label2 ,label3) + bcolors.ENDC) \n",
        "\n",
        "      update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "      update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "      update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "\n",
        "      print(bcolors.OKGREEN + 'covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'\n",
        "      #        print('covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'\n",
        "            % (len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
        "                neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n",
        "                neuron_covered(model_layer_dict3)[2]) + bcolors.ENDC)\n",
        "      #                 neuron_covered(model_layer_dict3)[2]))\n",
        "\n",
        "      averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                      neuron_covered(model_layer_dict3)[0]) / float(\n",
        "          neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "          neuron_covered(model_layer_dict3)[\n",
        "              1])\n",
        "      print(bcolors.OKGREEN + 'averaged covered neurons %.3f' % averaged_nc + bcolors.ENDC)\n",
        "      print('averaged covered neurons %.3f' % averaged_nc)\n",
        "\n",
        "      gen_img_deprocessed = deprocess_image(gen_img)\n",
        "\n",
        "      # save the result to disk\n",
        "      #imsave('./generated_inputs/' + 'already_differ_' + decode_label(pred1) + '_' + decode_label(\n",
        "      imageio.imwrite('./gdrive/My Drive/deepxplore/ImageNet/generated_inputs/' + 'already_differ_' + str(label1) + '_' + str(label2) + '_' + str(label3) + '.png',\n",
        "              gen_img_deprocessed)\n",
        "      continue\n",
        "      ######################## 摂動を加えなくても予測が3つのモデルで異なる場合の処理END ########################\n",
        "\n",
        "    ######################## 予測が3つのモデルで同じ場合の処理 Start ########################\n",
        "    # if all label agrees\n",
        "    orig_label = label1\n",
        "    layer_name1, index1 = neuron_to_cover(model_layer_dict1)\n",
        "    layer_name2, index2 = neuron_to_cover(model_layer_dict2)\n",
        "    layer_name3, index3 = neuron_to_cover(model_layer_dict3)\n",
        "    # construct joint loss function\n",
        "    if args.target_model == 0:\n",
        "        loss1 = -args.weight_diff * K.mean(model1.get_layer('dense_7').output[..., orig_label])\n",
        "        loss2 = K.mean(model2.get_layer('dense_8').output[..., orig_label])\n",
        "        loss3 = K.mean(model3.get_layer('dense_9').output[..., orig_label])\n",
        "    elif args.target_model == 1:\n",
        "        loss1 = K.mean(model1.get_layer('dense_7').output[..., orig_label])\n",
        "        loss2 = -args.weight_diff * K.mean(model2.get_layer('dense_8').output[..., orig_label])\n",
        "        loss3 = K.mean(model3.get_layer('dense_9').output[..., orig_label])\n",
        "    elif args.target_model == 2:\n",
        "        loss1 = K.mean(model1.get_layer('dense_7').output[..., label1])\n",
        "        loss2 = K.mean(model2.get_layer('dense_8').output[..., orig_label])\n",
        "        loss3 = -args.weight_diff * K.mean(model3.get_layer('dense_9').output[..., orig_label])\n",
        "    loss1_neuron = K.mean(model1.get_layer(layer_name1).output[..., index1])\n",
        "    loss2_neuron = K.mean(model2.get_layer(layer_name2).output[..., index2])\n",
        "    loss3_neuron = K.mean(model3.get_layer(layer_name3).output[..., index3])\n",
        "    layer_output = (loss1 + loss2 + loss3) + args.weight_nc * (loss1_neuron + loss2_neuron + loss3_neuron)    \n",
        "\n",
        "    # for adversarial image generation\n",
        "    final_loss = K.mean(layer_output)\n",
        "\n",
        "    # we compute the gradient of the input picture wrt this loss\n",
        "    grads = normalize(K.gradients(final_loss, input_tensor)[0])#####  エラー箇所\n",
        "    ##本来は K.gradients(final_loss, input_tensor)[0] = Tensor(\"gradients_8/AddN_18:0\", shape=(?, 224, 224, 3), dtype=float32) みたいな値を返すっぽい\n",
        "\n",
        "    # this function returns the loss and grads given the input picture\n",
        "    iterate = K.function([input_tensor], [loss1, loss2, loss3, loss1_neuron, loss2_neuron, loss3_neuron, grads])\n",
        "\n",
        "    # we run gradient ascent for 20 steps\n",
        "    for iters in range(args.grad_iterations):\n",
        "        loss_value1, loss_value2, loss_value3, loss_neuron1, loss_neuron2, loss_neuron3, grads_value = iterate(\n",
        "            [gen_img])\n",
        "        if args.transformation == 'light':\n",
        "            grads_value = constraint_light(grads_value)  # constraint the gradients value\n",
        "        elif args.transformation == 'occl':\n",
        "            grads_value = constraint_occl(grads_value, args.start_point,\n",
        "                                          args.occlusion_size)  # constraint the gradients value\n",
        "        elif args.transformation == 'blackout':\n",
        "            grads_value = constraint_black(grads_value)  # constraint the gradients value\n",
        "\n",
        "        gen_img += grads_value * args.step\n",
        "        pred1, pred2, pred3 = model1.predict(gen_img), model2.predict(gen_img), model3.predict(gen_img)\n",
        "        label1, label2, label3 = np.argmax(pred1[0]), np.argmax(pred2[0]), np.argmax(pred3[0])\n",
        "\n",
        "        if not label1 == label2 == label3:\n",
        "            update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "            update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "            update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "\n",
        "            print(bcolors.OKGREEN + 'covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'\n",
        "                  % (len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
        "                      neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n",
        "                      neuron_covered(model_layer_dict3)[2]) + bcolors.ENDC)\n",
        "            averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                            neuron_covered(model_layer_dict3)[0]) / float(\n",
        "                neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "                neuron_covered(model_layer_dict3)[\n",
        "                    1])\n",
        "            print(bcolors.OKGREEN + 'averaged covered neurons %.3f' % averaged_nc + bcolors.ENDC)\n",
        "            print('averaged covered neurons %.3f' % averaged_nc)\n",
        "\n",
        "            gen_img_deprocessed = deprocess_image(gen_img)\n",
        "            orig_img_deprocessed = deprocess_image(orig_img)\n",
        "\n",
        "            # save the result to disk\n",
        "            #imsave('./generated_inputs/' + args.transformation + '_' + decode_label(pred1) + '_' + decode_label(\n",
        "            imageio.imwrite('./gdrive/My Drive/deepxplore/ImageNet/generated_inputs/' + args.transformation + '_' + str(label1) + '_' + str(label2) + '_' + str(label3) + '.png', gen_img_deprocessed)\n",
        "            #imsave('./generated_inputs/' + args.transformation + '_' + decode_label(pred1) + '_' + decode_label(\n",
        "            imageio.imwrite('./gdrive/My Drive/deepxplore/ImageNet/generated_inputs/' + args.transformation + '_' + str(label1) + '_' + str(label2) + '_' + str(label3) + '_orig.png', orig_img_deprocessed)\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.624, 13890 neurons 0.623, 13890 neurons 0.623\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.624\u001b[0m\n",
            "averaged covered neurons 0.624\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.625, 13890 neurons 0.625, 13890 neurons 0.625\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.625\u001b[0m\n",
            "averaged covered neurons 0.625\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.632, 13890 neurons 0.632, 13890 neurons 0.632\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.632\u001b[0m\n",
            "averaged covered neurons 0.632\n",
            "input already causes different outputs: 1, 0, 0\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.634, 13890 neurons 0.634, 13890 neurons 0.634\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.634\u001b[0m\n",
            "averaged covered neurons 0.634\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.635, 13890 neurons 0.635, 13890 neurons 0.635\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.635\u001b[0m\n",
            "averaged covered neurons 0.635\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.638, 13890 neurons 0.638, 13890 neurons 0.638\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.638\u001b[0m\n",
            "averaged covered neurons 0.638\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.642, 13890 neurons 0.642, 13890 neurons 0.642\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.642\u001b[0m\n",
            "averaged covered neurons 0.642\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.643, 13890 neurons 0.643, 13890 neurons 0.643\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.643\u001b[0m\n",
            "averaged covered neurons 0.643\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.643, 13890 neurons 0.643, 13890 neurons 0.643\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.643\u001b[0m\n",
            "averaged covered neurons 0.643\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.644, 13890 neurons 0.644, 13890 neurons 0.644\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.644\u001b[0m\n",
            "averaged covered neurons 0.644\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.645, 13890 neurons 0.645, 13890 neurons 0.645\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.645\u001b[0m\n",
            "averaged covered neurons 0.645\n",
            "input already causes different outputs: 1, 0, 0\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.645, 13890 neurons 0.646, 13890 neurons 0.646\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.645\u001b[0m\n",
            "averaged covered neurons 0.645\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.646, 13890 neurons 0.646, 13890 neurons 0.646\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.646\u001b[0m\n",
            "averaged covered neurons 0.646\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.648, 13890 neurons 0.648, 13890 neurons 0.648\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.648\u001b[0m\n",
            "averaged covered neurons 0.648\n",
            "input already causes different outputs: 1, 0, 0\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.649, 13890 neurons 0.649, 13890 neurons 0.649\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.649\u001b[0m\n",
            "averaged covered neurons 0.649\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.651, 13890 neurons 0.651, 13890 neurons 0.651\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.651\u001b[0m\n",
            "averaged covered neurons 0.651\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.652, 13890 neurons 0.652, 13890 neurons 0.652\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.652\u001b[0m\n",
            "averaged covered neurons 0.652\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.652, 13890 neurons 0.652, 13890 neurons 0.652\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.652\u001b[0m\n",
            "averaged covered neurons 0.652\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.652, 13890 neurons 0.653, 13890 neurons 0.653\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.652\u001b[0m\n",
            "averaged covered neurons 0.652\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.653, 13890 neurons 0.654, 13890 neurons 0.654\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.654\u001b[0m\n",
            "averaged covered neurons 0.654\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.655, 13890 neurons 0.655, 13890 neurons 0.655\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.655\u001b[0m\n",
            "averaged covered neurons 0.655\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.656, 13890 neurons 0.656, 13890 neurons 0.656\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.656\u001b[0m\n",
            "averaged covered neurons 0.656\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.656, 13890 neurons 0.656, 13890 neurons 0.656\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.656\u001b[0m\n",
            "averaged covered neurons 0.656\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.659, 13890 neurons 0.659, 13890 neurons 0.659\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.659\u001b[0m\n",
            "averaged covered neurons 0.659\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.659, 13890 neurons 0.659, 13890 neurons 0.659\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.659\u001b[0m\n",
            "averaged covered neurons 0.659\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.659, 13890 neurons 0.660, 13890 neurons 0.660\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.659\u001b[0m\n",
            "averaged covered neurons 0.659\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.660, 13890 neurons 0.660, 13890 neurons 0.660\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.660\u001b[0m\n",
            "averaged covered neurons 0.660\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.660, 13890 neurons 0.660, 13890 neurons 0.660\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.660\u001b[0m\n",
            "averaged covered neurons 0.660\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.660, 13890 neurons 0.661, 13890 neurons 0.661\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.660\u001b[0m\n",
            "averaged covered neurons 0.660\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.660, 13890 neurons 0.661, 13890 neurons 0.661\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.661\u001b[0m\n",
            "averaged covered neurons 0.661\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.661, 13890 neurons 0.661, 13890 neurons 0.661\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.661\u001b[0m\n",
            "averaged covered neurons 0.661\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.661, 13890 neurons 0.661, 13890 neurons 0.661\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.661\u001b[0m\n",
            "averaged covered neurons 0.661\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.661, 13890 neurons 0.661, 13890 neurons 0.661\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.661\u001b[0m\n",
            "averaged covered neurons 0.661\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.662, 13890 neurons 0.662, 13890 neurons 0.662\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.662\u001b[0m\n",
            "averaged covered neurons 0.662\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.662, 13890 neurons 0.662, 13890 neurons 0.662\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.662\u001b[0m\n",
            "averaged covered neurons 0.662\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.663, 13890 neurons 0.663, 13890 neurons 0.663\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.663\u001b[0m\n",
            "averaged covered neurons 0.663\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.663, 13890 neurons 0.663, 13890 neurons 0.663\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.663\u001b[0m\n",
            "averaged covered neurons 0.663\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.664, 13890 neurons 0.664, 13890 neurons 0.664\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.664\u001b[0m\n",
            "averaged covered neurons 0.664\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.664, 13890 neurons 0.664, 13890 neurons 0.664\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.664\u001b[0m\n",
            "averaged covered neurons 0.664\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.665, 13890 neurons 0.665, 13890 neurons 0.665\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.665\u001b[0m\n",
            "averaged covered neurons 0.665\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.666, 13890 neurons 0.666, 13890 neurons 0.666\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.666\u001b[0m\n",
            "averaged covered neurons 0.666\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.666, 13890 neurons 0.666, 13890 neurons 0.666\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.666\u001b[0m\n",
            "averaged covered neurons 0.666\n",
            "input already causes different outputs: 1, 0, 0\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.667, 13890 neurons 0.667, 13890 neurons 0.667\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.667\u001b[0m\n",
            "averaged covered neurons 0.667\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.668, 13890 neurons 0.668, 13890 neurons 0.668\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.668\u001b[0m\n",
            "averaged covered neurons 0.668\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.668, 13890 neurons 0.668, 13890 neurons 0.668\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.668\u001b[0m\n",
            "averaged covered neurons 0.668\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.668, 13890 neurons 0.668, 13890 neurons 0.668\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.668\u001b[0m\n",
            "averaged covered neurons 0.668\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.669, 13890 neurons 0.669, 13890 neurons 0.669\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.669\u001b[0m\n",
            "averaged covered neurons 0.669\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.670, 13890 neurons 0.670, 13890 neurons 0.670\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.670\u001b[0m\n",
            "averaged covered neurons 0.670\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.671, 13890 neurons 0.671, 13890 neurons 0.671\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.671\u001b[0m\n",
            "averaged covered neurons 0.671\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.671, 13890 neurons 0.671, 13890 neurons 0.671\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.671\u001b[0m\n",
            "averaged covered neurons 0.671\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.671, 13890 neurons 0.671, 13890 neurons 0.671\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.671\u001b[0m\n",
            "averaged covered neurons 0.671\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.671, 13890 neurons 0.671, 13890 neurons 0.671\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.671\u001b[0m\n",
            "averaged covered neurons 0.671\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.671, 13890 neurons 0.671, 13890 neurons 0.671\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.671\u001b[0m\n",
            "averaged covered neurons 0.671\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.671, 13890 neurons 0.671, 13890 neurons 0.671\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.671\u001b[0m\n",
            "averaged covered neurons 0.671\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.671, 13890 neurons 0.671, 13890 neurons 0.671\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.671\u001b[0m\n",
            "averaged covered neurons 0.671\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.672, 13890 neurons 0.672, 13890 neurons 0.672\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.672\u001b[0m\n",
            "averaged covered neurons 0.672\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.672, 13890 neurons 0.672, 13890 neurons 0.672\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.672\u001b[0m\n",
            "averaged covered neurons 0.672\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.672, 13890 neurons 0.672, 13890 neurons 0.672\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.672\u001b[0m\n",
            "averaged covered neurons 0.672\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.673, 13890 neurons 0.673, 13890 neurons 0.673\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.673\u001b[0m\n",
            "averaged covered neurons 0.673\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.673, 13890 neurons 0.673, 13890 neurons 0.673\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.673\u001b[0m\n",
            "averaged covered neurons 0.673\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.673, 13890 neurons 0.673, 13890 neurons 0.673\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.673\u001b[0m\n",
            "averaged covered neurons 0.673\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.674, 13890 neurons 0.674, 13890 neurons 0.674\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.674\u001b[0m\n",
            "averaged covered neurons 0.674\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.674, 13890 neurons 0.674, 13890 neurons 0.674\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.674\u001b[0m\n",
            "averaged covered neurons 0.674\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.674, 13890 neurons 0.674, 13890 neurons 0.674\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.674\u001b[0m\n",
            "averaged covered neurons 0.674\n",
            "input already causes different outputs: 1, 0, 0\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.675, 13890 neurons 0.675, 13890 neurons 0.675\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.675\u001b[0m\n",
            "averaged covered neurons 0.675\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.675, 13890 neurons 0.675, 13890 neurons 0.675\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.675\u001b[0m\n",
            "averaged covered neurons 0.675\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.675, 13890 neurons 0.675, 13890 neurons 0.675\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.675\u001b[0m\n",
            "averaged covered neurons 0.675\n",
            "input already causes different outputs: 0, 1, 1\u001b[0m\n",
            "\u001b[92mcovered neurons percentage 13890 neurons 0.675, 13890 neurons 0.675, 13890 neurons 0.675\u001b[0m\n",
            "\u001b[92maveraged covered neurons 0.675\u001b[0m\n",
            "averaged covered neurons 0.675\n",
            "CPU times: user 9min 21s, sys: 1min 17s, total: 10min 39s\n",
            "Wall time: 14min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn3Uy4yLriOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6kmtx7QQMKA",
        "colab_type": "text"
      },
      "source": [
        "## エラー箇所\n",
        "* grads = normalize(K.gradients(final_loss, input_tensor)[0])\n",
        "## 原因 \n",
        "* K.gradients(final_loss, input_tensor)[0] が None\n",
        "\n",
        "## 追跡\n",
        "\n",
        "##小澤さんのコードと異なる部分\n",
        "### layer_output が異なる\n",
        "#### Nomal\n",
        "```\n",
        "layer_output\n",
        "Tensor(\"add_20:0\", shape=(), dtype=float32)\n",
        "```\n",
        "### Error\n",
        "```\n",
        "layer_output\n",
        "Tensor(\"add_50:0\", shape=(), dtype=float32)\n",
        "```\n",
        "\n",
        "\n",
        "### final_loss も異なる\n",
        "（ final_loss = K.mean(layer_output) なので当然ではあるが。）\n",
        "#### Nomal\n",
        "```\n",
        "final_loss\n",
        "Tensor(\"Mean_6:0\", shape=(), dtype=float32)\n",
        "\n",
        "```\n",
        "#### Error\n",
        "```\n",
        "final_loss\n",
        "Tensor(\"Mean_48:0\", shape=(), dtype=float32)\n",
        "```\n",
        "\n",
        "\n",
        "### input_tensor は同じ\n",
        "#### Nomal\n",
        "```\n",
        "input_tensor\n",
        "Tensor(\"input_1:0\", shape=(?, 224, 224, 3), dtype=float32)\n",
        "```\n",
        "#### Error\n",
        "```\n",
        "input_tensor\n",
        "Tensor(\"input_1:0\", shape=(?, 224, 224, 3), dtype=float32)\n",
        "```\n",
        "\n",
        "### layer_output は以下で定義\n",
        "```\n",
        "layer_output = (loss1 + loss2 + loss3) + args.weight_nc * (loss1_neuron + loss2_neuron + loss3_neuron)\n",
        "```\n",
        "loss1, loss2, loss3, loss1_neuron, loss2_neuron, loss3_neuron は以下で定義\n",
        "```\n",
        "    if args.target_model == 0:\n",
        "        loss1 = -args.weight_diff * K.mean(model1.get_layer('predictions').output[..., orig_label])\n",
        "        loss2 = K.mean(model2.get_layer('predictions').output[..., orig_label])\n",
        "        loss3 = K.mean(model3.get_layer('fc1000').output[..., orig_label])\n",
        "    elif args.target_model == 1:\n",
        "        loss1 = K.mean(model1.get_layer('predictions').output[..., orig_label])\n",
        "        loss2 = -args.weight_diff * K.mean(model2.get_layer('predictions').output[..., orig_label])\n",
        "        loss3 = K.mean(model3.get_layer('fc1000').output[..., orig_label])\n",
        "    elif args.target_model == 2:\n",
        "        loss1 = K.mean(model1.get_layer('predictions').output[..., label1])\n",
        "        loss2 = K.mean(model2.get_layer('predictions').output[..., orig_label])\n",
        "        loss3 = -args.weight_diff * K.mean(model3.get_layer('fc1000').output[..., orig_label])\n",
        "    loss1_neuron = K.mean(model1.get_layer(layer_name1).output[..., index1])\n",
        "    loss2_neuron = K.mean(model2.get_layer(layer_name2).output[..., index2])\n",
        "    loss3_neuron = K.mean(model3.get_layer(layer_name3).output[..., index3])\n",
        "    layer_output = (loss1 + loss2 + loss3) + args.weight_nc * (loss1_neuron + loss2_neuron + loss3_neuron)\n",
        "```\n",
        "\n",
        "### loss1～3, loss1～3_neuron の差分\n",
        "\n",
        "### Nomal\n",
        "```\n",
        "loss1\n",
        "Tensor(\"mul_118:0\", shape=(), dtype=float32)\n",
        "loss2\n",
        "Tensor(\"Mean_473:0\", shape=(), dtype=float32)\n",
        "loss3\n",
        "Tensor(\"Mean_474:0\", shape=(), dtype=float32)\n",
        "loss1_neuron\n",
        "Tensor(\"Mean_475:0\", shape=(), dtype=float32)\n",
        "loss2_neuron\n",
        "Tensor(\"Mean_476:0\", shape=(), dtype=float32)\n",
        "loss3_neuron\n",
        "Tensor(\"Mean_477:0\", shape=(), dtype=float32)\n",
        "layer_output\n",
        "Tensor(\"add_374:0\", shape=(), dtype=float32)\n",
        "```\n",
        "\n",
        "### Error\n",
        "```\n",
        "loss1\n",
        "Tensor(\"mul_14:0\", shape=(), dtype=float32)\n",
        "loss2\n",
        "Tensor(\"Mean_50:0\", shape=(), dtype=float32)\n",
        "loss3\n",
        "Tensor(\"Mean_51:0\", shape=(), dtype=float32)\n",
        "loss1_neuron\n",
        "Tensor(\"Mean_52:0\", shape=(), dtype=float32)\n",
        "loss2_neuron\n",
        "Tensor(\"Mean_53:0\", shape=(), dtype=float32)\n",
        "loss3_neuron\n",
        "Tensor(\"Mean_54:0\", shape=(), dtype=float32)\n",
        "layer_output\n",
        "Tensor(\"add_55:0\", shape=(), dtype=float32)\n",
        "```\n",
        "\n",
        "\n"
      ]
    }
  ]
}