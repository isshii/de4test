{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "DeepXplore_base.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isshii/de4test/blob/master/DeepXplore/DeepXplore_03_03_MNIST_per_figure_draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHbF5GaCQlkP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGVFjZpUIRF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 共通で使うパスなどの定義\n",
        "# 共通の変数設定\n",
        "# 共通フォルダパス\n",
        "data_dir = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/data\"\n",
        "#data_imagenet = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/data/ImageNet\"\n",
        "data_mnist = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/data/MNIST\"\n",
        "#data_imagenet_seeds = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/data/ImageNet/seeds\"\n",
        "model_dir = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/model\"\n",
        "output_dir = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/output\"\n",
        "tmp_dir = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/tmp\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4lP4POGn5Xj",
        "colab_type": "code",
        "outputId": "8ad3067d-1f21-4b53-c891-fbcb6966a0af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Goggle Drive つなぐ\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3d3Suv3Q5Db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# outputフォルダ内容物のクリーンアップ削除\n",
        "!rm \"$output_dir\"/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhdHYnLT0Nbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/ColabNotebooks/test4ai/model/MNIST')\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDY8sDVBqxmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a9a3249-bbb8-4639-f820-75efea5e3e9f"
      },
      "source": [
        "import argparse\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input\n",
        "import imageio\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Input, Dense, Activation, Flatten\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "import os"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiGGwQVElJNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "45dabb3e-2920-49d3-efd1-650b76ec1da9"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 9363819296037387895, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 15635049406761603987\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 2716633303471246417\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15956161332\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 13049004744745239112\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWQ2M_8glJNM",
        "colab_type": "code",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0e12112c-baea-47e0-9f58-f05896b4d29a"
      },
      "source": [
        "#@title デフォルトのタイトル テキスト\n",
        "# DeepXplore のパラメータ設定部\n",
        "# read the parameter\n",
        "# argument parsing\n",
        "parser = argparse.ArgumentParser(description='Main function for difference-inducing input generation in MNIST dataset')\n",
        "parser.add_argument('transformation', help=\"realistic transformation type\", choices=['light', 'occl', 'blackout'])\n",
        "parser.add_argument('weight_diff', help=\"weight hyperparm to control differential behavior\", type=float)\n",
        "parser.add_argument('weight_nc', help=\"weight hyperparm to control neuron coverage\", type=float)\n",
        "parser.add_argument('step', help=\"step size of gradient descent\", type=float)\n",
        "parser.add_argument('seeds', help=\"number of seeds of input\", type=int)\n",
        "parser.add_argument('grad_iterations', help=\"number of iterations of gradient descent\", type=int)\n",
        "parser.add_argument('threshold', help=\"threshold for determining neuron activated\", type=float)\n",
        "parser.add_argument('-t', '--target_model', help=\"target model that we want it predicts differently\",\n",
        "                    choices=[0, 1, 2], default=0, type=int)\n",
        "parser.add_argument('-sp', '--start_point', help=\"occlusion upper left corner coordinate\", default=(0, 0), type=tuple)\n",
        "parser.add_argument('-occl_size', '--occlusion_size', help=\"occlusion size\", default=(10, 10), type=tuple)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['-occl_size', '--occlusion_size'], dest='occlusion_size', nargs=None, const=None, default=(10, 10), type=<class 'tuple'>, choices=None, help='occlusion size', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Csx_IXrMdMj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93KW-VGjMzun",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title ノイズのタイプ light / occl / blackout\n",
        "#@body {light,occl,blackout} weight_diff weight_nc step seeds\n",
        "#                   grad_iterations threshold\n",
        "noise_type = \"light\" #@param [\"light\", \"occl\", \"blackout\"]\n",
        "weight_diff = \"0.1\" #@param {type:\"string\"}\n",
        "weight_nc = \"0.1\" #@param {type:\"string\"}\n",
        "step = \"20\" #@param {type:\"string\"}　#50だとほぼ白飛び\n",
        "seeds = \"80\" #@param {type:\"string\"}\n",
        "grad_iterations = \"10\" #@param {type:\"string\"}\n",
        "threshold = \"0.1\" #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szk80fCuPts9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = parser.parse_args([noise_type, weight_diff, weight_nc, step, seeds, grad_iterations, threshold])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tTYrllplJNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    x *= 255\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x.reshape(x.shape[1], x.shape[2])  # original shape (1,img_rows, img_cols,1)\n",
        "\n",
        "\n",
        "def normalize(x):\n",
        "    # utility function to normalize a tensor by its L2 norm\n",
        "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
        "\n",
        "\n",
        "def constraint_occl(gradients, start_point, rect_shape):\n",
        "    new_grads = np.zeros_like(gradients)\n",
        "    new_grads[:, start_point[0]:start_point[0] + rect_shape[0],\n",
        "    start_point[1]:start_point[1] + rect_shape[1]] = gradients[:, start_point[0]:start_point[0] + rect_shape[0],\n",
        "                                                     start_point[1]:start_point[1] + rect_shape[1]]\n",
        "    return new_grads\n",
        "\n",
        "\n",
        "def constraint_light(gradients):\n",
        "    new_grads = np.ones_like(gradients)\n",
        "    grad_mean = np.mean(gradients)\n",
        "    return grad_mean * new_grads\n",
        "\n",
        "\n",
        "def constraint_black(gradients, rect_shape=(6, 6)):\n",
        "    start_point = (\n",
        "        random.randint(0, gradients.shape[1] - rect_shape[0]), random.randint(0, gradients.shape[2] - rect_shape[1]))\n",
        "    new_grads = np.zeros_like(gradients)\n",
        "    patch = gradients[:, start_point[0]:start_point[0] + rect_shape[0], start_point[1]:start_point[1] + rect_shape[1]]\n",
        "    if np.mean(patch) < 0:\n",
        "        new_grads[:, start_point[0]:start_point[0] + rect_shape[0],\n",
        "        start_point[1]:start_point[1] + rect_shape[1]] = -np.ones_like(patch)\n",
        "    return new_grads\n",
        "\n",
        "\n",
        "def init_coverage_tables(model1, model2, model3):\n",
        "    model_layer_dict1 = defaultdict(bool)\n",
        "    model_layer_dict2 = defaultdict(bool)\n",
        "    model_layer_dict3 = defaultdict(bool)\n",
        "    init_dict(model1, model_layer_dict1)\n",
        "    init_dict(model2, model_layer_dict2)\n",
        "    init_dict(model3, model_layer_dict3)\n",
        "    return model_layer_dict1, model_layer_dict2, model_layer_dict3\n",
        "\n",
        "\n",
        "def init_dict(model, model_layer_dict):\n",
        "    for layer in model.layers:\n",
        "        if 'flatten' in layer.name or 'input' in layer.name:\n",
        "            continue\n",
        "        for index in range(layer.output_shape[-1]):\n",
        "            model_layer_dict[(layer.name, index)] = False\n",
        "\n",
        "\n",
        "def neuron_to_cover(model_layer_dict):\n",
        "    not_covered = [(layer_name, index) for (layer_name, index), v in model_layer_dict.items() if not v]\n",
        "    if not_covered:\n",
        "        layer_name, index = random.choice(not_covered)\n",
        "    else:\n",
        "        layer_name, index = random.choice(model_layer_dict.keys())\n",
        "    return layer_name, index\n",
        "\n",
        "\n",
        "def neuron_covered(model_layer_dict):\n",
        "    covered_neurons = len([v for v in model_layer_dict.values() if v])\n",
        "    total_neurons = len(model_layer_dict)\n",
        "    return covered_neurons, total_neurons, covered_neurons / float(total_neurons)\n",
        "\n",
        "\n",
        "def update_coverage(input_data, model, model_layer_dict, threshold=0):\n",
        "    layer_names = [layer.name for layer in model.layers if\n",
        "                   'flatten' not in layer.name and 'input' not in layer.name]\n",
        "\n",
        "    intermediate_layer_model = Model(inputs=model.input,\n",
        "                                     outputs=[model.get_layer(layer_name).output for layer_name in layer_names])\n",
        "    intermediate_layer_outputs = intermediate_layer_model.predict(input_data)\n",
        "\n",
        "    for i, intermediate_layer_output in enumerate(intermediate_layer_outputs):\n",
        "        scaled = scale(intermediate_layer_output[0])\n",
        "        for num_neuron in range(scaled.shape[-1]):\n",
        "            if np.mean(scaled[..., num_neuron]) > threshold and not model_layer_dict[(layer_names[i], num_neuron)]:\n",
        "                model_layer_dict[(layer_names[i], num_neuron)] = True\n",
        "\n",
        "\n",
        "def full_coverage(model_layer_dict):\n",
        "    if False in model_layer_dict.values():\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def scale(intermediate_layer_output, rmax=1, rmin=0):\n",
        "    X_std = (intermediate_layer_output - intermediate_layer_output.min()) / (\n",
        "        intermediate_layer_output.max() - intermediate_layer_output.min())\n",
        "    X_scaled = X_std * (rmax - rmin) + rmin\n",
        "    return X_scaled\n",
        "\n",
        "\n",
        "def fired(model, layer_name, index, input_data, threshold=0):\n",
        "    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "    intermediate_layer_output = intermediate_layer_model.predict(input_data)[0]\n",
        "    scaled = scale(intermediate_layer_output)\n",
        "    if np.mean(scaled[..., index]) > threshold:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def diverged(predictions1, predictions2, predictions3, target):\n",
        "    #     if predictions2 == predictions3 == target and predictions1 != target:\n",
        "    if not predictions1 == predictions2 == predictions3:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "#add\n",
        "def list_pictures(directory, ext='jpg|jpeg|bmp|png|ppm'):\n",
        "    return [os.path.join(root, f)\n",
        "            for root, _, files in os.walk(directory) for f in files\n",
        "            if re.match(r'([\\w]+\\.(?:' + ext + '))', f.lower())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoRphb5Fl0JT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "4b65db24-478b-47ce-a45b-1519b6034e4c"
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "# the data, shuffled and split between train and test sets\n",
        "(_, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "\n",
        "# define input tensor as a placeholder\n",
        "input_tensor = Input(shape=input_shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDDT47Er6u23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "outputId": "e9c78809-94bd-4225-f077-214db73ff702"
      },
      "source": [
        "'''\n",
        "LeNet-1\n",
        "'''\n",
        "def Model1(input_tensor=None, train=False):\n",
        "    nb_classes = 10\n",
        "    # convolution kernel size\n",
        "    kernel_size = (5, 5)\n",
        "\n",
        "    if train:\n",
        "        batch_size = 256\n",
        "        nb_epoch = 10\n",
        "\n",
        "        # input image dimensions\n",
        "        img_rows, img_cols = 28, 28\n",
        "\n",
        "        # the data, shuffled and split between train and test sets\n",
        "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "        print(x_train.shape)\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "        x_train /= 255\n",
        "        x_test /= 255\n",
        "\n",
        "        # convert class vectors to binary class matrices\n",
        "        y_train = to_categorical(y_train, nb_classes)\n",
        "        y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "        input_tensor = Input(shape=input_shape)\n",
        "    elif input_tensor is None:\n",
        "        print(bcolors.FAIL + 'you have to proved input_tensor when testing')\n",
        "        exit()\n",
        "\n",
        "    # block1\n",
        "    x = Convolution2D(4, kernel_size, activation='relu', padding='same', name='block1_conv1')(input_tensor)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), name='block1_pool1')(x)\n",
        "\n",
        "    # block2\n",
        "    x = Convolution2D(12, kernel_size, activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), name='block2_pool1')(x)\n",
        "\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(nb_classes, name='before_softmax')(x)\n",
        "    x = Activation('softmax', name='predictions')(x)\n",
        "\n",
        "    model = Model(input_tensor, x)\n",
        "\n",
        "    if train:\n",
        "        # compiling\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "\n",
        "        # trainig\n",
        "        model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=nb_epoch, verbose=1)\n",
        "        # save model\n",
        "#        model.save_weights('./Model1.h5')\n",
        "        model.save_weights('/content/gdrive/My Drive/ColabNotebooks/test4ai/model/MNIST/Model1.h5')\n",
        "        score = model.evaluate(x_test, y_test, verbose=0)\n",
        "        print('\\n')\n",
        "        print('Overall Test score:', score[0])\n",
        "        print('Overall Test accuracy:', score[1])\n",
        "    else:\n",
        "#        model.load_weights('./Model1.h5')\n",
        "        model.load_weights('/content/gdrive/My Drive/ColabNotebooks/test4ai/model/MNIST/Model1.h5')\n",
        "        print(bcolors.OKBLUE + 'Model1 loaded' + bcolors.ENDC)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    Model1(train=True)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.4320 - acc: 0.8692 - val_loss: 0.1406 - val_acc: 0.9573\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.1169 - acc: 0.9653 - val_loss: 0.0949 - val_acc: 0.9686\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0893 - acc: 0.9733 - val_loss: 0.0715 - val_acc: 0.9785\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0745 - acc: 0.9774 - val_loss: 0.0744 - val_acc: 0.9763\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0658 - acc: 0.9798 - val_loss: 0.0676 - val_acc: 0.9785\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0594 - acc: 0.9819 - val_loss: 0.0573 - val_acc: 0.9814\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0550 - acc: 0.9834 - val_loss: 0.0452 - val_acc: 0.9858\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0510 - acc: 0.9841 - val_loss: 0.0441 - val_acc: 0.9856\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0477 - acc: 0.9850 - val_loss: 0.0435 - val_acc: 0.9864\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0449 - acc: 0.9856 - val_loss: 0.0421 - val_acc: 0.9862\n",
            "\n",
            "\n",
            "Overall Test score: 0.04213812852177071\n",
            "Overall Test accuracy: 0.9862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU88awZf68JO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "06c5056b-5e2a-4b27-d599-e88a26b29cd1"
      },
      "source": [
        "'''\n",
        "LeNet-4\n",
        "'''\n",
        "def Model2(input_tensor=None, train=False):\n",
        "    nb_classes = 10\n",
        "    # convolution kernel size\n",
        "    kernel_size = (5, 5)\n",
        "\n",
        "    if train:\n",
        "        batch_size = 256\n",
        "        nb_epoch = 10\n",
        "\n",
        "        # input image dimensions\n",
        "        img_rows, img_cols = 28, 28\n",
        "\n",
        "        # the data, shuffled and split between train and test sets\n",
        "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "        x_train /= 255\n",
        "        x_test /= 255\n",
        "\n",
        "        # convert class vectors to binary class matrices\n",
        "        y_train = to_categorical(y_train, nb_classes)\n",
        "        y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "        input_tensor = Input(shape=input_shape)\n",
        "    elif input_tensor is None:\n",
        "        print(bcolors.FAIL + 'you have to proved input_tensor when testing')\n",
        "        exit()\n",
        "\n",
        "    # block1\n",
        "    x = Convolution2D(6, kernel_size, activation='relu', padding='same', name='block1_conv1')(input_tensor)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), name='block1_pool1')(x)\n",
        "\n",
        "    # block2\n",
        "    x = Convolution2D(16, kernel_size, activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), name='block2_pool1')(x)\n",
        "\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(84, activation='relu', name='fc1')(x)\n",
        "    x = Dense(nb_classes, name='before_softmax')(x)\n",
        "    x = Activation('softmax', name='predictions')(x)\n",
        "\n",
        "    model = Model(input_tensor, x)\n",
        "\n",
        "    if train:\n",
        "        # compiling\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "\n",
        "        # trainig\n",
        "        model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=nb_epoch, verbose=1)\n",
        "        # save model\n",
        "        model.save_weights('./Model2.h5')\n",
        "        score = model.evaluate(x_test, y_test, verbose=0)\n",
        "        print('\\n')\n",
        "        print('Overall Test score:', score[0])\n",
        "        print('Overall Test accuracy:', score[1])\n",
        "    else:\n",
        "        model.load_weights('./Model2.h5')\n",
        "        print(bcolors.OKBLUE + 'Model2 loaded' + bcolors.ENDC)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    Model2(train=True)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3586 - acc: 0.8930 - val_loss: 0.0845 - val_acc: 0.9722\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0838 - acc: 0.9741 - val_loss: 0.0603 - val_acc: 0.9809\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0605 - acc: 0.9814 - val_loss: 0.0681 - val_acc: 0.9755\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0485 - acc: 0.9848 - val_loss: 0.0600 - val_acc: 0.9808\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0409 - acc: 0.9875 - val_loss: 0.0360 - val_acc: 0.9887\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0346 - acc: 0.9893 - val_loss: 0.0371 - val_acc: 0.9878\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0300 - acc: 0.9904 - val_loss: 0.0425 - val_acc: 0.9864\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0264 - acc: 0.9919 - val_loss: 0.0285 - val_acc: 0.9903\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0234 - acc: 0.9929 - val_loss: 0.0417 - val_acc: 0.9869\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0206 - acc: 0.9934 - val_loss: 0.0272 - val_acc: 0.9913\n",
            "\n",
            "\n",
            "Overall Test score: 0.02722550432001008\n",
            "Overall Test accuracy: 0.9913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufs67uRN7KYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "3d7a0c95-b8da-434f-d036-b50f510b4806"
      },
      "source": [
        "'''\n",
        "LeNet-5\n",
        "'''\n",
        "def Model3(input_tensor=None, train=False):\n",
        "    nb_classes = 10\n",
        "    # convolution kernel size\n",
        "    kernel_size = (5, 5)\n",
        "\n",
        "    if train:\n",
        "        batch_size = 256\n",
        "        nb_epoch = 10\n",
        "\n",
        "        # input image dimensions\n",
        "        img_rows, img_cols = 28, 28\n",
        "\n",
        "        # the data, shuffled and split between train and test sets\n",
        "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "        x_train /= 255\n",
        "        x_test /= 255\n",
        "\n",
        "        # convert class vectors to binary class matrices\n",
        "        y_train = to_categorical(y_train, nb_classes)\n",
        "        y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "        input_tensor = Input(shape=input_shape)\n",
        "    elif input_tensor is None:\n",
        "        print(bcolors.FAIL + 'you have to proved input_tensor when testing')\n",
        "        exit()\n",
        "\n",
        "    # block1\n",
        "    x = Convolution2D(6, kernel_size, activation='relu', padding='same', name='block1_conv1')(input_tensor)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), name='block1_pool1')(x)\n",
        "\n",
        "    # block2\n",
        "    x = Convolution2D(16, kernel_size, activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), name='block2_pool1')(x)\n",
        "\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(120, activation='relu', name='fc1')(x)\n",
        "    x = Dense(84, activation='relu', name='fc2')(x)\n",
        "    x = Dense(nb_classes, name='before_softmax')(x)\n",
        "    x = Activation('softmax', name='predictions')(x)\n",
        "\n",
        "    model = Model(input_tensor, x)\n",
        "\n",
        "    if train:\n",
        "        # compiling\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "\n",
        "        # trainig\n",
        "        model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=nb_epoch, verbose=1)\n",
        "        # save model\n",
        "        model.save_weights('./Model3.h5')\n",
        "        score = model.evaluate(x_test, y_test, verbose=0)\n",
        "        print('\\n')\n",
        "        print('Overall Test score:', score[0])\n",
        "        print('Overall Test accuracy:', score[1])\n",
        "    else:\n",
        "        model.load_weights('./Model3.h5')\n",
        "        print(bcolors.OKBLUE + 'Model3 loaded' + bcolors.ENDC)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    Model3(train=True)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.3909 - acc: 0.8779 - val_loss: 0.1085 - val_acc: 0.9663\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0841 - acc: 0.9739 - val_loss: 0.0713 - val_acc: 0.9772\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0579 - acc: 0.9817 - val_loss: 0.0741 - val_acc: 0.9741\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0439 - acc: 0.9863 - val_loss: 0.0410 - val_acc: 0.9865\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0359 - acc: 0.9886 - val_loss: 0.0667 - val_acc: 0.9774\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0300 - acc: 0.9909 - val_loss: 0.0788 - val_acc: 0.9768\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0258 - acc: 0.9919 - val_loss: 0.0364 - val_acc: 0.9877\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0219 - acc: 0.9927 - val_loss: 0.0293 - val_acc: 0.9894\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0188 - acc: 0.9938 - val_loss: 0.0462 - val_acc: 0.9838\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0163 - acc: 0.9948 - val_loss: 0.0359 - val_acc: 0.9884\n",
            "\n",
            "\n",
            "Overall Test score: 0.03592152180007543\n",
            "Overall Test accuracy: 0.9884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K9QiwlW7WWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "bed4d5aa-e738-4e7d-f4e7-63ce20b4f712"
      },
      "source": [
        "model1 = Model1(input_tensor=input_tensor)\n",
        "model2 = Model2(input_tensor=input_tensor)\n",
        "model3 = Model3(input_tensor=input_tensor)\n",
        "model_layer_dict1, model_layer_dict2, model_layer_dict3 = init_coverage_tables(model1, model2, model3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[94mModel1 loaded\u001b[0m\n",
            "\u001b[94mModel2 loaded\u001b[0m\n",
            "\u001b[94mModel3 loaded\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD6cHroNl43Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start gen inputs\n",
        "# img_paths = list_pictures(data_imagenet_seeds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkfdTZi4mUPf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "89a406ed-3925-48bc-9ac4-0aa7dbcb3b51"
      },
      "source": [
        "%%time\n",
        "\n",
        "count_already = 0\n",
        "count_found = 0\n",
        "count_not_found = 0\n",
        "for _ in range(args.seeds):\n",
        "    gen_img = np.expand_dims(random.choice(x_test), axis=0)\n",
        "    orig_img = gen_img.copy()\n",
        "    # first check if input already induces differences\n",
        "    label1, label2, label3 = np.argmax(model1.predict(gen_img)[0]), np.argmax(model2.predict(gen_img)[0]), np.argmax(model3.predict(gen_img)[0])\n",
        "\n",
        "    if not label1 == label2 == label3:\n",
        "        count_already += 1\n",
        "        print(bcolors.OKGREEN + '{}/{}. input already causes different outputs ({},{},{}) at{}/{}: '.format(_, args.seeds, label1, label2, label3, count_already, count_already + count_found + count_not_found) + bcolors.ENDC)\n",
        "#        print(bcolors.OKBLUE + '{}/{}. input already causes different outputs: {}, {}, {}'.format(_, args.seeds, label1, label2, label3) + bcolors.ENDC)\n",
        "        \n",
        "\n",
        "        update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "        update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "        update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "\n",
        "        print(bcolors.OKGREEN + '     covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'\n",
        "              % (len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
        "                 neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n",
        "                 neuron_covered(model_layer_dict3)[2]) + bcolors.ENDC)\n",
        "        averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                       neuron_covered(model_layer_dict3)[0]) / float(\n",
        "            neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "            neuron_covered(model_layer_dict3)[\n",
        "                1])\n",
        "        print(bcolors.OKGREEN + '     averaged covered neurons %.3f' % (averaged_nc) + bcolors.ENDC)\n",
        "\n",
        "        gen_img_deprocessed = deprocess_image(gen_img)\n",
        "\n",
        "        # save the result to disk\n",
        "        outputfilepath0 = os.path.join(output_dir, 'already_differ_' + str(label1) + '_' + str(label2) + '_' + str(label3) +'_['+ str(_) +  '].png')\n",
        "        imageio.imwrite(outputfilepath0, gen_img_deprocessed)\n",
        "        continue\n",
        "\n",
        "    # if all label agrees\n",
        "    orig_label = label1\n",
        "    layer_name1, index1 = neuron_to_cover(model_layer_dict1)\n",
        "    layer_name2, index2 = neuron_to_cover(model_layer_dict2)\n",
        "    layer_name3, index3 = neuron_to_cover(model_layer_dict3)\n",
        "\n",
        "    # construct joint loss function\n",
        "    if args.target_model == 0:\n",
        "        loss1 = -args.weight_diff * K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss2 = K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss3 = K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n",
        "    elif args.target_model == 1:\n",
        "        loss1 = K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss2 = -args.weight_diff * K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss3 = K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n",
        "    elif args.target_model == 2:\n",
        "        loss1 = K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss2 = K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss3 = -args.weight_diff * K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n",
        "    loss1_neuron = K.mean(model1.get_layer(layer_name1).output[..., index1])\n",
        "    loss2_neuron = K.mean(model2.get_layer(layer_name2).output[..., index2])\n",
        "    loss3_neuron = K.mean(model3.get_layer(layer_name3).output[..., index3])\n",
        "    layer_output = (loss1 + loss2 + loss3) + args.weight_nc * (loss1_neuron + loss2_neuron + loss3_neuron)\n",
        "\n",
        "    # for adversarial image generation\n",
        "    final_loss = K.mean(layer_output)\n",
        "\n",
        "    # we compute the gradient of the input picture wrt this loss\n",
        "    grads = normalize(K.gradients(final_loss, input_tensor)[0])\n",
        "\n",
        "    # this function returns the loss and grads given the input picture\n",
        "    iterate = K.function([input_tensor], [loss1, loss2, loss3, loss1_neuron, loss2_neuron, loss3_neuron, grads])\n",
        "\n",
        "    # we run gradient ascent for 20 steps\n",
        "    for iters in range(args.grad_iterations):\n",
        "        loss_value1, loss_value2, loss_value3, loss_neuron1, loss_neuron2, loss_neuron3, grads_value = iterate(\n",
        "            [gen_img])\n",
        "        if args.transformation == 'light':\n",
        "            grads_value = constraint_light(grads_value)  # constraint the gradients value\n",
        "        elif args.transformation == 'occl':\n",
        "            grads_value = constraint_occl(grads_value, args.start_point,\n",
        "                                          args.occlusion_size)  # constraint the gradients value\n",
        "        elif args.transformation == 'blackout':\n",
        "            grads_value = constraint_black(grads_value)  # constraint the gradients value\n",
        "\n",
        "        gen_img += grads_value * args.step\n",
        "        predictions1 = np.argmax(model1.predict(gen_img)[0])\n",
        "        predictions2 = np.argmax(model2.predict(gen_img)[0])\n",
        "        predictions3 = np.argmax(model3.predict(gen_img)[0])\n",
        "\n",
        "        if not predictions1 == predictions2 == predictions3:\n",
        "            update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "            update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "            update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "            count_found += 1\n",
        "            print(bcolors.OKBLUE + '%4d/%d. found at %d! covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f at %d/%d'\n",
        "                  % (_, args.seeds, iters, len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
        "                     neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n",
        "                     neuron_covered(model_layer_dict3)[2], count_found, count_already + count_found + count_not_found) + bcolors.ENDC)\n",
        "            averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                           neuron_covered(model_layer_dict3)[0]) / float(\n",
        "                neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "                neuron_covered(model_layer_dict3)[\n",
        "                    1])\n",
        "            print(bcolors.OKBLUE + '     averaged covered neurons %.3f' % averaged_nc + bcolors.ENDC)\n",
        "\n",
        "            gen_img_deprocessed = deprocess_image(gen_img)\n",
        "            orig_img_deprocessed = deprocess_image(orig_img)\n",
        "\n",
        "            # save the result to disk\n",
        "            #outputfilepath = os.path.join(output_dir, args.transformation + '_' + str(label1) + '_' + str(label2) + '_' + str(label3) + '.png')\n",
        "            outputfilepath = os.path.join(output_dir, args.transformation + '_from' + str(label1) + '_to' + str(predictions1) + '_'  + str(predictions2) + '_' + str(predictions3) +'_['+ str(_) +  '].png')\n",
        "            #print(outputfilepath)\n",
        "            imageio.imwrite(outputfilepath, gen_img_deprocessed)\n",
        "#            outputfilepath2 = os.path.join(output_dir, args.transformation + '_' + str(label1) + '_' + str(label2) + '_' + str(label3) + '_orig.png')\n",
        "            outputfilepath2 = os.path.join(output_dir, args.transformation + '_from' + str(label1) + '_to' + str(predictions1) + '_'  + str(predictions2) + '_' + str(predictions3) +'_['+ str(_) +  ']_orig.png')\n",
        "            #print(outputfilepath2)\n",
        "            imageio.imwrite(outputfilepath2, orig_img_deprocessed)\n",
        "            break\n",
        "        #add\n",
        "        if iters == (args.grad_iterations-1):\n",
        "            update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "            update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "            update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "            averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                           neuron_covered(model_layer_dict3)[0]) / float(\n",
        "                neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "                neuron_covered(model_layer_dict3)[\n",
        "                    1])\n",
        "            count_not_found += 1\n",
        "            print('%4d/%d. test suite was not found: averaged covered neurons %.3f at %d/%d' % (_, args.seeds, averaged_nc, count_not_found, count_already + count_found + count_not_found))\n",
        "\n",
        "            gen_img_deprocessed = deprocess_image(gen_img)\n",
        "            #orig_img_deprocessed = deprocess_image(orig_img)\n",
        "\n",
        "            # save the result to disk\n",
        "            #outputfilepath = os.path.join(output_dir, args.transformation + '_' + str(label1) + '_' + str(label2) + '_' + str(label3) + '.png')\n",
        "            outputfilepath = os.path.join(output_dir, 'not_found_' + str(label1)+'_['+ str(_) + '].png')\n",
        "#            print(outputfilepath)\n",
        "            imageio.imwrite(outputfilepath, gen_img_deprocessed)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0/80. test suite was not found: averaged covered neurons 0.402 at 1/1\n",
            "\u001b[94m   1/80. found at 2! covered neurons percentage 52 neurons 0.558, 148 neurons 0.736, 268 neurons 0.549 at 1/2\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.609\u001b[0m\n",
            "\u001b[94m   2/80. found at 5! covered neurons percentage 52 neurons 0.596, 148 neurons 0.750, 268 neurons 0.608 at 2/3\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.652\u001b[0m\n",
            "\u001b[94m   3/80. found at 1! covered neurons percentage 52 neurons 0.654, 148 neurons 0.764, 268 neurons 0.690 at 3/4\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.709\u001b[0m\n",
            "\u001b[94m   4/80. found at 1! covered neurons percentage 52 neurons 0.731, 148 neurons 0.784, 268 neurons 0.769 at 4/5\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.769\u001b[0m\n",
            "\u001b[94m   5/80. found at 1! covered neurons percentage 52 neurons 0.731, 148 neurons 0.784, 268 neurons 0.772 at 5/6\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.771\u001b[0m\n",
            "\u001b[94m   6/80. found at 1! covered neurons percentage 52 neurons 0.731, 148 neurons 0.818, 268 neurons 0.810 at 6/7\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.803\u001b[0m\n",
            "\u001b[94m   7/80. found at 0! covered neurons percentage 52 neurons 0.750, 148 neurons 0.831, 268 neurons 0.858 at 7/8\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.838\u001b[0m\n",
            "\u001b[94m   8/80. found at 2! covered neurons percentage 52 neurons 0.750, 148 neurons 0.851, 268 neurons 0.858 at 8/9\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.844\u001b[0m\n",
            "\u001b[94m   9/80. found at 2! covered neurons percentage 52 neurons 0.750, 148 neurons 0.865, 268 neurons 0.866 at 9/10\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.853\u001b[0m\n",
            "\u001b[94m  10/80. found at 2! covered neurons percentage 52 neurons 0.750, 148 neurons 0.865, 268 neurons 0.866 at 10/11\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.853\u001b[0m\n",
            "\u001b[94m  11/80. found at 1! covered neurons percentage 52 neurons 0.750, 148 neurons 0.865, 268 neurons 0.869 at 11/12\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.855\u001b[0m\n",
            "\u001b[94m  12/80. found at 1! covered neurons percentage 52 neurons 0.750, 148 neurons 0.872, 268 neurons 0.869 at 12/13\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.857\u001b[0m\n",
            "\u001b[94m  13/80. found at 1! covered neurons percentage 52 neurons 0.750, 148 neurons 0.878, 268 neurons 0.869 at 13/14\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.859\u001b[0m\n",
            "\u001b[94m  14/80. found at 2! covered neurons percentage 52 neurons 0.750, 148 neurons 0.878, 268 neurons 0.869 at 14/15\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.859\u001b[0m\n",
            "  15/80. test suite was not found: averaged covered neurons 0.859 at 2/16\n",
            "\u001b[94m  16/80. found at 1! covered neurons percentage 52 neurons 0.750, 148 neurons 0.878, 268 neurons 0.873 at 15/17\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.861\u001b[0m\n",
            "  17/80. test suite was not found: averaged covered neurons 0.863 at 3/18\n",
            "\u001b[92m18/80. input already causes different outputs (5,3,3) at1/19: \u001b[0m\n",
            "\u001b[92m     covered neurons percentage 52 neurons 0.808, 148 neurons 0.905, 268 neurons 0.881\u001b[0m\n",
            "\u001b[92m     averaged covered neurons 0.880\u001b[0m\n",
            "\u001b[94m  19/80. found at 2! covered neurons percentage 52 neurons 0.808, 148 neurons 0.905, 268 neurons 0.896 at 16/20\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.889\u001b[0m\n",
            "\u001b[94m  20/80. found at 2! covered neurons percentage 52 neurons 0.808, 148 neurons 0.905, 268 neurons 0.907 at 17/21\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.895\u001b[0m\n",
            "\u001b[94m  21/80. found at 1! covered neurons percentage 52 neurons 0.808, 148 neurons 0.905, 268 neurons 0.907 at 18/22\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.895\u001b[0m\n",
            "\u001b[94m  22/80. found at 1! covered neurons percentage 52 neurons 0.808, 148 neurons 0.905, 268 neurons 0.910 at 19/23\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.897\u001b[0m\n",
            "\u001b[94m  23/80. found at 1! covered neurons percentage 52 neurons 0.808, 148 neurons 0.905, 268 neurons 0.910 at 20/24\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.897\u001b[0m\n",
            "\u001b[94m  24/80. found at 1! covered neurons percentage 52 neurons 0.808, 148 neurons 0.905, 268 neurons 0.910 at 21/25\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.897\u001b[0m\n",
            "\u001b[94m  25/80. found at 4! covered neurons percentage 52 neurons 0.827, 148 neurons 0.905, 268 neurons 0.914 at 22/26\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.902\u001b[0m\n",
            "\u001b[94m  26/80. found at 5! covered neurons percentage 52 neurons 0.827, 148 neurons 0.905, 268 neurons 0.914 at 23/27\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.902\u001b[0m\n",
            "\u001b[94m  27/80. found at 1! covered neurons percentage 52 neurons 0.846, 148 neurons 0.912, 268 neurons 0.918 at 24/28\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.908\u001b[0m\n",
            "  28/80. test suite was not found: averaged covered neurons 0.912 at 4/29\n",
            "\u001b[94m  29/80. found at 1! covered neurons percentage 52 neurons 0.846, 148 neurons 0.919, 268 neurons 0.922 at 25/30\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.912\u001b[0m\n",
            "\u001b[94m  30/80. found at 2! covered neurons percentage 52 neurons 0.846, 148 neurons 0.919, 268 neurons 0.922 at 26/31\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.912\u001b[0m\n",
            "\u001b[94m  31/80. found at 4! covered neurons percentage 52 neurons 0.846, 148 neurons 0.919, 268 neurons 0.922 at 27/32\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.912\u001b[0m\n",
            "\u001b[92m32/80. input already causes different outputs (5,0,0) at2/33: \u001b[0m\n",
            "\u001b[92m     covered neurons percentage 52 neurons 0.846, 148 neurons 0.919, 268 neurons 0.922\u001b[0m\n",
            "\u001b[92m     averaged covered neurons 0.912\u001b[0m\n",
            "\u001b[94m  33/80. found at 2! covered neurons percentage 52 neurons 0.846, 148 neurons 0.919, 268 neurons 0.922 at 28/34\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.912\u001b[0m\n",
            "\u001b[94m  34/80. found at 2! covered neurons percentage 52 neurons 0.846, 148 neurons 0.919, 268 neurons 0.922 at 29/35\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.912\u001b[0m\n",
            "\u001b[94m  35/80. found at 1! covered neurons percentage 52 neurons 0.846, 148 neurons 0.919, 268 neurons 0.922 at 30/36\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.912\u001b[0m\n",
            "\u001b[94m  36/80. found at 2! covered neurons percentage 52 neurons 0.846, 148 neurons 0.919, 268 neurons 0.922 at 31/37\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.912\u001b[0m\n",
            "\u001b[94m  37/80. found at 1! covered neurons percentage 52 neurons 0.846, 148 neurons 0.926, 268 neurons 0.922 at 32/38\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.915\u001b[0m\n",
            "\u001b[94m  38/80. found at 2! covered neurons percentage 52 neurons 0.846, 148 neurons 0.926, 268 neurons 0.922 at 33/39\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.915\u001b[0m\n",
            "  39/80. test suite was not found: averaged covered neurons 0.915 at 5/40\n",
            "\u001b[94m  40/80. found at 1! covered neurons percentage 52 neurons 0.846, 148 neurons 0.932, 268 neurons 0.922 at 34/41\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.917\u001b[0m\n",
            "\u001b[94m  41/80. found at 1! covered neurons percentage 52 neurons 0.846, 148 neurons 0.932, 268 neurons 0.925 at 35/42\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "\u001b[94m  42/80. found at 1! covered neurons percentage 52 neurons 0.846, 148 neurons 0.932, 268 neurons 0.925 at 36/43\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "\u001b[94m  43/80. found at 0! covered neurons percentage 52 neurons 0.846, 148 neurons 0.932, 268 neurons 0.925 at 37/44\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "  44/80. test suite was not found: averaged covered neurons 0.919 at 6/45\n",
            "\u001b[94m  45/80. found at 2! covered neurons percentage 52 neurons 0.846, 148 neurons 0.932, 268 neurons 0.925 at 38/46\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "\u001b[94m  46/80. found at 1! covered neurons percentage 52 neurons 0.846, 148 neurons 0.932, 268 neurons 0.925 at 39/47\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "\u001b[94m  47/80. found at 3! covered neurons percentage 52 neurons 0.846, 148 neurons 0.932, 268 neurons 0.925 at 40/48\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "\u001b[94m  48/80. found at 1! covered neurons percentage 52 neurons 0.846, 148 neurons 0.932, 268 neurons 0.925 at 41/49\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "  49/80. test suite was not found: averaged covered neurons 0.919 at 7/50\n",
            "\u001b[94m  50/80. found at 9! covered neurons percentage 52 neurons 0.846, 148 neurons 0.932, 268 neurons 0.925 at 42/51\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "\u001b[94m  51/80. found at 2! covered neurons percentage 52 neurons 0.846, 148 neurons 0.932, 268 neurons 0.925 at 43/52\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "\u001b[94m  52/80. found at 0! covered neurons percentage 52 neurons 0.846, 148 neurons 0.932, 268 neurons 0.925 at 44/53\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "  53/80. test suite was not found: averaged covered neurons 0.919 at 8/54\n",
            "  54/80. test suite was not found: averaged covered neurons 0.919 at 9/55\n",
            "\u001b[94m  55/80. found at 4! covered neurons percentage 52 neurons 0.846, 148 neurons 0.932, 268 neurons 0.925 at 45/56\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "\u001b[94m  56/80. found at 2! covered neurons percentage 52 neurons 0.846, 148 neurons 0.939, 268 neurons 0.925 at 46/57\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.921\u001b[0m\n",
            "  57/80. test suite was not found: averaged covered neurons 0.925 at 10/58\n",
            "\u001b[94m  58/80. found at 0! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 47/59\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m  59/80. found at 1! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 48/60\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "  60/80. test suite was not found: averaged covered neurons 0.925 at 11/61\n",
            "\u001b[94m  61/80. found at 2! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 49/62\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m  62/80. found at 1! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 50/63\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m  63/80. found at 2! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 51/64\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m  64/80. found at 9! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 52/65\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "  65/80. test suite was not found: averaged covered neurons 0.925 at 12/66\n",
            "\u001b[94m  66/80. found at 3! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 53/67\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m  67/80. found at 2! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 54/68\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m  68/80. found at 0! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 55/69\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "  69/80. test suite was not found: averaged covered neurons 0.925 at 13/70\n",
            "\u001b[94m  70/80. found at 1! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 56/71\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m  71/80. found at 1! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 57/72\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m  72/80. found at 1! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 58/73\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m  73/80. found at 1! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 59/74\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "  74/80. test suite was not found: averaged covered neurons 0.925 at 14/75\n",
            "\u001b[94m  75/80. found at 1! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 60/76\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "  76/80. test suite was not found: averaged covered neurons 0.925 at 15/77\n",
            "\u001b[94m  77/80. found at 1! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 61/78\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "  78/80. test suite was not found: averaged covered neurons 0.925 at 16/79\n",
            "\u001b[94m  79/80. found at 1! covered neurons percentage 52 neurons 0.885, 148 neurons 0.939, 268 neurons 0.925 at 62/80\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "CPU times: user 4min 1s, sys: 1.93 s, total: 4min 2s\n",
            "Wall time: 4min 2s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxWV5ElWzHTy",
        "colab_type": "text"
      },
      "source": [
        "# 02 neuron coverage測定\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGZQRy9H-84T",
        "colab_type": "text"
      },
      "source": [
        "## 02 01 layerごと"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a71yjeqUDVRj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "df4100d2-8d0c-4744-ed79-4e48f222d6f6"
      },
      "source": [
        "%%time\n",
        "#list(model_layer_dict1.keys())\n",
        "data_list_layer_nc = list([x[0][0], x[1]] for x in model_layer_dict3.items())\n",
        "data_list_layer = list(x[0][0] for x in model_layer_dict3.items())\n",
        "data_list_nc = list(x[1] for x in model_layer_dict3.items())\n",
        "#print(len(x))\n",
        "print([len(data_list_layer_nc), len(data_list_layer_nc[0]), len(data_list_layer), len(data_list_nc)])\n",
        "#import matplotlib\n",
        "#matplotlib.pyplot.hist(x)\n",
        "\n",
        "\n",
        "data_list_layer_nc_on = list(x[0][0] for x in model_layer_dict3.items() if x[1]==True)\n",
        "data_list_layer_nc_off = list(x[0][0] for x in model_layer_dict3.items() if x[1]==False)\n",
        "print(len(data_list_layer_nc_on), len(data_list_layer_nc_off), len(data_list_layer_nc_on)+len(data_list_layer_nc_off))\n",
        "data_list_layer_name = list(x[0][0] for x in model_layer_dict3.items() if x[0][1]==0)\n",
        "print(len(data_list_layer_name))\n",
        "bins = len(data_list_layer_name)-1\n",
        "\n",
        "data_list_layer_nc_0 = list(0 for x in model_layer_dict3.items() if x[1]==True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[268, 2, 268, 268]\n",
            "248 20 268\n",
            "8\n",
            "CPU times: user 1.94 ms, sys: 1.01 ms, total: 2.95 ms\n",
            "Wall time: 2.82 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1idGNH-zSvO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "e2d1b6f4-0684-4602-b609-c7994a83cf35"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(30,10),dpi=60)\n",
        "#ax = fig.add_subplot(1,2,1)\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "matplotlib.pyplot.hist(data_list_layer, rwidth=0.8, bins=bins)\n",
        "# x軸縦書き。\n",
        "#plt.xticks(rotation=90)\n",
        "ax.set_xlabel('layer')\n",
        "ax.set_ylabel('# of neurons')\n",
        "\n",
        "#ax = fig.add_subplot(1,2,2)\n",
        "#matplotlib.pyplot.hist(data_list_layer, rwidth=0.8, bins=bins)\n",
        "## x 軸のラベル\n",
        "#dt_labels = [dt.strftime('%H:%M') for dt in df['datetime']]  # ラベル一覧作成\n",
        "## 4つおきにラベルを表示する。\n",
        "#plt.xticks(rotation=90)\n",
        "#plt.ylim(0,12000)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, '# of neurons')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABaAAAAHsCAYAAAAkdQrMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAwxP8HdMIdqXwOKvcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1800x600 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6px7zF7tzU5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "c9465904-c62e-460a-8710-b78f9d9c9577"
      },
      "source": [
        "\n",
        "fig = plt.figure(figsize=(12,5),dpi=60)\n",
        "#ax = fig.add_subplot(1,2,1)\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "#ax.hist([data_list_layer_nc_on, data_list_layer_nc_off],label=['ON', 'OFF'], histtype='bar', stacked=True, rwidth=0.9, bins=bins)\n",
        "ax.hist([data_list_layer_nc_on, data_list_layer_nc_off],label=['ON','OFF'], histtype='bar', stacked=True, rwidth=0.8, bins=bins)\n",
        "#ax.hist(data_list_layer_nc_on,label='ON', histtype='bar', rwidth=0.9, bins=bins)\n",
        "plt.xticks(rotation=90)\n",
        "ax.set_xlabel('layer name')\n",
        "ax.set_ylabel('# of neurons')\n",
        "ax.legend(loc='upper left')\n",
        "#ax = fig.add_subplot(1,2,2)\n",
        "#ax.hist([data_list_layer_nc_on, data_list_layer_nc_off],label=['ON', 'OFF'], histtype='bar', stacked=False, rwidth=0.9, bins=bins)\n",
        "#plt.xticks(rotation=90)\n",
        "#ax.set_xlabel('layer')\n",
        "#ax.set_ylabel('# of neurons')\n",
        "#ax.legend(loc='upper left')\n",
        "#plt.ylim(0,100)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7efb7bcc1da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAFCCAYAAADG9Bi/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6P8Dr32HDy/fWEwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x300 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MceoR_F83dKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imwjpOrA3diw",
        "colab_type": "text"
      },
      "source": [
        "#03 MNIST\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbC--mVy_Bhr",
        "colab_type": "text"
      },
      "source": [
        "##03 01 base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opqQwaLp1oWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "15e5c6e2-b99c-424e-ccb3-5731b5dc7b39"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n0_b0Os3lH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ee89c15-bf16-4c8d-8639-19654f9d328b"
      },
      "source": [
        "type(x_train)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT6jhu-I3yiP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "650ff359-6288-40df-827f-349c93b16c5e"
      },
      "source": [
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0CYjrnp30Uy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce013f6a-6a98-4762-c752-fd9b9d993d07"
      },
      "source": [
        "y_train[0:10]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgmwCS0kqL0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "138dbbce-41f5-4f3c-d434-15d50d8fb68b"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgny02LY5mur",
        "colab_type": "text"
      },
      "source": [
        "描画\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pteSDp_0qY2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e4779576-d3c9-4c67-f8f8-b46a4f752d40"
      },
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[24], cmap=\"binary_r\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe091741cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHmh74tsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-wvy_vz5wgt",
        "colab_type": "text"
      },
      "source": [
        "## 03 02 MNISTの画像をラベル（数字）ごとに仕分ける"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7iD41gOr876",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "475bf782-f6f0-4312-def4-0b34284203cc"
      },
      "source": [
        "test_per_fig_x = np.array([])\n",
        "test_per_fig_y = np.array([])\n",
        "tests_x = np.array([])\n",
        "tests_y = np.array([])\n",
        "\n",
        "length = 80\n",
        "for i in range(10):\n",
        "  cond = [(x==i) for x in y_test]\n",
        "  test_per_fig_x = x_test[cond]\n",
        "  test_per_fig_y = y_test[cond]\n",
        "  print(i, test_per_fig_x.shape, test_per_fig_x.shape[0]-1000)\n",
        "  tests_x = np.append(tests_x, test_per_fig_x[:length])\n",
        "  tests_y = np.append(tests_y, test_per_fig_y[:length])\n",
        "#  conds = [conds, cond]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 (980, 28, 28) -20\n",
            "1 (1135, 28, 28) 135\n",
            "2 (1032, 28, 28) 32\n",
            "3 (1010, 28, 28) 10\n",
            "4 (982, 28, 28) -18\n",
            "5 (892, 28, 28) -108\n",
            "6 (958, 28, 28) -42\n",
            "7 (1028, 28, 28) 28\n",
            "8 (974, 28, 28) -26\n",
            "9 (1009, 28, 28) 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "032uAPZ95xoQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a0b7835-cadf-4366-b383-4b491cfde16c"
      },
      "source": [
        "print(tests_x.shape[0]/28/28/10, length, \"equal?\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80.0 80 equal?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmI-_D_V-Ao_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l4FW_nv-B9Z",
        "colab_type": "text"
      },
      "source": [
        "## 03 03 画像ごとのDeepXplore試作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPMU9ZU_-M1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "count_already = 0\n",
        "count_found = 0\n",
        "count_not_found = 0\n",
        "for index_fig in range(10):\n",
        "  for _ in range(length)):\n",
        "    gen_img = np.expand_dims(random.choice(x_test), axis=0)\n",
        "    orig_img = gen_img.copy()\n",
        "    # first check if input already induces differences\n",
        "    label1, label2, label3 = np.argmax(model1.predict(gen_img)[0]), np.argmax(model2.predict(gen_img)[0]), np.argmax(model3.predict(gen_img)[0])\n",
        "\n",
        "    if not label1 == label2 == label3:\n",
        "        count_already += 1\n",
        "        print(bcolors.OKGREEN + '{}/10. {}/{}. input already causes different outputs ({},{},{}) at{}/{}: '.format(index_fig, _, args.seeds, label1, label2, label3, count_already, count_already + count_found + count_not_found) + bcolors.ENDC)\n",
        "#        print(bcolors.OKBLUE + '{}/{}. input already causes different outputs: {}, {}, {}'.format(_, args.seeds, label1, label2, label3) + bcolors.ENDC)\n",
        "        \n",
        "\n",
        "        update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "        update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "        update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "\n",
        "        print(bcolors.OKGREEN + '     covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'\n",
        "              % (len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
        "                 neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n",
        "                 neuron_covered(model_layer_dict3)[2]) + bcolors.ENDC)\n",
        "        averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                       neuron_covered(model_layer_dict3)[0]) / float(\n",
        "            neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "            neuron_covered(model_layer_dict3)[\n",
        "                1])\n",
        "        print(bcolors.OKGREEN + '     averaged covered neurons %.3f' % (averaged_nc) + bcolors.ENDC)\n",
        "\n",
        "        gen_img_deprocessed = deprocess_image(gen_img)\n",
        "\n",
        "        # save the result to disk\n",
        "        outputfilepath0 = os.path.join(output_dir, 'already_differ_' + str(label1) + '_' + str(label2) + '_' + str(label3) +'_['+ str(_) +  '].png')\n",
        "        imageio.imwrite(outputfilepath0, gen_img_deprocessed)\n",
        "        continue\n",
        "\n",
        "    # if all label agrees\n",
        "    orig_label = label1\n",
        "    layer_name1, index1 = neuron_to_cover(model_layer_dict1)\n",
        "    layer_name2, index2 = neuron_to_cover(model_layer_dict2)\n",
        "    layer_name3, index3 = neuron_to_cover(model_layer_dict3)\n",
        "\n",
        "    # construct joint loss function\n",
        "    if args.target_model == 0:\n",
        "        loss1 = -args.weight_diff * K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss2 = K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss3 = K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n",
        "    elif args.target_model == 1:\n",
        "        loss1 = K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss2 = -args.weight_diff * K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss3 = K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n",
        "    elif args.target_model == 2:\n",
        "        loss1 = K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss2 = K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss3 = -args.weight_diff * K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n",
        "    loss1_neuron = K.mean(model1.get_layer(layer_name1).output[..., index1])\n",
        "    loss2_neuron = K.mean(model2.get_layer(layer_name2).output[..., index2])\n",
        "    loss3_neuron = K.mean(model3.get_layer(layer_name3).output[..., index3])\n",
        "    layer_output = (loss1 + loss2 + loss3) + args.weight_nc * (loss1_neuron + loss2_neuron + loss3_neuron)\n",
        "\n",
        "    # for adversarial image generation\n",
        "    final_loss = K.mean(layer_output)\n",
        "\n",
        "    # we compute the gradient of the input picture wrt this loss\n",
        "    grads = normalize(K.gradients(final_loss, input_tensor)[0])\n",
        "\n",
        "    # this function returns the loss and grads given the input picture\n",
        "    iterate = K.function([input_tensor], [loss1, loss2, loss3, loss1_neuron, loss2_neuron, loss3_neuron, grads])\n",
        "\n",
        "    # we run gradient ascent for 20 steps\n",
        "    for iters in range(args.grad_iterations):\n",
        "        loss_value1, loss_value2, loss_value3, loss_neuron1, loss_neuron2, loss_neuron3, grads_value = iterate(\n",
        "            [gen_img])\n",
        "        if args.transformation == 'light':\n",
        "            grads_value = constraint_light(grads_value)  # constraint the gradients value\n",
        "        elif args.transformation == 'occl':\n",
        "            grads_value = constraint_occl(grads_value, args.start_point,\n",
        "                                          args.occlusion_size)  # constraint the gradients value\n",
        "        elif args.transformation == 'blackout':\n",
        "            grads_value = constraint_black(grads_value)  # constraint the gradients value\n",
        "\n",
        "        gen_img += grads_value * args.step\n",
        "        predictions1 = np.argmax(model1.predict(gen_img)[0])\n",
        "        predictions2 = np.argmax(model2.predict(gen_img)[0])\n",
        "        predictions3 = np.argmax(model3.predict(gen_img)[0])\n",
        "\n",
        "        if not predictions1 == predictions2 == predictions3:\n",
        "            update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "            update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "            update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "            count_found += 1\n",
        "            print(bcolors.OKBLUE + '%2d/10. %4d/%d. found at %d! covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f at %d/%d'\n",
        "                  % (index_fig, _, args.seeds, iters, len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
        "                     neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n",
        "                     neuron_covered(model_layer_dict3)[2], count_found, count_already + count_found + count_not_found) + bcolors.ENDC)\n",
        "            averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                           neuron_covered(model_layer_dict3)[0]) / float(\n",
        "                neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "                neuron_covered(model_layer_dict3)[\n",
        "                    1])\n",
        "            print(bcolors.OKBLUE + '     averaged covered neurons %.3f' % averaged_nc + bcolors.ENDC)\n",
        "\n",
        "            gen_img_deprocessed = deprocess_image(gen_img)\n",
        "            orig_img_deprocessed = deprocess_image(orig_img)\n",
        "\n",
        "            # save the result to disk\n",
        "            #outputfilepath = os.path.join(output_dir, args.transformation + '_' + str(label1) + '_' + str(label2) + '_' + str(label3) + '.png')\n",
        "            outputfilepath = os.path.join(output_dir, args.transformation + '_from' + str(label1) + '_to' + str(predictions1) + '_'  + str(predictions2) + '_' + str(predictions3) +'_['+ str(_) +  '].png')\n",
        "            #print(outputfilepath)\n",
        "            imageio.imwrite(outputfilepath, gen_img_deprocessed)\n",
        "#            outputfilepath2 = os.path.join(output_dir, args.transformation + '_' + str(label1) + '_' + str(label2) + '_' + str(label3) + '_orig.png')\n",
        "            outputfilepath2 = os.path.join(output_dir, args.transformation + '_from' + str(label1) + '_to' + str(predictions1) + '_'  + str(predictions2) + '_' + str(predictions3) +'_['+ str(_) +  ']_orig.png')\n",
        "            #print(outputfilepath2)\n",
        "            imageio.imwrite(outputfilepath2, orig_img_deprocessed)\n",
        "            break\n",
        "        #add\n",
        "        if iters == (args.grad_iterations-1):\n",
        "            update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "            update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "            update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "            averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                           neuron_covered(model_layer_dict3)[0]) / float(\n",
        "                neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "                neuron_covered(model_layer_dict3)[\n",
        "                    1])\n",
        "            count_not_found += 1\n",
        "            print('%2d/10. %4d/%d. test suite was not found: averaged covered neurons %.3f at %d/%d' % (index_fig, _, args.seeds, averaged_nc, count_not_found, count_already + count_found + count_not_found))\n",
        "\n",
        "            gen_img_deprocessed = deprocess_image(gen_img)\n",
        "            #orig_img_deprocessed = deprocess_image(orig_img)\n",
        "\n",
        "            # save the result to disk\n",
        "            #outputfilepath = os.path.join(output_dir, args.transformation + '_' + str(label1) + '_' + str(label2) + '_' + str(label3) + '.png')\n",
        "            outputfilepath = os.path.join(output_dir, 'not_found_' + str(label1)+'_['+ str(_) + '].png')\n",
        "#            print(outputfilepath)\n",
        "            imageio.imwrite(outputfilepath, gen_img_deprocessed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i_FkG64BOYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}