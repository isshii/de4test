{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "DeepXplore_with_LimeData.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isshii/de4test/blob/master/DeepXplore/DeepXplore_with_LimeData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGVFjZpUIRF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 共通で使うパスなどの定義\n",
        "# 共通の変数設定\n",
        "# 共通フォルダパス\n",
        "data_dir = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/data\"\n",
        "data_imagenet = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/data/ImageNet\"\n",
        "data_imagenet_seeds = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/data/ImageNet/seeds\"\n",
        "model_dir = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/model\"\n",
        "output_dir = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/output\"\n",
        "tmp_dir = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/tmp\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4lP4POGn5Xj",
        "colab_type": "code",
        "outputId": "3548460d-2eef-421f-d66a-1c37df39f117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# Goggle Drive つなぐ\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3d3Suv3Q5Db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# outputフォルダ内容物のクリーンアップ削除\n",
        "!rm \"$output_dir\"/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDY8sDVBqxmK",
        "colab_type": "code",
        "outputId": "5861e9f7-6164-4226-c91b-ed57119174c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import argparse\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.layers import Input\n",
        "import imageio\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiGGwQVElJNH",
        "colab_type": "code",
        "outputId": "a7972ece-271b-470c-d4aa-0defe9f1f0a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 473040390303178362, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 17029367125077635141\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 9661749827306392005\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14912199066\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 16806230322597559401\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Csx_IXrMdMj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tTYrllplJNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "import os, re\n",
        "\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    input_img_data = image.img_to_array(img)\n",
        "    input_img_data = np.expand_dims(input_img_data, axis=0)\n",
        "    input_img_data = preprocess_input(input_img_data)  # final input shape = (1,224,224,3)\n",
        "    return input_img_data\n",
        "\n",
        "\n",
        "def deprocess_image(x):\n",
        "    x = x.reshape((224, 224, 3))\n",
        "    # Remove zero-center by mean pixel\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "\n",
        "def decode_label(pred):\n",
        "    return decode_predictions(pred)[0][0][1]\n",
        "\n",
        "\n",
        "def normalize(x):\n",
        "    # utility function to normalize a tensor by its L2 norm\n",
        "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
        "\n",
        "\n",
        "def constraint_occl(gradients, start_point, rect_shape):\n",
        "    new_grads = np.zeros_like(gradients)\n",
        "    new_grads[:, start_point[0]:start_point[0] + rect_shape[0],\n",
        "    start_point[1]:start_point[1] + rect_shape[1]] = gradients[:, start_point[0]:start_point[0] + rect_shape[0],\n",
        "                                                     start_point[1]:start_point[1] + rect_shape[1]]\n",
        "    return new_grads\n",
        "\n",
        "\n",
        "def constraint_light(gradients):\n",
        "    new_grads = np.ones_like(gradients)\n",
        "    grad_mean = 1e4 * np.mean(gradients)\n",
        "    return grad_mean * new_grads\n",
        "\n",
        "\n",
        "def constraint_black(gradients, rect_shape=(10, 10)):\n",
        "    start_point = (\n",
        "        random.randint(0, gradients.shape[1] - rect_shape[0]), random.randint(0, gradients.shape[2] - rect_shape[1]))\n",
        "    new_grads = np.zeros_like(gradients)\n",
        "    patch = gradients[:, start_point[0]:start_point[0] + rect_shape[0], start_point[1]:start_point[1] + rect_shape[1]]\n",
        "    if np.mean(patch) < 0:\n",
        "        new_grads[:, start_point[0]:start_point[0] + rect_shape[0],\n",
        "        start_point[1]:start_point[1] + rect_shape[1]] = -np.ones_like(patch)\n",
        "    return new_grads\n",
        "\n",
        "\n",
        "def init_coverage_tables(model1, model2, model3):\n",
        "    model_layer_dict1 = defaultdict(bool)\n",
        "    model_layer_dict2 = defaultdict(bool)\n",
        "    model_layer_dict3 = defaultdict(bool)\n",
        "    init_dict(model1, model_layer_dict1)\n",
        "    init_dict(model2, model_layer_dict2)\n",
        "    init_dict(model3, model_layer_dict3)\n",
        "    return model_layer_dict1, model_layer_dict2, model_layer_dict3\n",
        "\n",
        "\n",
        "def init_dict(model, model_layer_dict):\n",
        "    for layer in model.layers:\n",
        "        if 'flatten' in layer.name or 'input' in layer.name:\n",
        "            continue\n",
        "        for index in range(layer.output_shape[-1]):\n",
        "            model_layer_dict[(layer.name, index)] = False\n",
        "\n",
        "\n",
        "def neuron_to_cover(model_layer_dict):\n",
        "    not_covered = [(layer_name, index) for (layer_name, index), v in list(model_layer_dict.items()) if not v]\n",
        "    if not_covered:\n",
        "        layer_name, index = random.choice(not_covered)\n",
        "    else:\n",
        "        layer_name, index = random.choice(list(model_layer_dict.keys()))\n",
        "    return layer_name, index\n",
        "\n",
        "\n",
        "def neuron_covered(model_layer_dict):\n",
        "    covered_neurons = len([v for v in list(model_layer_dict.values()) if v])\n",
        "    total_neurons = len(model_layer_dict)\n",
        "    return covered_neurons, total_neurons, covered_neurons / float(total_neurons)\n",
        "\n",
        "\n",
        "def scale(intermediate_layer_output, rmax=1, rmin=0):\n",
        "    X_std = (intermediate_layer_output - intermediate_layer_output.min()) / (\n",
        "        intermediate_layer_output.max() - intermediate_layer_output.min())\n",
        "    X_scaled = X_std * (rmax - rmin) + rmin\n",
        "    return X_scaled\n",
        "\n",
        "\n",
        "def update_coverage(input_data, model, model_layer_dict, threshold=0):\n",
        "    layer_names = [layer.name for layer in model.layers if\n",
        "                   'flatten' not in layer.name and 'input' not in layer.name]\n",
        "\n",
        "    intermediate_layer_model = Model(inputs=model.input,\n",
        "                                     outputs=[model.get_layer(layer_name).output for layer_name in layer_names])\n",
        "    intermediate_layer_outputs = intermediate_layer_model.predict(input_data)\n",
        "\n",
        "    for i, intermediate_layer_output in enumerate(intermediate_layer_outputs):\n",
        "        scaled = scale(intermediate_layer_output[0])\n",
        "        for num_neuron in range(scaled.shape[-1]):\n",
        "            if np.mean(scaled[..., num_neuron]) > threshold and not model_layer_dict[(layer_names[i], num_neuron)]:\n",
        "                model_layer_dict[(layer_names[i], num_neuron)] = True\n",
        "\n",
        "\n",
        "def full_coverage(model_layer_dict):\n",
        "    if False in list(model_layer_dict.values()):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def fired(model, layer_name, index, input_data, threshold=0):\n",
        "    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "    intermediate_layer_output = intermediate_layer_model.predict(input_data)[0]\n",
        "    scaled = scale(intermediate_layer_output)\n",
        "    if np.mean(scaled[..., index]) > threshold:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def diverged(predictions1, predictions2, predictions3, target):\n",
        "    if not predictions1 == predictions2 == predictions3:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "#add\n",
        "def list_pictures(directory, ext='jpg|jpeg|bmp|png|ppm'):\n",
        "    return [os.path.join(root, f)\n",
        "            for root, _, files in os.walk(directory) for f in files\n",
        "            if re.match(r'([\\w]+\\.(?:' + ext + '))', f.lower())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoRphb5Fl0JT",
        "colab_type": "code",
        "outputId": "f7954de8-ea35-40f7-ff7f-d1755b956b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "%%time\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 224, 224\n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "\n",
        "# define input tensor as a placeholder\n",
        "input_tensor = Input(shape=input_shape)\n",
        "\n",
        "# load multiple models sharing same input tensor\n",
        "K.set_learning_phase(0)\n",
        "model1 = VGG16(input_tensor=input_tensor)\n",
        "model2 = VGG19(input_tensor=input_tensor)\n",
        "model3 = ResNet50(input_tensor=input_tensor)\n",
        "\n",
        "\n",
        "# init coverage table\n",
        "model_layer_dict1, model_layer_dict2, model_layer_dict3 = init_coverage_tables(model1, model2, model3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 6s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 19s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102858752/102853048 [==============================] - 1s 0us/step\n",
            "CPU times: user 11 s, sys: 5.13 s, total: 16.2 s\n",
            "Wall time: 42.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnPoyioOFvBI",
        "colab_type": "code",
        "outputId": "b416cf9c-63a0-45bf-8543-f5b6bb42a35d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        }
      },
      "source": [
        "import yaml\n",
        "class PrettySafeLoader(yaml.SafeLoader):\n",
        "    def construct_python_tuple(self, node):\n",
        "        return tuple(self.construct_sequence(node))\n",
        "\n",
        "PrettySafeLoader.add_constructor(\n",
        "    u'tag:yaml.org,2002:python/tuple',\n",
        "    PrettySafeLoader.construct_python_tuple)\n",
        "\n",
        "thing = yaml.load(\"\"\"\n",
        "ILSVRC2012_test_00001288.JPEG: !!python/tuple [164, 0]\n",
        "ILSVRC2012_test_00001306.JPEG: !!python/tuple [62, 109]\n",
        "ILSVRC2012_test_00001322.JPEG: !!python/tuple [0, 36]\n",
        "ILSVRC2012_test_00001351.JPEG: !!python/tuple [118, 5]\n",
        "ILSVRC2012_test_00001369.JPEG: !!python/tuple [119, 119]\n",
        "ILSVRC2012_test_00001375.JPEG: !!python/tuple [54, 70]\n",
        "ILSVRC2012_test_00001390.JPEG: !!python/tuple [123, 0]\n",
        "ILSVRC2012_test_00001422.JPEG: !!python/tuple [137, 118]\n",
        "ILSVRC2012_test_00001428.JPEG: !!python/tuple [16, 73]\n",
        "ILSVRC2012_test_00001451.JPEG: !!python/tuple [141, 12]\n",
        "ILSVRC2012_test_00001469.JPEG: !!python/tuple [44, 164]\n",
        "ILSVRC2012_test_00001475.JPEG: !!python/tuple [70, 164]\n",
        "ILSVRC2012_test_00001490.JPEG: !!python/tuple [97, 0]\n",
        "ILSVRC2012_test_00001514.JPEG: !!python/tuple [164, 145]\n",
        "ILSVRC2012_test_00001526.JPEG: !!python/tuple [140, 20]\n",
        "ILSVRC2012_test_00001530.JPEG: !!python/tuple [164, 164]\n",
        "ILSVRC2012_test_00001543.JPEG: !!python/tuple [72, 90]\n",
        "ILSVRC2012_test_00001549.JPEG: !!python/tuple [104, 55]\n",
        "ILSVRC2012_test_00001567.JPEG: !!python/tuple [77, 122]\n",
        "ILSVRC2012_test_00001582.JPEG: !!python/tuple [60, 70]\n",
        "ILSVRC2012_test_00001588.JPEG: !!python/tuple [164, 164]\n",
        "ILSVRC2012_test_00001613.JPEG: !!python/tuple [0, 85]\n",
        "ILSVRC2012_test_00001619.JPEG: !!python/tuple [47, 25]\n",
        "ILSVRC2012_test_00001637.JPEG: !!python/tuple [0, 135]\n",
        "ILSVRC2012_test_00001644.JPEG: !!python/tuple [29, 156]\n",
        "ILSVRC2012_test_00001660.JPEG: !!python/tuple [164, 0]\n",
        "ILSVRC2012_test_00001676.JPEG: !!python/tuple [0, 57]\n",
        "ILSVRC2012_test_00001685.JPEG: !!python/tuple [121, 23]\n",
        "ILSVRC2012_test_00001699.JPEG: !!python/tuple [164, 23]\n",
        "ILSVRC2012_test_00001701.JPEG: !!python/tuple [80, 164]\n",
        "ILSVRC2012_test_00001725.JPEG: !!python/tuple [56, 164]\n",
        "ILSVRC2012_test_00001733.JPEG: !!python/tuple [71, 43]\n",
        "ILSVRC2012_test_00001739.JPEG: !!python/tuple [0, 164]\n",
        "ILSVRC2012_test_00001756.JPEG: !!python/tuple [0, 164]\n",
        "ILSVRC2012_test_00001772.JPEG: !!python/tuple [88, 87]\n",
        "ILSVRC2012_test_00001778.JPEG: !!python/tuple [29, 164]\n",
        "ILSVRC2012_test_00001796.JPEG: !!python/tuple [118, 164]\n",
        "ILSVRC2012_test_00001797.JPEG: !!python/tuple [164, 164]\n",
        "ILSVRC2012_test_00001810.JPEG: !!python/tuple [136, 86]\n",
        "ILSVRC2012_test_00001834.JPEG: !!python/tuple [16, 68]\n",
        "ILSVRC2012_test_00001847.JPEG: !!python/tuple [99, 54]\n",
        "ILSVRC2012_test_00001863.JPEG: !!python/tuple [123, 4]\n",
        "ILSVRC2012_test_00001869.JPEG: !!python/tuple [67, 137]\n",
        "ILSVRC2012_test_00001886.JPEG: !!python/tuple [141, 75]\n",
        "ILSVRC2012_test_00001890.JPEG: !!python/tuple [164, 164]\n",
        "ILSVRC2012_test_00001902.JPEG: !!python/tuple [104, 43]\n",
        "ILSVRC2012_test_00001926.JPEG: !!python/tuple [62, 135]\n",
        "ILSVRC2012_test_00001930.JPEG: !!python/tuple [21, 164]\n",
        "ILSVRC2012_test_00001949.JPEG: !!python/tuple [117, 17]\n",
        "ILSVRC2012_test_00001955.JPEG: !!python/tuple [0, 80]\n",
        "\"\"\")\n",
        "\n",
        "for filename in thing:\n",
        "    print(f\"{filename} : {thing[filename]}\")\n",
        "    # ここで dx\n",
        "    # filename は使い方同じで、thing[filename] をノイズの場所として与える\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ILSVRC2012_test_00001288.JPEG : (164, 0)\n",
            "ILSVRC2012_test_00001306.JPEG : (62, 109)\n",
            "ILSVRC2012_test_00001322.JPEG : (0, 36)\n",
            "ILSVRC2012_test_00001351.JPEG : (118, 5)\n",
            "ILSVRC2012_test_00001369.JPEG : (119, 119)\n",
            "ILSVRC2012_test_00001375.JPEG : (54, 70)\n",
            "ILSVRC2012_test_00001390.JPEG : (123, 0)\n",
            "ILSVRC2012_test_00001422.JPEG : (137, 118)\n",
            "ILSVRC2012_test_00001428.JPEG : (16, 73)\n",
            "ILSVRC2012_test_00001451.JPEG : (141, 12)\n",
            "ILSVRC2012_test_00001469.JPEG : (44, 164)\n",
            "ILSVRC2012_test_00001475.JPEG : (70, 164)\n",
            "ILSVRC2012_test_00001490.JPEG : (97, 0)\n",
            "ILSVRC2012_test_00001514.JPEG : (164, 145)\n",
            "ILSVRC2012_test_00001526.JPEG : (140, 20)\n",
            "ILSVRC2012_test_00001530.JPEG : (164, 164)\n",
            "ILSVRC2012_test_00001543.JPEG : (72, 90)\n",
            "ILSVRC2012_test_00001549.JPEG : (104, 55)\n",
            "ILSVRC2012_test_00001567.JPEG : (77, 122)\n",
            "ILSVRC2012_test_00001582.JPEG : (60, 70)\n",
            "ILSVRC2012_test_00001588.JPEG : (164, 164)\n",
            "ILSVRC2012_test_00001613.JPEG : (0, 85)\n",
            "ILSVRC2012_test_00001619.JPEG : (47, 25)\n",
            "ILSVRC2012_test_00001637.JPEG : (0, 135)\n",
            "ILSVRC2012_test_00001644.JPEG : (29, 156)\n",
            "ILSVRC2012_test_00001660.JPEG : (164, 0)\n",
            "ILSVRC2012_test_00001676.JPEG : (0, 57)\n",
            "ILSVRC2012_test_00001685.JPEG : (121, 23)\n",
            "ILSVRC2012_test_00001699.JPEG : (164, 23)\n",
            "ILSVRC2012_test_00001701.JPEG : (80, 164)\n",
            "ILSVRC2012_test_00001725.JPEG : (56, 164)\n",
            "ILSVRC2012_test_00001733.JPEG : (71, 43)\n",
            "ILSVRC2012_test_00001739.JPEG : (0, 164)\n",
            "ILSVRC2012_test_00001756.JPEG : (0, 164)\n",
            "ILSVRC2012_test_00001772.JPEG : (88, 87)\n",
            "ILSVRC2012_test_00001778.JPEG : (29, 164)\n",
            "ILSVRC2012_test_00001796.JPEG : (118, 164)\n",
            "ILSVRC2012_test_00001797.JPEG : (164, 164)\n",
            "ILSVRC2012_test_00001810.JPEG : (136, 86)\n",
            "ILSVRC2012_test_00001834.JPEG : (16, 68)\n",
            "ILSVRC2012_test_00001847.JPEG : (99, 54)\n",
            "ILSVRC2012_test_00001863.JPEG : (123, 4)\n",
            "ILSVRC2012_test_00001869.JPEG : (67, 137)\n",
            "ILSVRC2012_test_00001886.JPEG : (141, 75)\n",
            "ILSVRC2012_test_00001890.JPEG : (164, 164)\n",
            "ILSVRC2012_test_00001902.JPEG : (104, 43)\n",
            "ILSVRC2012_test_00001926.JPEG : (62, 135)\n",
            "ILSVRC2012_test_00001930.JPEG : (21, 164)\n",
            "ILSVRC2012_test_00001949.JPEG : (117, 17)\n",
            "ILSVRC2012_test_00001955.JPEG : (0, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkfdTZi4mUPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deep_xplorer(img_path):\n",
        "    gen_img = preprocess_image(img_path)\n",
        "    orig_img = gen_img.copy()\n",
        "    # first check if input already induces differences\n",
        "    pred1, pred2, pred3 = model1.predict(gen_img), model2.predict(gen_img), model3.predict(gen_img)\n",
        "    label1, label2, label3 = np.argmax(pred1[0]), np.argmax(pred2[0]), np.argmax(pred3[0])\n",
        "    if not label1 == label2 == label3:\n",
        "        print('input already causes different outputs: {}, {}, {}'.format(decode_label(pred1),\n",
        "                                                                                            decode_label(pred2),\n",
        "                                                                                            decode_label(\n",
        "                                                                                                pred3)))\n",
        "\n",
        "        update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "        update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "        update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "\n",
        "        print('covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'\n",
        "              % (len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
        "                 neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n",
        "                 neuron_covered(model_layer_dict3)[2]))\n",
        "  \n",
        "        averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                       neuron_covered(model_layer_dict3)[0]) / float(\n",
        "            neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "            neuron_covered(model_layer_dict3)[1])\n",
        "        print('averaged covered neurons %.3f' % averaged_nc)\n",
        "\n",
        "        gen_img_deprocessed = deprocess_image(gen_img)\n",
        "\n",
        "        # save the result to disk\n",
        "        outputfilepath0 = os.path.join(output_dir, 'already_differ_' + decode_label(pred1) + '_' + decode_label(pred2) + '_' + decode_label(pred3) + '.png')\n",
        "        imageio.imwrite(outputfilepath0, gen_img_deprocessed)\n",
        "        return\n",
        "\n",
        "    # if all label agrees\n",
        "    orig_label = label1\n",
        "    layer_name1, index1 = neuron_to_cover(model_layer_dict1)\n",
        "    layer_name2, index2 = neuron_to_cover(model_layer_dict2)\n",
        "    layer_name3, index3 = neuron_to_cover(model_layer_dict3)\n",
        "\n",
        "    # construct joint loss function\n",
        "    if args.target_model == 0:\n",
        "        loss1 = -args.weight_diff * K.mean(model1.get_layer('predictions').output[..., orig_label])\n",
        "        loss2 = K.mean(model2.get_layer('predictions').output[..., orig_label])\n",
        "        loss3 = K.mean(model3.get_layer('fc1000').output[..., orig_label])\n",
        "    elif args.target_model == 1:\n",
        "        loss1 = K.mean(model1.get_layer('predictions').output[..., orig_label])\n",
        "        loss2 = -args.weight_diff * K.mean(model2.get_layer('predictions').output[..., orig_label])\n",
        "        loss3 = K.mean(model3.get_layer('fc1000').output[..., orig_label])\n",
        "    elif args.target_model == 2:\n",
        "        loss1 = K.mean(model1.get_layer('predictions').output[..., label1])\n",
        "        loss2 = K.mean(model2.get_layer('predictions').output[..., orig_label])\n",
        "        loss3 = -args.weight_diff * K.mean(model3.get_layer('fc1000').output[..., orig_label])\n",
        "    loss1_neuron = K.mean(model1.get_layer(layer_name1).output[..., index1])\n",
        "    loss2_neuron = K.mean(model2.get_layer(layer_name2).output[..., index2])\n",
        "    loss3_neuron = K.mean(model3.get_layer(layer_name3).output[..., index3])\n",
        "    layer_output = (loss1 + loss2 + loss3) + args.weight_nc * (loss1_neuron + loss2_neuron + loss3_neuron)\n",
        "\n",
        "    # for adversarial image generation\n",
        "    final_loss = K.mean(layer_output)\n",
        "\n",
        "    # we compute the gradient of the input picture wrt this loss\n",
        "    grads = normalize(K.gradients(final_loss, input_tensor)[0])\n",
        "\n",
        "    # this function returns the loss and grads given the input picture\n",
        "    iterate = K.function([input_tensor], [loss1, loss2, loss3, loss1_neuron, loss2_neuron, loss3_neuron, grads])\n",
        "\n",
        "    # we run gradient ascent for 20 steps\n",
        "    for iters in range(args.grad_iterations):\n",
        "        loss_value1, loss_value2, loss_value3, loss_neuron1, loss_neuron2, loss_neuron3, grads_value = iterate(\n",
        "            [gen_img])\n",
        "        if args.transformation == 'light':\n",
        "            grads_value = constraint_light(grads_value)  # constraint the gradients value\n",
        "        elif args.transformation == 'occl':\n",
        "            grads_value = constraint_occl(grads_value, args.start_point,\n",
        "                                          args.occlusion_size)  # constraint the gradients value\n",
        "        elif args.transformation == 'blackout':\n",
        "            grads_value = constraint_black(grads_value)  # constraint the gradients value\n",
        "\n",
        "        gen_img += grads_value * args.step\n",
        "        pred1, pred2, pred3 = model1.predict(gen_img), model2.predict(gen_img), model3.predict(gen_img)\n",
        "        label1, label2, label3 = np.argmax(pred1[0]), np.argmax(pred2[0]), np.argmax(pred3[0])\n",
        "\n",
        "        if not label1 == label2 == label3:\n",
        "            update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "            update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "            update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "            averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                           neuron_covered(model_layer_dict3)[0]) / float(\n",
        "                neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "                neuron_covered(model_layer_dict3)[\n",
        "                    1])\n",
        "            print('averaged covered neurons %.3f' % averaged_nc)\n",
        "\n",
        "            gen_img_deprocessed = deprocess_image(gen_img)\n",
        "            orig_img_deprocessed = deprocess_image(orig_img)\n",
        "\n",
        "            # save the result to disk\n",
        "            outputfilepath = os.path.join(output_dir, args.transformation + '_' + decode_label(pred1) + '_' + decode_label(pred2) + '_' + decode_label(pred3) + '.png')\n",
        "            print(outputfilepath)\n",
        "            imageio.imwrite(outputfilepath, gen_img_deprocessed)\n",
        "            outputfilepath2 = os.path.join(output_dir, args.transformation + '_' + decode_label(pred1) + '_' + decode_label(pred2) + '_' + decode_label(pred3) + '_orig.png')\n",
        "            print(outputfilepath2)\n",
        "            imageio.imwrite(outputfilepath2, orig_img_deprocessed)\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD6cHroNl43Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start gen inputs\n",
        " img_paths = list_pictures(data_imagenet_seeds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9X_iCqLGtdb",
        "colab_type": "code",
        "outputId": "57942f4e-83e7-4b14-f667-bb06ab1a2344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        }
      },
      "source": [
        "%%time\n",
        "iteration = 1\n",
        "for img_path in img_paths:\n",
        "  print(iteration)\n",
        "  iteration += 1\n",
        "  print(os.path.basename(img_path))\n",
        "  print(thing[os.path.basename(img_path)])\n",
        "  start_x = 0 # thing[os.path.basename(img_path)][0]\n",
        "  start_y = 0 # thing[os.path.basename(img_path)][1]\n",
        "\n",
        "\n",
        "  parser = argparse.ArgumentParser(description='Main function for difference-inducing input generation in MNIST dataset')\n",
        "  parser.add_argument('transformation', help=\"realistic transformation type\", choices=['light', 'occl', 'blackout'])\n",
        "  parser.add_argument('weight_diff', help=\"weight hyperparm to control differential behavior\", type=float)\n",
        "  parser.add_argument('weight_nc', help=\"weight hyperparm to control neuron coverage\", type=float)\n",
        "  parser.add_argument('step', help=\"step size of gradient descent\", type=float)\n",
        "  parser.add_argument('seeds', help=\"number of seeds of input\", type=int)\n",
        "  parser.add_argument('grad_iterations', help=\"number of iterations of gradient descent\", type=int)\n",
        "  parser.add_argument('threshold', help=\"threshold for determining neuron activated\", type=float)\n",
        "  parser.add_argument('-t', '--target_model', help=\"target model that we want it predicts differently\",\n",
        "                    choices=[0, 1, 2], default=0, type=int)\n",
        "  parser.add_argument('-sp', '--start_point', help=\"occlusion upper left corner coordinate\", default=(start_y, start_x), type=tuple)\n",
        "  parser.add_argument('-occl_size', '--occlusion_size', help=\"occlusion size\", default=(60, 60), type=tuple)\n",
        "\n",
        "  noise_type = \"occl\" \n",
        "  weight_diff = \"0.1\" \n",
        "  weight_nc = \"0.1\" \n",
        "  step = \"1\" \n",
        "  seeds = \"50\" \n",
        "  grad_iterations = \"100\" \n",
        "  threshold = \"0.1\"\n",
        "\n",
        "  args = parser.parse_args([noise_type, weight_diff, weight_nc, step, seeds, grad_iterations, threshold])\n",
        "  \n",
        "  deep_xplorer(img_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "ILSVRC2012_test_00001926.JPEG\n",
            "(62, 135)\n",
            "input already causes different outputs: stole, stole, cardigan\n",
            "covered neurons percentage 14888 neurons 0.607, 16168 neurons 0.584, 94123 neurons 0.827\n",
            "averaged covered neurons 0.769\n",
            "2\n",
            "ILSVRC2012_test_00001869.JPEG\n",
            "(67, 137)\n",
            "input already causes different outputs: bannister, bannister, pole\n",
            "covered neurons percentage 14888 neurons 0.607, 16168 neurons 0.584, 94123 neurons 0.827\n",
            "averaged covered neurons 0.769\n",
            "3\n",
            "ILSVRC2012_test_00001733.JPEG\n",
            "(71, 43)\n",
            "4\n",
            "ILSVRC2012_test_00001567.JPEG\n",
            "(77, 122)\n",
            "5\n",
            "ILSVRC2012_test_00001739.JPEG\n",
            "(0, 164)\n",
            "6\n",
            "ILSVRC2012_test_00001810.JPEG\n",
            "(136, 86)\n",
            "7\n",
            "ILSVRC2012_test_00001288.JPEG\n",
            "(164, 0)\n",
            "input already causes different outputs: convertible, sports_car, convertible\n",
            "covered neurons percentage 14888 neurons 0.607, 16168 neurons 0.584, 94123 neurons 0.827\n",
            "averaged covered neurons 0.769\n",
            "8\n",
            "ILSVRC2012_test_00001514.JPEG\n",
            "(164, 145)\n",
            "9\n",
            "ILSVRC2012_test_00001490.JPEG\n",
            "(97, 0)\n",
            "10\n",
            "ILSVRC2012_test_00001902.JPEG\n",
            "(104, 43)\n",
            "averaged covered neurons 0.769\n",
            "/content/gdrive/My Drive/ColabNotebooks/test4ai/output/occl_dragonfly_ringlet_ringlet.png\n",
            "/content/gdrive/My Drive/ColabNotebooks/test4ai/output/occl_dragonfly_ringlet_ringlet_orig.png\n",
            "11\n",
            "ILSVRC2012_test_00001549.JPEG\n",
            "(104, 55)\n",
            "averaged covered neurons 0.770\n",
            "/content/gdrive/My Drive/ColabNotebooks/test4ai/output/occl_abacus_parachute_parachute.png\n",
            "/content/gdrive/My Drive/ColabNotebooks/test4ai/output/occl_abacus_parachute_parachute_orig.png\n",
            "12\n",
            "ILSVRC2012_test_00001955.JPEG\n",
            "(0, 80)\n",
            "input already causes different outputs: vault, vault, altar\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}