{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "DeepXplore_base.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isshii/de4test/blob/test_ozawa/DeepXplore/DeepXplore_03_06_coverage_dependence_per_neuron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHbF5GaCQlkP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGVFjZpUIRF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 共通で使うパスなどの定義\n",
        "# 共通の変数設定\n",
        "# 共通フォルダパス\n",
        "\n",
        "import datetime\n",
        "import pytz\n",
        "dt_now = datetime.datetime.now(pytz.timezone('Asia/Tokyo'))\n",
        "dt_str = str(dt_now.strftime('%Y%m%d_%H%M'))\n",
        "\n",
        "data_dir = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/data\"\n",
        "#data_imagenet = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/data/ImageNet\"\n",
        "data_mnist = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/data/MNIST\"\n",
        "#data_imagenet_seeds = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/data/ImageNet/seeds\"\n",
        "model_dir = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/model\"\n",
        "#output_dir = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/output\"\n",
        "output_dir = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/output/\" + dt_str\n",
        "tmp_dir = \"/content/gdrive/My Drive/ColabNotebooks/test4ai/tmp\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4lP4POGn5Xj",
        "colab_type": "code",
        "outputId": "8c0e1c9d-a214-4d62-94af-dabca0665f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Goggle Drive つなぐ\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3d3Suv3Q5Db",
        "colab_type": "code",
        "outputId": "18d8d0e6-6906-40e2-ffd5-2dd4bdf968fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# outputフォルダ内容物のクリーンアップ削除\n",
        "!mkdir \"$output_dir\"\n",
        "!rm \"$output_dir\"/*"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/gdrive/My Drive/ColabNotebooks/test4ai/output/20191226_2228/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhdHYnLT0Nbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/ColabNotebooks/test4ai/model/MNIST')\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDY8sDVBqxmK",
        "colab_type": "code",
        "outputId": "dadb51a1-e499-449c-e873-2f0d9580632c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import argparse\n",
        "import pandas as pd\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input\n",
        "import imageio\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Input, Dense, Activation, Flatten\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "import os"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiGGwQVElJNH",
        "colab_type": "code",
        "outputId": "55076a88-c5bd-4543-9f5d-4010f49a1d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 14640310725190579065, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 8778016146651625765\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 4263123365289240808\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15956161332\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 8119542745455481165\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWQ2M_8glJNM",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "04841f64-cfcd-4489-8886-e162bf2e33d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title デフォルトのタイトル テキスト\n",
        "# DeepXplore のパラメータ設定部\n",
        "# read the parameter\n",
        "# argument parsing\n",
        "parser = argparse.ArgumentParser(description='Main function for difference-inducing input generation in MNIST dataset')\n",
        "parser.add_argument('transformation', help=\"realistic transformation type\", choices=['light', 'occl', 'blackout'])\n",
        "parser.add_argument('weight_diff', help=\"weight hyperparm to control differential behavior\", type=float)\n",
        "parser.add_argument('weight_nc', help=\"weight hyperparm to control neuron coverage\", type=float)\n",
        "parser.add_argument('step', help=\"step size of gradient descent\", type=float)\n",
        "parser.add_argument('seeds', help=\"number of seeds of input\", type=int)\n",
        "parser.add_argument('grad_iterations', help=\"number of iterations of gradient descent\", type=int)\n",
        "parser.add_argument('threshold', help=\"threshold for determining neuron activated\", type=float)\n",
        "parser.add_argument('-t', '--target_model', help=\"target model that we want it predicts differently\",\n",
        "                    choices=[0, 1, 2], default=0, type=int)\n",
        "parser.add_argument('-sp', '--start_point', help=\"occlusion upper left corner coordinate\", default=(0, 0), type=tuple)\n",
        "parser.add_argument('-occl_size', '--occlusion_size', help=\"occlusion size\", default=(10, 10), type=tuple)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['-occl_size', '--occlusion_size'], dest='occlusion_size', nargs=None, const=None, default=(10, 10), type=<class 'tuple'>, choices=None, help='occlusion size', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Csx_IXrMdMj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93KW-VGjMzun",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title ノイズのタイプ light / occl / blackout\n",
        "#@body {light,occl,blackout} weight_diff weight_nc step seeds\n",
        "#                   grad_iterations threshold\n",
        "noise_type = \"light\" #@param [\"light\", \"occl\", \"blackout\"]\n",
        "weight_diff = \"0.1\" #@param {type:\"string\"}\n",
        "weight_nc = \"0.1\" #@param {type:\"string\"}\n",
        "step = \"20\" #@param {type:\"string\"}　#50だとほぼ白飛び\n",
        "seeds = \"100\" #@param {type:\"string\"}\n",
        "grad_iterations = \"10\" #@param {type:\"string\"}\n",
        "threshold = \"0.1\" #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szk80fCuPts9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = parser.parse_args([noise_type, weight_diff, weight_nc, step, seeds, grad_iterations, threshold])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tTYrllplJNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    x *= 255\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x.reshape(x.shape[1], x.shape[2])  # original shape (1,img_rows, img_cols,1)\n",
        "\n",
        "\n",
        "def normalize(x):\n",
        "    # utility function to normalize a tensor by its L2 norm\n",
        "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
        "\n",
        "\n",
        "def constraint_occl(gradients, start_point, rect_shape):\n",
        "    new_grads = np.zeros_like(gradients)\n",
        "    new_grads[:, start_point[0]:start_point[0] + rect_shape[0],\n",
        "    start_point[1]:start_point[1] + rect_shape[1]] = gradients[:, start_point[0]:start_point[0] + rect_shape[0],\n",
        "                                                     start_point[1]:start_point[1] + rect_shape[1]]\n",
        "    return new_grads\n",
        "\n",
        "\n",
        "def constraint_light(gradients):\n",
        "    new_grads = np.ones_like(gradients)\n",
        "    grad_mean = np.mean(gradients)\n",
        "    return grad_mean * new_grads\n",
        "\n",
        "\n",
        "def constraint_black(gradients, rect_shape=(6, 6)):\n",
        "    start_point = (\n",
        "        random.randint(0, gradients.shape[1] - rect_shape[0]), random.randint(0, gradients.shape[2] - rect_shape[1]))\n",
        "    new_grads = np.zeros_like(gradients)\n",
        "    patch = gradients[:, start_point[0]:start_point[0] + rect_shape[0], start_point[1]:start_point[1] + rect_shape[1]]\n",
        "    if np.mean(patch) < 0:\n",
        "        new_grads[:, start_point[0]:start_point[0] + rect_shape[0],\n",
        "        start_point[1]:start_point[1] + rect_shape[1]] = -np.ones_like(patch)\n",
        "    return new_grads\n",
        "\n",
        "\n",
        "def init_coverage_tables(model1, model2, model3):\n",
        "    model_layer_dict1 = defaultdict(bool)\n",
        "    model_layer_dict2 = defaultdict(bool)\n",
        "    model_layer_dict3 = defaultdict(bool)\n",
        "    init_dict(model1, model_layer_dict1)\n",
        "    init_dict(model2, model_layer_dict2)\n",
        "    init_dict(model3, model_layer_dict3)\n",
        "    return model_layer_dict1, model_layer_dict2, model_layer_dict3\n",
        "\n",
        "\n",
        "def init_dict(model, model_layer_dict):\n",
        "    for layer in model.layers:\n",
        "        if 'flatten' in layer.name or 'input' in layer.name:\n",
        "            continue\n",
        "        for index in range(layer.output_shape[-1]):\n",
        "            model_layer_dict[(layer.name, index)] = False\n",
        "\n",
        "\n",
        "def neuron_to_cover(model_layer_dict):\n",
        "    not_covered = [(layer_name, index) for (layer_name, index), v in model_layer_dict.items() if not v]\n",
        "    if not_covered:\n",
        "        layer_name, index = random.choice(not_covered)\n",
        "    else:\n",
        "        layer_name, index = random.choice(model_layer_dict.keys())\n",
        "    return layer_name, index\n",
        "\n",
        "\n",
        "def neuron_covered(model_layer_dict):\n",
        "    covered_neurons = len([v for v in model_layer_dict.values() if v])\n",
        "    total_neurons = len(model_layer_dict)\n",
        "    return covered_neurons, total_neurons, covered_neurons / float(total_neurons)\n",
        "\n",
        "\n",
        "def update_coverage(input_data, model, model_layer_dict, threshold=0):\n",
        "    layer_names = [layer.name for layer in model.layers if\n",
        "                   'flatten' not in layer.name and 'input' not in layer.name]\n",
        "\n",
        "    intermediate_layer_model = Model(inputs=model.input,\n",
        "                                     outputs=[model.get_layer(layer_name).output for layer_name in layer_names])\n",
        "    intermediate_layer_outputs = intermediate_layer_model.predict(input_data)\n",
        "\n",
        "    for i, intermediate_layer_output in enumerate(intermediate_layer_outputs):\n",
        "        scaled = scale(intermediate_layer_output[0])\n",
        "        for num_neuron in range(scaled.shape[-1]):\n",
        "            if np.mean(scaled[..., num_neuron]) > threshold and not model_layer_dict[(layer_names[i], num_neuron)]:\n",
        "                model_layer_dict[(layer_names[i], num_neuron)] = True\n",
        "\n",
        "\n",
        "def full_coverage(model_layer_dict):\n",
        "    if False in model_layer_dict.values():\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def scale(intermediate_layer_output, rmax=1, rmin=0):\n",
        "    X_std = (intermediate_layer_output - intermediate_layer_output.min()) / (\n",
        "        intermediate_layer_output.max() - intermediate_layer_output.min())\n",
        "    X_scaled = X_std * (rmax - rmin) + rmin\n",
        "    return X_scaled\n",
        "\n",
        "\n",
        "def fired(model, layer_name, index, input_data, threshold=0):\n",
        "    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "    intermediate_layer_output = intermediate_layer_model.predict(input_data)[0]\n",
        "    scaled = scale(intermediate_layer_output)\n",
        "    if np.mean(scaled[..., index]) > threshold:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def diverged(predictions1, predictions2, predictions3, target):\n",
        "    #     if predictions2 == predictions3 == target and predictions1 != target:\n",
        "    if not predictions1 == predictions2 == predictions3:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "#add\n",
        "def list_pictures(directory, ext='jpg|jpeg|bmp|png|ppm'):\n",
        "    return [os.path.join(root, f)\n",
        "            for root, _, files in os.walk(directory) for f in files\n",
        "            if re.match(r'([\\w]+\\.(?:' + ext + '))', f.lower())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoRphb5Fl0JT",
        "colab_type": "code",
        "outputId": "a2d3785b-a9f4-430d-a900-5a53443c4314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "# the data, shuffled and split between train and test sets\n",
        "(_, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "\n",
        "# define input tensor as a placeholder\n",
        "input_tensor = Input(shape=input_shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDDT47Er6u23",
        "colab_type": "code",
        "outputId": "30a9cfa5-51b0-42af-cbbe-6fcfaa9fed23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "'''\n",
        "LeNet-1\n",
        "'''\n",
        "def Model1(input_tensor=None, train=False):\n",
        "    nb_classes = 10\n",
        "    # convolution kernel size\n",
        "    kernel_size = (5, 5)\n",
        "\n",
        "    if train:\n",
        "        batch_size = 256\n",
        "        nb_epoch = 10\n",
        "\n",
        "        # input image dimensions\n",
        "        img_rows, img_cols = 28, 28\n",
        "\n",
        "        # the data, shuffled and split between train and test sets\n",
        "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "        print(x_train.shape)\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "        x_train /= 255\n",
        "        x_test /= 255\n",
        "\n",
        "        # convert class vectors to binary class matrices\n",
        "        y_train = to_categorical(y_train, nb_classes)\n",
        "        y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "        input_tensor = Input(shape=input_shape)\n",
        "    elif input_tensor is None:\n",
        "        print(bcolors.FAIL + 'you have to proved input_tensor when testing')\n",
        "        exit()\n",
        "\n",
        "    # block1\n",
        "    x = Convolution2D(4, kernel_size, activation='relu', padding='same', name='block1_conv1')(input_tensor)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), name='block1_pool1')(x)\n",
        "\n",
        "    # block2\n",
        "    x = Convolution2D(12, kernel_size, activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), name='block2_pool1')(x)\n",
        "\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(nb_classes, name='before_softmax')(x)\n",
        "    x = Activation('softmax', name='predictions')(x)\n",
        "\n",
        "    model = Model(input_tensor, x)\n",
        "\n",
        "    if train:\n",
        "        # compiling\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "\n",
        "        # trainig\n",
        "        model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=nb_epoch, verbose=1)\n",
        "        # save model\n",
        "#        model.save_weights('./Model1.h5')\n",
        "        model.save_weights('/content/gdrive/My Drive/ColabNotebooks/test4ai/model/MNIST/Model1.h5')\n",
        "        score = model.evaluate(x_test, y_test, verbose=0)\n",
        "        print('\\n')\n",
        "        print('Overall Test score:', score[0])\n",
        "        print('Overall Test accuracy:', score[1])\n",
        "    else:\n",
        "#        model.load_weights('./Model1.h5')\n",
        "        model.load_weights('/content/gdrive/My Drive/ColabNotebooks/test4ai/model/MNIST/Model1.h5')\n",
        "        print(bcolors.OKBLUE + 'Model1 loaded' + bcolors.ENDC)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    Model1(train=True)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.4919 - acc: 0.8460 - val_loss: 0.1298 - val_acc: 0.9600\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.1175 - acc: 0.9648 - val_loss: 0.1032 - val_acc: 0.9688\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.0851 - acc: 0.9740 - val_loss: 0.0660 - val_acc: 0.9794\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.0699 - acc: 0.9792 - val_loss: 0.0614 - val_acc: 0.9806\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0606 - acc: 0.9819 - val_loss: 0.0533 - val_acc: 0.9829\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0544 - acc: 0.9836 - val_loss: 0.0560 - val_acc: 0.9818\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.0505 - acc: 0.9852 - val_loss: 0.0511 - val_acc: 0.9830\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0463 - acc: 0.9858 - val_loss: 0.0566 - val_acc: 0.9819\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 21us/step - loss: 0.0432 - acc: 0.9868 - val_loss: 0.0496 - val_acc: 0.9828\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.0409 - acc: 0.9874 - val_loss: 0.0471 - val_acc: 0.9846\n",
            "\n",
            "\n",
            "Overall Test score: 0.047055332215712405\n",
            "Overall Test accuracy: 0.9846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU88awZf68JO",
        "colab_type": "code",
        "outputId": "914997dd-297c-4677-c558-ab18d71f05ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "'''\n",
        "LeNet-4\n",
        "'''\n",
        "def Model2(input_tensor=None, train=False):\n",
        "    nb_classes = 10\n",
        "    # convolution kernel size\n",
        "    kernel_size = (5, 5)\n",
        "\n",
        "    if train:\n",
        "        batch_size = 256\n",
        "        nb_epoch = 10\n",
        "\n",
        "        # input image dimensions\n",
        "        img_rows, img_cols = 28, 28\n",
        "\n",
        "        # the data, shuffled and split between train and test sets\n",
        "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "        x_train /= 255\n",
        "        x_test /= 255\n",
        "\n",
        "        # convert class vectors to binary class matrices\n",
        "        y_train = to_categorical(y_train, nb_classes)\n",
        "        y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "        input_tensor = Input(shape=input_shape)\n",
        "    elif input_tensor is None:\n",
        "        print(bcolors.FAIL + 'you have to proved input_tensor when testing')\n",
        "        exit()\n",
        "\n",
        "    # block1\n",
        "    x = Convolution2D(6, kernel_size, activation='relu', padding='same', name='block1_conv1')(input_tensor)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), name='block1_pool1')(x)\n",
        "\n",
        "    # block2\n",
        "    x = Convolution2D(16, kernel_size, activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), name='block2_pool1')(x)\n",
        "\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(84, activation='relu', name='fc1')(x)\n",
        "    x = Dense(nb_classes, name='before_softmax')(x)\n",
        "    x = Activation('softmax', name='predictions')(x)\n",
        "\n",
        "    model = Model(input_tensor, x)\n",
        "\n",
        "    if train:\n",
        "        # compiling\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "\n",
        "        # trainig\n",
        "        model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=nb_epoch, verbose=1)\n",
        "        # save model\n",
        "        model.save_weights('./Model2.h5')\n",
        "        score = model.evaluate(x_test, y_test, verbose=0)\n",
        "        print('\\n')\n",
        "        print('Overall Test score:', score[0])\n",
        "        print('Overall Test accuracy:', score[1])\n",
        "    else:\n",
        "        model.load_weights('./Model2.h5')\n",
        "        print(bcolors.OKBLUE + 'Model2 loaded' + bcolors.ENDC)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    Model2(train=True)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.3593 - acc: 0.8900 - val_loss: 0.0933 - val_acc: 0.9729\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0810 - acc: 0.9755 - val_loss: 0.0681 - val_acc: 0.9789\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0587 - acc: 0.9819 - val_loss: 0.0945 - val_acc: 0.9684\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0467 - acc: 0.9853 - val_loss: 0.0479 - val_acc: 0.9845\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0402 - acc: 0.9877 - val_loss: 0.0381 - val_acc: 0.9861\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0334 - acc: 0.9897 - val_loss: 0.0447 - val_acc: 0.9846\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0293 - acc: 0.9907 - val_loss: 0.0389 - val_acc: 0.9874\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0251 - acc: 0.9920 - val_loss: 0.0335 - val_acc: 0.9895\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0217 - acc: 0.9933 - val_loss: 0.0317 - val_acc: 0.9900\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0190 - acc: 0.9937 - val_loss: 0.0289 - val_acc: 0.9911\n",
            "\n",
            "\n",
            "Overall Test score: 0.028897808011685264\n",
            "Overall Test accuracy: 0.9911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufs67uRN7KYL",
        "colab_type": "code",
        "outputId": "9fce1255-10c4-4a76-c70b-8ab6eecfd6e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "'''\n",
        "LeNet-5\n",
        "'''\n",
        "def Model3(input_tensor=None, train=False):\n",
        "    nb_classes = 10\n",
        "    # convolution kernel size\n",
        "    kernel_size = (5, 5)\n",
        "\n",
        "    if train:\n",
        "        batch_size = 256\n",
        "        nb_epoch = 10\n",
        "\n",
        "        # input image dimensions\n",
        "        img_rows, img_cols = 28, 28\n",
        "\n",
        "        # the data, shuffled and split between train and test sets\n",
        "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "        x_train /= 255\n",
        "        x_test /= 255\n",
        "\n",
        "        # convert class vectors to binary class matrices\n",
        "        y_train = to_categorical(y_train, nb_classes)\n",
        "        y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "        input_tensor = Input(shape=input_shape)\n",
        "    elif input_tensor is None:\n",
        "        print(bcolors.FAIL + 'you have to proved input_tensor when testing')\n",
        "        exit()\n",
        "\n",
        "    # block1\n",
        "    x = Convolution2D(6, kernel_size, activation='relu', padding='same', name='block1_conv1')(input_tensor)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), name='block1_pool1')(x)\n",
        "\n",
        "    # block2\n",
        "    x = Convolution2D(16, kernel_size, activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), name='block2_pool1')(x)\n",
        "\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(120, activation='relu', name='fc1')(x)\n",
        "    x = Dense(84, activation='relu', name='fc2')(x)\n",
        "    x = Dense(nb_classes, name='before_softmax')(x)\n",
        "    x = Activation('softmax', name='predictions')(x)\n",
        "\n",
        "    model = Model(input_tensor, x)\n",
        "\n",
        "    if train:\n",
        "        # compiling\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "\n",
        "        # trainig\n",
        "        model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=nb_epoch, verbose=1)\n",
        "        # save model\n",
        "        model.save_weights('./Model3.h5')\n",
        "        score = model.evaluate(x_test, y_test, verbose=0)\n",
        "        print('\\n')\n",
        "        print('Overall Test score:', score[0])\n",
        "        print('Overall Test accuracy:', score[1])\n",
        "    else:\n",
        "        model.load_weights('./Model3.h5')\n",
        "        print(bcolors.OKBLUE + 'Model3 loaded' + bcolors.ENDC)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    Model3(train=True)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.3843 - acc: 0.8777 - val_loss: 0.1173 - val_acc: 0.9606\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0791 - acc: 0.9750 - val_loss: 0.0555 - val_acc: 0.9817\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0558 - acc: 0.9823 - val_loss: 0.0481 - val_acc: 0.9845\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0424 - acc: 0.9863 - val_loss: 0.0396 - val_acc: 0.9863\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0333 - acc: 0.9894 - val_loss: 0.0362 - val_acc: 0.9873\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0284 - acc: 0.9911 - val_loss: 0.0672 - val_acc: 0.9779\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0240 - acc: 0.9924 - val_loss: 0.0314 - val_acc: 0.9901\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0203 - acc: 0.9932 - val_loss: 0.0634 - val_acc: 0.9792\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0171 - acc: 0.9943 - val_loss: 0.0436 - val_acc: 0.9860\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0143 - acc: 0.9954 - val_loss: 0.0397 - val_acc: 0.9877\n",
            "\n",
            "\n",
            "Overall Test score: 0.03968658735411009\n",
            "Overall Test accuracy: 0.9877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K9QiwlW7WWR",
        "colab_type": "code",
        "outputId": "cb31e4be-ea28-4e8a-9eac-fbd01ac70eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model1 = Model1(input_tensor=input_tensor)\n",
        "model2 = Model2(input_tensor=input_tensor)\n",
        "model3 = Model3(input_tensor=input_tensor)\n",
        "model_layer_dict1, model_layer_dict2, model_layer_dict3 = init_coverage_tables(model1, model2, model3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[94mModel1 loaded\u001b[0m\n",
            "\u001b[94mModel2 loaded\u001b[0m\n",
            "\u001b[94mModel3 loaded\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD6cHroNl43Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start gen inputs\n",
        "# img_paths = list_pictures(data_imagenet_seeds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brFIdSfL8nHP",
        "colab_type": "code",
        "outputId": "ffebb161-2d5e-4374-db95-86d9b105d4ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "test_per_fig_x = np.array([])\n",
        "test_per_fig_y = np.array([])\n",
        "tests_x = np.array([])\n",
        "tests_y = np.array([])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "#x_train = x_train.astype('float')\n",
        "#x_test = x_test.astype('float')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "length = int(args.seeds/10)\n",
        "for i in range(10):\n",
        "  cond = [(x==i) for x in y_test]\n",
        "  test_per_fig_x = x_test[cond]\n",
        "  test_per_fig_y = y_test[cond]\n",
        "  print(i, test_per_fig_x.shape, test_per_fig_x.shape[0]-1000)\n",
        "  tests_x = np.append(tests_x, test_per_fig_x[:length])\n",
        "  tests_y = np.append(tests_y, test_per_fig_y[:length])\n",
        "#  conds = [conds, cond]\n",
        "print(\"check!\", tests_x.shape[0]/28/28/10, \"=\", length, \"equal?\")\n",
        "tests_x = tests_x.reshape(-1,28,28,1)\n",
        "#tests_x = tests_x.reshape(-1,1,28,28,1,)\n",
        "tests_x.shape\n",
        "tests_x = tests_x.astype('float32')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 (980, 28, 28) -20\n",
            "1 (1135, 28, 28) 135\n",
            "2 (1032, 28, 28) 32\n",
            "3 (1010, 28, 28) 10\n",
            "4 (982, 28, 28) -18\n",
            "5 (892, 28, 28) -108\n",
            "6 (958, 28, 28) -42\n",
            "7 (1028, 28, 28) 28\n",
            "8 (974, 28, 28) -26\n",
            "9 (1009, 28, 28) 9\n",
            "check! 10.0 = 10 equal?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyo2SSSz8vkT",
        "colab_type": "code",
        "outputId": "b9de504f-e545-45eb-c0f8-e932d11859b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkfdTZi4mUPf",
        "colab_type": "code",
        "outputId": "121d1709-d295-4dc6-ec08-bdadf7e3b69e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "def neuron_output(input_data, model, model_layer_dict, threshold=0):\n",
        "    layer_names = [layer.name for layer in model.layers if\n",
        "                   'flatten' not in layer.name and 'input' not in layer.name]\n",
        "\n",
        "    intermediate_layer_model = Model(inputs=model.input,\n",
        "                                     outputs=[model.get_layer(layer_name).output for layer_name in layer_names])\n",
        "    intermediate_layer_outputs = intermediate_layer_model.predict(input_data)\n",
        "    \n",
        "    out_list = []\n",
        "    out_list_scale = []\n",
        "    for i, intermediate_layer_output in enumerate(intermediate_layer_outputs):\n",
        "        scaled = scale(intermediate_layer_output[0])\n",
        "        for num_neuron in range(scaled.shape[-1]):\n",
        "            out_list.append(np.mean(intermediate_layer_output[..., num_neuron]))\n",
        "            out_list_scale.append(np.mean(scaled[..., num_neuron]))\n",
        "\n",
        "    return out_list, out_list_scale\n",
        "\n",
        "\n",
        "count_already = 0\n",
        "count_found = 0\n",
        "count_not_found = 0\n",
        "temp_per_nc1 = np.array([])\n",
        "temp_per_nc2 = np.array([])\n",
        "temp_per_nc3 = np.array([])\n",
        "temp_num_nc1 = np.array([])\n",
        "temp_num_nc2 = np.array([])\n",
        "temp_num_nc3 = np.array([])\n",
        "\n",
        "#for each neuron\n",
        "num_neurons1 = neuron_covered(model_layer_dict1)[1]\n",
        "num_neurons2 = neuron_covered(model_layer_dict2)[1]\n",
        "num_neurons3 = neuron_covered(model_layer_dict3)[1]\n",
        "\n",
        "column_tmp1 = list(model_layer_dict1.keys())\n",
        "column_tmp2 = list(model_layer_dict2.keys())\n",
        "column_tmp3 = list(model_layer_dict3.keys())\n",
        "df1 = pd.DataFrame(columns=column_tmp1)\n",
        "df2 = pd.DataFrame(columns=column_tmp2)\n",
        "df3 = pd.DataFrame(columns=column_tmp3)\n",
        "df1_scale = pd.DataFrame(columns=column_tmp1)\n",
        "df2_scale = pd.DataFrame(columns=column_tmp2)\n",
        "df3_scale = pd.DataFrame(columns=column_tmp3)\n",
        "trial = 0\n",
        "\n",
        "for index_fig in range(10):\n",
        "  print(\"figure\"+str(index_fig))\n",
        "  for _ in range(length):\n",
        "      #gen_img = np.expand_dims(random.choice(tests_x), axis=0)\n",
        "      gen_img = np.expand_dims(tests_x[(length*index_fig + _)], axis=0)\n",
        "      orig_img = gen_img.copy()\n",
        "      # first check if input already induces differences\n",
        "      label1, label2, label3 = np.argmax(model1.predict(gen_img)[0]), np.argmax(model2.predict(gen_img)[0]), np.argmax(model3.predict(gen_img)[0])\n",
        "\n",
        "      if not label1 == label2 == label3:\n",
        "          count_already += 1\n",
        "          print(bcolors.OKGREEN + '{}/{}. input already causes different outputs ({},{},{}) at{}/{}: '.format(_, length, label1, label2, label3, count_already, count_already + count_found + count_not_found) + bcolors.ENDC)        \n",
        "          #print(bcolors.OKGREEN + '{}/{}. input already causes different outputs ({},{},{}) at{}/{}: '.format(_, length, label1, label2, label3, count_already, count_already + count_found + count_not_found) + bcolors.ENDC)        \n",
        "\n",
        "          update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "          update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "          update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "\n",
        "          temp_per_nc1=np.append(temp_per_nc1,  neuron_covered(model_layer_dict1)[2])\n",
        "          temp_per_nc2=np.append(temp_per_nc2,  neuron_covered(model_layer_dict2)[2])\n",
        "          temp_per_nc3=np.append(temp_per_nc3,  neuron_covered(model_layer_dict3)[2])\n",
        "          temp_num_nc1=np.append(temp_num_nc1,  neuron_covered(model_layer_dict1)[0])\n",
        "          temp_num_nc2=np.append(temp_num_nc2,  neuron_covered(model_layer_dict2)[0])\n",
        "          temp_num_nc3=np.append(temp_num_nc3,  neuron_covered(model_layer_dict3)[0])\n",
        "                               \n",
        "          print(bcolors.OKGREEN + '     covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'% (len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
        "                  neuron_covered(model_layer_dict2)[2], len(model_layer_dict3), neuron_covered(model_layer_dict3)[2]) + bcolors.ENDC)\n",
        "          averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                       neuron_covered(model_layer_dict3)[0]) / float(neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +neuron_covered(model_layer_dict3)[1])\n",
        "          print(bcolors.OKGREEN + '     averaged covered neurons %.3f' % (averaged_nc) + bcolors.ENDC)\n",
        "\n",
        "          gen_img_deprocessed = deprocess_image(gen_img)\n",
        "\n",
        "          # save the result to disk\n",
        "          outputfilepath0 = os.path.join(output_dir, 'already_differ_' + str(label1) + '_' + str(label2) + '_' + str(label3) +'_['+ str(_) +  '].png')\n",
        "          imageio.imwrite(outputfilepath0, gen_img_deprocessed)\n",
        "\n",
        "          temp, temp_scale = neuron_output(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "          temp = pd.Series(temp, index=df1.columns, name=str(trial))\n",
        "          temp_scale = pd.Series(temp_scale, index=df1.columns, name=str(trial))\n",
        "          df1 = df1.append(temp)\n",
        "          df1_scale = df1_scale.append(temp_scale)\n",
        "\n",
        "          temp, temp_scale = neuron_output(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "          temp = pd.Series(temp, index=df2.columns, name=str(trial))\n",
        "          temp_scale = pd.Series(temp_scale, index=df2.columns, name=str(trial))\n",
        "          df2 = df2.append(temp)\n",
        "          df2_scale = df2_scale.append(temp_scale)\n",
        "\n",
        "          temp, temp_scale = neuron_output(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "          temp = pd.Series(temp, index=df3.columns, name=str(trial))\n",
        "          temp_scale = pd.Series(temp_scale, index=df3.columns, name=str(trial))\n",
        "\n",
        "          df3 = df3.append(temp)\n",
        "          df3_scale = df3_scale.append(temp_scale)\n",
        "\n",
        "          trial += 1\n",
        "          continue\n",
        "\n",
        "      # if all label agrees\n",
        "      orig_label = label1\n",
        "      layer_name1, index1 = neuron_to_cover(model_layer_dict1)\n",
        "      layer_name2, index2 = neuron_to_cover(model_layer_dict2)\n",
        "      layer_name3, index3 = neuron_to_cover(model_layer_dict3)\n",
        "\n",
        "      # construct joint loss function\n",
        "      if args.target_model == 0:\n",
        "        loss1 = -args.weight_diff * K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss2 = K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss3 = K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n",
        "      elif args.target_model == 1:\n",
        "        loss1 = K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss2 = -args.weight_diff * K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss3 = K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n",
        "      elif args.target_model == 2:\n",
        "        loss1 = K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss2 = K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n",
        "        loss3 = -args.weight_diff * K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n",
        "      loss1_neuron = K.mean(model1.get_layer(layer_name1).output[..., index1])\n",
        "      loss2_neuron = K.mean(model2.get_layer(layer_name2).output[..., index2])\n",
        "      loss3_neuron = K.mean(model3.get_layer(layer_name3).output[..., index3])\n",
        "      layer_output = (loss1 + loss2 + loss3) + args.weight_nc * (loss1_neuron + loss2_neuron + loss3_neuron)\n",
        "\n",
        "      # for adversarial image generation\n",
        "      final_loss = K.mean(layer_output)\n",
        "\n",
        "      # we compute the gradient of the input picture wrt this loss\n",
        "      grads = normalize(K.gradients(final_loss, input_tensor)[0])\n",
        "\n",
        "      # this function returns the loss and grads given the input picture\n",
        "      iterate = K.function([input_tensor], [loss1, loss2, loss3, loss1_neuron, loss2_neuron, loss3_neuron, grads])\n",
        "\n",
        "      # we run gradient ascent for some steps\n",
        "      for iters in range(args.grad_iterations):\n",
        "        loss_value1, loss_value2, loss_value3, loss_neuron1, loss_neuron2, loss_neuron3, grads_value = iterate(\n",
        "            [gen_img])\n",
        "        if args.transformation == 'light':\n",
        "            grads_value = constraint_light(grads_value)  # constraint the gradients value\n",
        "        elif args.transformation == 'occl':\n",
        "            grads_value = constraint_occl(grads_value, args.start_point,\n",
        "                                          args.occlusion_size)  # constraint the gradients value\n",
        "        elif args.transformation == 'blackout':\n",
        "            grads_value = constraint_black(grads_value)  # constraint the gradients value\n",
        "\n",
        "        gen_img += grads_value * args.step\n",
        "        predictions1 = np.argmax(model1.predict(gen_img)[0])\n",
        "        predictions2 = np.argmax(model2.predict(gen_img)[0])\n",
        "        predictions3 = np.argmax(model3.predict(gen_img)[0])\n",
        "\n",
        "        if not predictions1 == predictions2 == predictions3:\n",
        "            update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "            update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "            update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "            count_found += 1\n",
        "            print(bcolors.OKBLUE + '%4d/%d. found at %d! covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f at %d/%d'\n",
        "#                  % (_, args.seeds, iters, len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
        "                  % (_, length, iters, len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n",
        "                     neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n",
        "                     neuron_covered(model_layer_dict3)[2], count_found, count_already + count_found + count_not_found) + bcolors.ENDC)\n",
        "            averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                           neuron_covered(model_layer_dict3)[0]) / float(\n",
        "                neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "                neuron_covered(model_layer_dict3)[1])\n",
        "            print(bcolors.OKBLUE + '     averaged covered neurons %.3f' % averaged_nc + bcolors.ENDC)\n",
        "\n",
        "            gen_img_deprocessed = deprocess_image(gen_img)\n",
        "            orig_img_deprocessed = deprocess_image(orig_img)\n",
        "\n",
        "            # save the result to disk\n",
        "            #outputfilepath = os.path.join(output_dir, args.transformation + '_' + str(label1) + '_' + str(label2) + '_' + str(label3) + '.png')\n",
        "            outputfilepath = os.path.join(output_dir, args.transformation + '_from' + str(label1) + '_to' + str(predictions1) + '_'  + str(predictions2) + '_' + str(predictions3) +'_['+ str(_) +  '].png')\n",
        "            #print(outputfilepath)\n",
        "            imageio.imwrite(outputfilepath, gen_img_deprocessed)\n",
        "#            outputfilepath2 = os.path.join(output_dir, args.transformation + '_' + str(label1) + '_' + str(label2) + '_' + str(label3) + '_orig.png')\n",
        "            outputfilepath2 = os.path.join(output_dir, args.transformation + '_from' + str(label1) + '_to' + str(predictions1) + '_'  + str(predictions2) + '_' + str(predictions3) +'_['+ str(_) +  ']_orig.png')\n",
        "            #print(outputfilepath2)\n",
        "            imageio.imwrite(outputfilepath2, orig_img_deprocessed)\n",
        "            temp_per_nc1=np.append(temp_per_nc1,  neuron_covered(model_layer_dict1)[2])\n",
        "            temp_per_nc2=np.append(temp_per_nc2,  neuron_covered(model_layer_dict2)[2])\n",
        "            temp_per_nc3=np.append(temp_per_nc3,  neuron_covered(model_layer_dict3)[2])\n",
        "            temp_num_nc1=np.append(temp_num_nc1,  neuron_covered(model_layer_dict1)[0])\n",
        "            temp_num_nc2=np.append(temp_num_nc2,  neuron_covered(model_layer_dict2)[0])\n",
        "            temp_num_nc3=np.append(temp_num_nc3,  neuron_covered(model_layer_dict3)[0])\n",
        "\n",
        "            temp, temp_scale = neuron_output(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "            temp = pd.Series(temp, index=df1.columns, name=str(trial))\n",
        "            temp_scale = pd.Series(temp_scale, index=df1.columns, name=str(trial))\n",
        "            df1 = df1.append(temp)\n",
        "            df1_scale = df1_scale.append(temp_scale)\n",
        "\n",
        "            temp, temp_scale = neuron_output(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "            temp = pd.Series(temp, index=df2.columns, name=str(trial))\n",
        "            temp_scale = pd.Series(temp_scale, index=df2.columns, name=str(trial))\n",
        "            df2 = df2.append(temp)\n",
        "            df2_scale = df2_scale.append(temp_scale)\n",
        "\n",
        "            temp, temp_scale = neuron_output(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "            temp = pd.Series(temp, index=df3.columns, name=str(trial))\n",
        "            temp_scale = pd.Series(temp_scale, index=df3.columns, name=str(trial))\n",
        "\n",
        "            df3 = df3.append(temp)\n",
        "            df3_scale = df3_scale.append(temp_scale)\n",
        "\n",
        "            trial += 1\n",
        "            break\n",
        "          \n",
        "          #add\n",
        "        if iters == (args.grad_iterations-1):\n",
        "            update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "            update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "            update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "            averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n",
        "                           neuron_covered(model_layer_dict3)[0]) / float(neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n",
        "                neuron_covered(model_layer_dict3)[1])\n",
        "            count_not_found += 1\n",
        "#              print('%4d/%d. test suite was not found: averaged covered neurons %.3f at %d/%d' % (_, args.seeds, averaged_nc, count_not_found, count_already + count_found + count_not_found))\n",
        "            print('%4d/%d. test suite was not found: averaged covered neurons %.3f at %d/%d' % (_, length, averaged_nc, count_not_found, count_already + count_found + count_not_found))\n",
        "\n",
        "            gen_img_deprocessed = deprocess_image(gen_img)\n",
        "            #orig_img_deprocessed = deprocess_image(orig_img)\n",
        "\n",
        "            # save the result to disk\n",
        "            #outputfilepath = os.path.join(output_dir, args.transformation + '_' + str(label1) + '_' + str(label2) + '_' + str(label3) + '.png')\n",
        "            outputfilepath = os.path.join(output_dir, 'not_found_' + str(label1)+'_['+ str(_) + '].png')\n",
        "#           print(outputfilepath)\n",
        "            imageio.imwrite(outputfilepath, gen_img_deprocessed)\n",
        "\n",
        "            \n",
        "            temp, temp_scale = neuron_output(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "            temp = pd.Series(temp, index=df1.columns, name=str(trial))\n",
        "            temp_scale = pd.Series(temp_scale, index=df1.columns, name=str(trial))\n",
        "            df1 = df1.append(temp)\n",
        "            df1_scale = df1_scale.append(temp_scale)\n",
        "\n",
        "            temp, temp_scale = neuron_output(gen_img, model2, model_layer_dict2, args.threshold)\n",
        "            temp = pd.Series(temp, index=df2.columns, name=str(trial))\n",
        "            temp_scale = pd.Series(temp_scale, index=df2.columns, name=str(trial))\n",
        "            df2 = df2.append(temp)\n",
        "            df2_scale = df2_scale.append(temp_scale)\n",
        "\n",
        "            temp, temp_scale = neuron_output(gen_img, model3, model_layer_dict3, args.threshold)\n",
        "            temp = pd.Series(temp, index=df3.columns, name=str(trial))\n",
        "            temp_scale = pd.Series(temp_scale, index=df3.columns, name=str(trial))\n",
        "\n",
        "            df3 = df3.append(temp)\n",
        "            df3_scale = df3_scale.append(temp_scale)\n",
        "\n",
        "            trial += 1\n",
        "            \n",
        "            #break\n",
        "\n",
        "            temp_per_nc1=np.append(temp_per_nc1,  neuron_covered(model_layer_dict1)[2])\n",
        "            temp_per_nc2=np.append(temp_per_nc2,  neuron_covered(model_layer_dict2)[2])\n",
        "            temp_per_nc3=np.append(temp_per_nc3,  neuron_covered(model_layer_dict3)[2])\n",
        "            temp_num_nc1=np.append(temp_num_nc1,  neuron_covered(model_layer_dict1)[0])\n",
        "            temp_num_nc2=np.append(temp_num_nc2,  neuron_covered(model_layer_dict2)[0])\n",
        "            temp_num_nc3=np.append(temp_num_nc3,  neuron_covered(model_layer_dict3)[0])\n",
        "\n",
        "temp_per_nc1=temp_per_nc1.reshape(10, length)\n",
        "temp_per_nc2=temp_per_nc2.reshape(10, length)\n",
        "temp_per_nc3=temp_per_nc3.reshape(10, length)\n",
        "temp_num_nc1=temp_num_nc1.reshape(10, length)\n",
        "temp_num_nc2=temp_num_nc2.reshape(10, length)\n",
        "temp_num_nc3=temp_num_nc3.reshape(10, length)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "figure0\n",
            "\u001b[94m   0/10. found at 0! covered neurons percentage 52 neurons 0.327, 148 neurons 0.473, 268 neurons 0.444 at 1/1\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.440\u001b[0m\n",
            "\u001b[94m   1/10. found at 1! covered neurons percentage 52 neurons 0.423, 148 neurons 0.561, 268 neurons 0.526 at 2/2\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.526\u001b[0m\n",
            "\u001b[94m   2/10. found at 8! covered neurons percentage 52 neurons 0.481, 148 neurons 0.581, 268 neurons 0.560 at 3/3\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.558\u001b[0m\n",
            "\u001b[94m   3/10. found at 2! covered neurons percentage 52 neurons 0.481, 148 neurons 0.595, 268 neurons 0.575 at 4/4\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.571\u001b[0m\n",
            "\u001b[94m   4/10. found at 0! covered neurons percentage 52 neurons 0.481, 148 neurons 0.608, 268 neurons 0.582 at 5/5\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.579\u001b[0m\n",
            "\u001b[94m   5/10. found at 3! covered neurons percentage 52 neurons 0.481, 148 neurons 0.622, 268 neurons 0.590 at 6/6\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.588\u001b[0m\n",
            "\u001b[94m   6/10. found at 7! covered neurons percentage 52 neurons 0.481, 148 neurons 0.642, 268 neurons 0.612 at 7/7\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.607\u001b[0m\n",
            "\u001b[94m   7/10. found at 3! covered neurons percentage 52 neurons 0.481, 148 neurons 0.642, 268 neurons 0.619 at 8/8\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.611\u001b[0m\n",
            "\u001b[94m   8/10. found at 1! covered neurons percentage 52 neurons 0.827, 148 neurons 0.730, 268 neurons 0.720 at 9/9\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.735\u001b[0m\n",
            "\u001b[94m   9/10. found at 1! covered neurons percentage 52 neurons 0.827, 148 neurons 0.736, 268 neurons 0.735 at 10/10\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.746\u001b[0m\n",
            "figure1\n",
            "\u001b[94m   0/10. found at 1! covered neurons percentage 52 neurons 0.865, 148 neurons 0.764, 268 neurons 0.795 at 11/11\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.793\u001b[0m\n",
            "\u001b[94m   1/10. found at 1! covered neurons percentage 52 neurons 0.865, 148 neurons 0.777, 268 neurons 0.802 at 12/12\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.801\u001b[0m\n",
            "\u001b[94m   2/10. found at 2! covered neurons percentage 52 neurons 0.904, 148 neurons 0.804, 268 neurons 0.821 at 13/13\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.825\u001b[0m\n",
            "\u001b[94m   3/10. found at 1! covered neurons percentage 52 neurons 0.904, 148 neurons 0.811, 268 neurons 0.828 at 14/14\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.831\u001b[0m\n",
            "\u001b[94m   4/10. found at 1! covered neurons percentage 52 neurons 0.904, 148 neurons 0.811, 268 neurons 0.828 at 15/15\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.831\u001b[0m\n",
            "\u001b[94m   5/10. found at 2! covered neurons percentage 52 neurons 0.904, 148 neurons 0.811, 268 neurons 0.832 at 16/16\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.833\u001b[0m\n",
            "\u001b[94m   6/10. found at 2! covered neurons percentage 52 neurons 0.904, 148 neurons 0.811, 268 neurons 0.832 at 17/17\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.833\u001b[0m\n",
            "\u001b[94m   7/10. found at 0! covered neurons percentage 52 neurons 0.904, 148 neurons 0.811, 268 neurons 0.832 at 18/18\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.833\u001b[0m\n",
            "\u001b[94m   8/10. found at 0! covered neurons percentage 52 neurons 0.904, 148 neurons 0.831, 268 neurons 0.840 at 19/19\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.844\u001b[0m\n",
            "\u001b[94m   9/10. found at 2! covered neurons percentage 52 neurons 0.904, 148 neurons 0.838, 268 neurons 0.843 at 20/20\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.848\u001b[0m\n",
            "figure2\n",
            "   0/10. test suite was not found: averaged covered neurons 0.865 at 1/21\n",
            "\u001b[94m   1/10. found at 9! covered neurons percentage 52 neurons 0.904, 148 neurons 0.872, 268 neurons 0.862 at 21/22\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.870\u001b[0m\n",
            "\u001b[94m   2/10. found at 3! covered neurons percentage 52 neurons 0.904, 148 neurons 0.872, 268 neurons 0.862 at 22/23\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.870\u001b[0m\n",
            "\u001b[94m   3/10. found at 1! covered neurons percentage 52 neurons 0.904, 148 neurons 0.872, 268 neurons 0.873 at 23/24\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.876\u001b[0m\n",
            "\u001b[94m   4/10. found at 1! covered neurons percentage 52 neurons 0.904, 148 neurons 0.872, 268 neurons 0.873 at 24/25\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.876\u001b[0m\n",
            "\u001b[94m   5/10. found at 1! covered neurons percentage 52 neurons 0.904, 148 neurons 0.878, 268 neurons 0.873 at 25/26\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.878\u001b[0m\n",
            "\u001b[94m   6/10. found at 1! covered neurons percentage 52 neurons 0.904, 148 neurons 0.878, 268 neurons 0.877 at 26/27\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.880\u001b[0m\n",
            "   7/10. test suite was not found: averaged covered neurons 0.880 at 2/28\n",
            "\u001b[94m   8/10. found at 1! covered neurons percentage 52 neurons 0.904, 148 neurons 0.878, 268 neurons 0.877 at 27/29\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.880\u001b[0m\n",
            "\u001b[94m   9/10. found at 4! covered neurons percentage 52 neurons 0.904, 148 neurons 0.878, 268 neurons 0.888 at 28/30\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.887\u001b[0m\n",
            "figure3\n",
            "\u001b[94m   0/10. found at 1! covered neurons percentage 52 neurons 0.904, 148 neurons 0.885, 268 neurons 0.892 at 29/31\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.891\u001b[0m\n",
            "\u001b[94m   1/10. found at 0! covered neurons percentage 52 neurons 0.904, 148 neurons 0.885, 268 neurons 0.892 at 30/32\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.891\u001b[0m\n",
            "\u001b[94m   2/10. found at 3! covered neurons percentage 52 neurons 0.904, 148 neurons 0.885, 268 neurons 0.892 at 31/33\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.891\u001b[0m\n",
            "\u001b[94m   3/10. found at 0! covered neurons percentage 52 neurons 0.904, 148 neurons 0.892, 268 neurons 0.892 at 32/34\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.893\u001b[0m\n",
            "\u001b[94m   4/10. found at 4! covered neurons percentage 52 neurons 0.904, 148 neurons 0.892, 268 neurons 0.892 at 33/35\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.893\u001b[0m\n",
            "\u001b[94m   5/10. found at 7! covered neurons percentage 52 neurons 0.923, 148 neurons 0.899, 268 neurons 0.892 at 34/36\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.897\u001b[0m\n",
            "\u001b[94m   6/10. found at 4! covered neurons percentage 52 neurons 0.923, 148 neurons 0.899, 268 neurons 0.892 at 35/37\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.897\u001b[0m\n",
            "\u001b[94m   7/10. found at 0! covered neurons percentage 52 neurons 0.923, 148 neurons 0.899, 268 neurons 0.892 at 36/38\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.897\u001b[0m\n",
            "\u001b[94m   8/10. found at 0! covered neurons percentage 52 neurons 0.923, 148 neurons 0.899, 268 neurons 0.896 at 37/39\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.900\u001b[0m\n",
            "\u001b[94m   9/10. found at 0! covered neurons percentage 52 neurons 0.923, 148 neurons 0.899, 268 neurons 0.896 at 38/40\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.900\u001b[0m\n",
            "figure4\n",
            "   0/10. test suite was not found: averaged covered neurons 0.906 at 3/41\n",
            "\u001b[94m   1/10. found at 1! covered neurons percentage 52 neurons 0.923, 148 neurons 0.899, 268 neurons 0.910 at 39/42\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.908\u001b[0m\n",
            "\u001b[94m   2/10. found at 1! covered neurons percentage 52 neurons 0.923, 148 neurons 0.899, 268 neurons 0.910 at 40/43\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.908\u001b[0m\n",
            "\u001b[94m   3/10. found at 6! covered neurons percentage 52 neurons 0.923, 148 neurons 0.899, 268 neurons 0.910 at 41/44\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.908\u001b[0m\n",
            "   4/10. test suite was not found: averaged covered neurons 0.908 at 4/45\n",
            "\u001b[94m   5/10. found at 1! covered neurons percentage 52 neurons 0.923, 148 neurons 0.899, 268 neurons 0.910 at 42/46\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.908\u001b[0m\n",
            "\u001b[94m   6/10. found at 1! covered neurons percentage 52 neurons 0.923, 148 neurons 0.899, 268 neurons 0.910 at 43/47\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.908\u001b[0m\n",
            "\u001b[94m   7/10. found at 5! covered neurons percentage 52 neurons 0.923, 148 neurons 0.899, 268 neurons 0.910 at 44/48\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.908\u001b[0m\n",
            "   8/10. test suite was not found: averaged covered neurons 0.908 at 5/49\n",
            "   9/10. test suite was not found: averaged covered neurons 0.910 at 6/50\n",
            "figure5\n",
            "\u001b[94m   0/10. found at 0! covered neurons percentage 52 neurons 0.923, 148 neurons 0.899, 268 neurons 0.918 at 45/51\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.912\u001b[0m\n",
            "\u001b[94m   1/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.899, 268 neurons 0.918 at 46/52\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.915\u001b[0m\n",
            "\u001b[94m   2/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.899, 268 neurons 0.918 at 47/53\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.915\u001b[0m\n",
            "\u001b[94m   3/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.899, 268 neurons 0.918 at 48/54\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.915\u001b[0m\n",
            "\u001b[94m   4/10. found at 7! covered neurons percentage 52 neurons 0.942, 148 neurons 0.899, 268 neurons 0.918 at 49/55\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.915\u001b[0m\n",
            "\u001b[94m   5/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.899, 268 neurons 0.918 at 50/56\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.915\u001b[0m\n",
            "\u001b[94m   6/10. found at 4! covered neurons percentage 52 neurons 0.942, 148 neurons 0.899, 268 neurons 0.918 at 51/57\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.915\u001b[0m\n",
            "\u001b[94m   7/10. found at 2! covered neurons percentage 52 neurons 0.942, 148 neurons 0.899, 268 neurons 0.918 at 52/58\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.915\u001b[0m\n",
            "\u001b[94m   8/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.899, 268 neurons 0.918 at 53/59\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.915\u001b[0m\n",
            "\u001b[94m   9/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.899, 268 neurons 0.918 at 54/60\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.915\u001b[0m\n",
            "figure6\n",
            "\u001b[94m   0/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.905, 268 neurons 0.918 at 55/61\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.917\u001b[0m\n",
            "\u001b[94m   1/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.905, 268 neurons 0.918 at 56/62\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.917\u001b[0m\n",
            "\u001b[94m   2/10. found at 3! covered neurons percentage 52 neurons 0.942, 148 neurons 0.905, 268 neurons 0.918 at 57/63\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.917\u001b[0m\n",
            "\u001b[94m   3/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.905, 268 neurons 0.918 at 58/64\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.917\u001b[0m\n",
            "\u001b[94m   4/10. found at 7! covered neurons percentage 52 neurons 0.942, 148 neurons 0.912, 268 neurons 0.918 at 59/65\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "\u001b[94m   5/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.912, 268 neurons 0.918 at 60/66\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "\u001b[94m   6/10. found at 4! covered neurons percentage 52 neurons 0.942, 148 neurons 0.912, 268 neurons 0.918 at 61/67\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "\u001b[94m   7/10. found at 8! covered neurons percentage 52 neurons 0.942, 148 neurons 0.912, 268 neurons 0.918 at 62/68\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "\u001b[94m   8/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.912, 268 neurons 0.918 at 63/69\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "\u001b[94m   9/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.912, 268 neurons 0.918 at 64/70\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.919\u001b[0m\n",
            "figure7\n",
            "\u001b[94m   0/10. found at 3! covered neurons percentage 52 neurons 0.942, 148 neurons 0.919, 268 neurons 0.918 at 65/71\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.921\u001b[0m\n",
            "\u001b[94m   1/10. found at 4! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.918 at 66/72\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.923\u001b[0m\n",
            "\u001b[94m   2/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.918 at 67/73\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.923\u001b[0m\n",
            "\u001b[94m   3/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.918 at 68/74\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.923\u001b[0m\n",
            "\u001b[94m   4/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.918 at 69/75\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.923\u001b[0m\n",
            "\u001b[94m   5/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.918 at 70/76\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.923\u001b[0m\n",
            "   6/10. test suite was not found: averaged covered neurons 0.923 at 7/77\n",
            "\u001b[94m   7/10. found at 2! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 71/78\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m   8/10. found at 2! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 72/79\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m   9/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 73/80\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "figure8\n",
            "\u001b[94m   0/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 74/81\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m   1/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 75/82\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m   2/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 76/83\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m   3/10. found at 3! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 77/84\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m   4/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 78/85\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m   5/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 79/86\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m   6/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 80/87\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m   7/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 81/88\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m   8/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 82/89\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m   9/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 83/90\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "figure9\n",
            "\u001b[94m   0/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 84/91\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m   1/10. found at 3! covered neurons percentage 52 neurons 0.942, 148 neurons 0.926, 268 neurons 0.922 at 85/92\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.925\u001b[0m\n",
            "\u001b[94m   2/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.932, 268 neurons 0.925 at 86/93\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.929\u001b[0m\n",
            "\u001b[94m   3/10. found at 4! covered neurons percentage 52 neurons 0.942, 148 neurons 0.939, 268 neurons 0.925 at 87/94\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.932\u001b[0m\n",
            "\u001b[94m   4/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.939, 268 neurons 0.925 at 88/95\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.932\u001b[0m\n",
            "\u001b[94m   5/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.939, 268 neurons 0.925 at 89/96\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.932\u001b[0m\n",
            "\u001b[94m   6/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.939, 268 neurons 0.925 at 90/97\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.932\u001b[0m\n",
            "\u001b[94m   7/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.939, 268 neurons 0.925 at 91/98\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.932\u001b[0m\n",
            "\u001b[94m   8/10. found at 0! covered neurons percentage 52 neurons 0.942, 148 neurons 0.939, 268 neurons 0.925 at 92/99\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.932\u001b[0m\n",
            "\u001b[94m   9/10. found at 1! covered neurons percentage 52 neurons 0.942, 148 neurons 0.939, 268 neurons 0.925 at 93/100\u001b[0m\n",
            "\u001b[94m     averaged covered neurons 0.932\u001b[0m\n",
            "CPU times: user 8min 28s, sys: 2.87 s, total: 8min 31s\n",
            "Wall time: 8min 32s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80lvnBNfg8Z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###print(type(df1_scale.columns[0]), df1_scale.columns[0][0], df1_scale.columns[0][1])\n",
        "###\n",
        "###thresholds = np.linspace(0,0.4,2)\n",
        "###print(thresholds)\n",
        "###\n",
        "###for thres in thresholds:\n",
        "###  print(thres)\n",
        "###  for colm in df1_scale.columns:\n",
        "####    bools = df\n",
        "###    bools = df1_scale[colm] > thres\n",
        "###    print(thres, bools.sum())\n",
        "####  print(bools, bools.sum())\n",
        "####bools = df1_scale[df1_scale.columns[0]] > 0.1\n",
        "####print(bools, bools.sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QtyLAZiPeKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bools_sum_layer =  pd.DataFrame(columns=(\"layer\", \"count\", \"index\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B19EsPFQrak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thres = 0.4\n",
        "bools = df1_scale > thres\n",
        "\n",
        "for i, count in enumerate(bools.sum()):\n",
        "#    print(bools.sum().index[i][0], bools.sum().index[i][1], count)\n",
        "    cont = [bools.sum().index[i][0], count, bools.sum().index[i][1]]\n",
        "    cont = pd.Series(cont, index=bools_sum_layer.columns, name=str(i))\n",
        "    bools_sum_layer = bools_sum_layer.append(cont)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W4ySii4Txkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "42a12937-58ca-4a12-e281-8b1651385b93"
      },
      "source": [
        "#bools_sum_layer.columns\n",
        "bools.sum()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(block1_conv1, 0)       0\n",
              "(block1_conv1, 1)      33\n",
              "(block1_conv1, 2)       0\n",
              "(block1_conv1, 3)       0\n",
              "(block1_pool1, 0)      21\n",
              "(block1_pool1, 1)      34\n",
              "(block1_pool1, 2)       6\n",
              "(block1_pool1, 3)       0\n",
              "(block2_conv1, 0)       0\n",
              "(block2_conv1, 1)       0\n",
              "(block2_conv1, 2)       0\n",
              "(block2_conv1, 3)       0\n",
              "(block2_conv1, 4)       2\n",
              "(block2_conv1, 5)       0\n",
              "(block2_conv1, 6)       0\n",
              "(block2_conv1, 7)       0\n",
              "(block2_conv1, 8)       0\n",
              "(block2_conv1, 9)       8\n",
              "(block2_conv1, 10)      0\n",
              "(block2_conv1, 11)      0\n",
              "(block2_pool1, 0)       0\n",
              "(block2_pool1, 1)       0\n",
              "(block2_pool1, 2)       0\n",
              "(block2_pool1, 3)      24\n",
              "(block2_pool1, 4)      23\n",
              "(block2_pool1, 5)       0\n",
              "(block2_pool1, 6)       0\n",
              "(block2_pool1, 7)       0\n",
              "(block2_pool1, 8)       0\n",
              "(block2_pool1, 9)      31\n",
              "(block2_pool1, 10)      0\n",
              "(block2_pool1, 11)      0\n",
              "(before_softmax, 0)    13\n",
              "(before_softmax, 1)    77\n",
              "(before_softmax, 2)    93\n",
              "(before_softmax, 3)    89\n",
              "(before_softmax, 4)    69\n",
              "(before_softmax, 5)    67\n",
              "(before_softmax, 6)    38\n",
              "(before_softmax, 7)    58\n",
              "(before_softmax, 8)    76\n",
              "(before_softmax, 9)    42\n",
              "(predictions, 0)        0\n",
              "(predictions, 1)        5\n",
              "(predictions, 2)       56\n",
              "(predictions, 3)       11\n",
              "(predictions, 4)       12\n",
              "(predictions, 5)        2\n",
              "(predictions, 6)        5\n",
              "(predictions, 7)        0\n",
              "(predictions, 8)        7\n",
              "(predictions, 9)        2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqW-Pk3iQoSv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "3e4f880b-ef6a-4ae4-8726-fc8407f942e3"
      },
      "source": [
        "bools_sum_layer.head(15)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>layer</th>\n",
              "      <th>count</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>block1_conv1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>block1_conv1</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>block1_conv1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>block1_conv1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>block1_pool1</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>block1_pool1</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>block1_pool1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>block1_pool1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>block2_conv1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>block2_conv1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>block2_conv1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>block2_conv1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>block2_conv1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>block2_conv1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>block2_conv1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           layer count index\n",
              "0   block1_conv1     0     0\n",
              "1   block1_conv1    33     1\n",
              "2   block1_conv1     0     2\n",
              "3   block1_conv1     0     3\n",
              "4   block1_pool1    21     0\n",
              "5   block1_pool1    34     1\n",
              "6   block1_pool1     6     2\n",
              "7   block1_pool1     0     3\n",
              "8   block2_conv1     0     0\n",
              "9   block2_conv1     0     1\n",
              "10  block2_conv1     0     2\n",
              "11  block2_conv1     0     3\n",
              "12  block2_conv1     2     4\n",
              "13  block2_conv1     0     5\n",
              "14  block2_conv1     0     6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VhvynP7lHy5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "52bb7d2a-2e32-4681-f66f-30278024f3d2"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-d43a097a654c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mthres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mbools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1_scale\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'thresholds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNk4OB6Pqq7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "97b949aa-8438-4d61-c30c-a9e51c02917f"
      },
      "source": [
        "import pylab as pl\n",
        "\n",
        "thres = 0.1\n",
        "bools = df1_scale > thres\n",
        "bools.sum().hist()\n",
        "pl.xlabel(\"activation time\")\n",
        "pl.ylabel(\"number of neurons\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'number of neurons')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9i776jSEOTn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9ff0955e-b088-47bb-c0f1-2181cdd44e49"
      },
      "source": [
        "test = bools.sum()\n",
        "print(type(test))\n",
        "print(test[0])\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRhR6N3GEi9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "0cea8508-9afe-42a5-ff9e-56d25df2aaa5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(test.index[0],test.index[0][0])\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(12, 8))\n",
        "test.plot(kind=\"bar\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('block1_conv1', 0) block1_conv1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa3243eef98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsUAAAIqCAYAAADM2TdPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsg30FQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20OgY8wsUSOP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2655084a-e2c9-405a-c1dd-cfc4032c9198"
      },
      "source": [
        "temp, temp_scale = neuron_output(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "temp, temp_scale_mod = neuron_output(gen_img, model1, model_layer_dict1, args.threshold)\n",
        "#temp_scale\n",
        "temp_list = df1.columns\n",
        "temp_list_mod = df1.columns\n",
        "\n",
        "\n",
        "for i, layer in enumerate(temp_list):\n",
        "  #print(i, layer)\n",
        "  if layer[1] == 0:\n",
        "    print(i, layer)\n",
        "    if i > 0:\n",
        "      temp_list_mod.insert(i, (\"None\", 0))\n",
        "      temp_scale_mod.insert(i,0)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 ('block1_conv1', 0)\n",
            "4 ('block1_pool1', 0)\n",
            "8 ('block2_conv1', 0)\n",
            "20 ('block2_pool1', 0)\n",
            "32 ('before_softmax', 0)\n",
            "42 ('predictions', 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPTxxcKAYMQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "1c15918a-974e-4d86-f846-b1a2ee221d06"
      },
      "source": [
        "print(temp_list)\n",
        "print(temp_list_mod)\n",
        "print(temp_scale)\n",
        "print(temp_scale_mod)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index([  ('block1_conv1', 0),   ('block1_conv1', 1),   ('block1_conv1', 2),\n",
            "         ('block1_conv1', 3),   ('block1_pool1', 0),   ('block1_pool1', 1),\n",
            "         ('block1_pool1', 2),   ('block1_pool1', 3),   ('block2_conv1', 0),\n",
            "         ('block2_conv1', 1),   ('block2_conv1', 2),   ('block2_conv1', 3),\n",
            "         ('block2_conv1', 4),   ('block2_conv1', 5),   ('block2_conv1', 6),\n",
            "         ('block2_conv1', 7),   ('block2_conv1', 8),   ('block2_conv1', 9),\n",
            "        ('block2_conv1', 10),  ('block2_conv1', 11),   ('block2_pool1', 0),\n",
            "         ('block2_pool1', 1),   ('block2_pool1', 2),   ('block2_pool1', 3),\n",
            "         ('block2_pool1', 4),   ('block2_pool1', 5),   ('block2_pool1', 6),\n",
            "         ('block2_pool1', 7),   ('block2_pool1', 8),   ('block2_pool1', 9),\n",
            "        ('block2_pool1', 10),  ('block2_pool1', 11), ('before_softmax', 0),\n",
            "       ('before_softmax', 1), ('before_softmax', 2), ('before_softmax', 3),\n",
            "       ('before_softmax', 4), ('before_softmax', 5), ('before_softmax', 6),\n",
            "       ('before_softmax', 7), ('before_softmax', 8), ('before_softmax', 9),\n",
            "          ('predictions', 0),    ('predictions', 1),    ('predictions', 2),\n",
            "          ('predictions', 3),    ('predictions', 4),    ('predictions', 5),\n",
            "          ('predictions', 6),    ('predictions', 7),    ('predictions', 8),\n",
            "          ('predictions', 9)],\n",
            "      dtype='object')\n",
            "Index([  ('block1_conv1', 0),   ('block1_conv1', 1),   ('block1_conv1', 2),\n",
            "         ('block1_conv1', 3),   ('block1_pool1', 0),   ('block1_pool1', 1),\n",
            "         ('block1_pool1', 2),   ('block1_pool1', 3),   ('block2_conv1', 0),\n",
            "         ('block2_conv1', 1),   ('block2_conv1', 2),   ('block2_conv1', 3),\n",
            "         ('block2_conv1', 4),   ('block2_conv1', 5),   ('block2_conv1', 6),\n",
            "         ('block2_conv1', 7),   ('block2_conv1', 8),   ('block2_conv1', 9),\n",
            "        ('block2_conv1', 10),  ('block2_conv1', 11),   ('block2_pool1', 0),\n",
            "         ('block2_pool1', 1),   ('block2_pool1', 2),   ('block2_pool1', 3),\n",
            "         ('block2_pool1', 4),   ('block2_pool1', 5),   ('block2_pool1', 6),\n",
            "         ('block2_pool1', 7),   ('block2_pool1', 8),   ('block2_pool1', 9),\n",
            "        ('block2_pool1', 10),  ('block2_pool1', 11), ('before_softmax', 0),\n",
            "       ('before_softmax', 1), ('before_softmax', 2), ('before_softmax', 3),\n",
            "       ('before_softmax', 4), ('before_softmax', 5), ('before_softmax', 6),\n",
            "       ('before_softmax', 7), ('before_softmax', 8), ('before_softmax', 9),\n",
            "          ('predictions', 0),    ('predictions', 1),    ('predictions', 2),\n",
            "          ('predictions', 3),    ('predictions', 4),    ('predictions', 5),\n",
            "          ('predictions', 6),    ('predictions', 7),    ('predictions', 8),\n",
            "          ('predictions', 9)],\n",
            "      dtype='object')\n",
            "[0.0102703525, 0.3961128, 0.22291616, 0.12878035, 0.022121865, 0.43234745, 0.25660372, 0.16681033, 0.053691518, 0.076974295, 0.10533199, 0.23163013, 0.0014115529, 0.06623608, 0.122125044, 0.06357269, 0.21187082, 0.03133929, 0.07943694, 0.014548258, 0.11478055, 0.17382927, 0.23558465, 0.35600317, 0.0055308854, 0.10386828, 0.21879463, 0.12979332, 0.29564607, 0.059923135, 0.16457978, 0.043961562, 0.2066805, 0.04662384, 0.699718, 0.9877837, 0.5075219, 0.37357655, 0.35823685, 0.0, 1.0, 0.86871904, 0.0, 0.0, 0.0, 3.4633525e-15, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
            "[0.0102703525, 0.3961128, 0.22291616, 0.12878035, 0, 0.022121865, 0.43234745, 0.25660372, 0, 0.16681033, 0.053691518, 0.076974295, 0.10533199, 0.23163013, 0.0014115529, 0.06623608, 0.122125044, 0.06357269, 0.21187082, 0.03133929, 0, 0.07943694, 0.014548258, 0.11478055, 0.17382927, 0.23558465, 0.35600317, 0.0055308854, 0.10386828, 0.21879463, 0.12979332, 0.29564607, 0, 0.059923135, 0.16457978, 0.043961562, 0.2066805, 0.04662384, 0.699718, 0.9877837, 0.5075219, 0.37357655, 0, 0.35823685, 0.0, 1.0, 0.86871904, 0.0, 0.0, 0.0, 3.4633525e-15, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI6mbgm3HSFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHWoVLXLYLh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDPvC0JSHVpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs = test.index\n",
        "xs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKCZjT-uk3no",
        "colab_type": "text"
      },
      "source": [
        "for thres in thresholds:\n",
        "#  for colm in df1_scale.columns:\n",
        "#    bools = df\n",
        "bools = df1_scale[df1_scale.columns[0]] > thresholds\n",
        "print(thres)\n",
        "print(bools, bools.sum())\n",
        "#bools = df1_scale[df1_scale.columns[0]] > 0.1\n",
        "#print(bools, bools.sum())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmL8BC2QHVCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo-WxIcnOzEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "df1_scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLyQvSQN5bPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_per_x1 = np.average(temp_per_nc1, axis=1)\n",
        "data_per_x2 = np.average(temp_per_nc2, axis=1)\n",
        "data_per_x3 = np.average(temp_per_nc3, axis=1)\n",
        "std_per_x1 = np.std(temp_per_nc1, axis=1)\n",
        "std_per_x2 = np.std(temp_per_nc2, axis=1)\n",
        "std_per_x3 = np.std(temp_per_nc3, axis=1)\n",
        "\n",
        "print(data_per_x1, std_per_x1, std_per_x2, std_per_x3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIlpsRy3XY95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_num_x1 = np.average(temp_num_nc1, axis=1)\n",
        "data_num_x2 = np.average(temp_num_nc2, axis=1)\n",
        "data_num_x3 = np.average(temp_num_nc3, axis=1)\n",
        "std_num_x1 = np.std(temp_num_nc1, axis=1)\n",
        "std_num_x2 = np.std(temp_num_nc2, axis=1)\n",
        "std_num_x3 = np.std(temp_num_nc3, axis=1)\n",
        "\n",
        "print(data_num_x1, std_num_x1, std_num_x2, std_num_x3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc6vamXyXbEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "t = np.linspace(0, 10, 10)\n",
        "fig = plt.figure(figsize=(20,7),dpi=60)\n",
        "ax = fig.add_subplot(1,2,1)\n",
        "plt.errorbar(t, data_per_x1, yerr=std_per_x1, marker=\"o\", label=\"model1\")\n",
        "plt.errorbar(t, data_per_x2, yerr=std_per_x2, marker=\"s\", label=\"model2\")\n",
        "plt.errorbar(t, data_per_x3, yerr=std_per_x3, marker=\"^\", label=\"model3\")\n",
        "ax.legend(loc=0)\n",
        "plt.legend(fontsize=18)\n",
        "plt.title(\"neuron coverage\", fontsize=18)\n",
        "ax.set_xlabel('step', fontsize=18)\n",
        "ax.set_ylabel('neuron coverage', fontsize=18)\n",
        "plt.tick_params(labelsize=16)\n",
        "\n",
        "ax = fig.add_subplot(1,2,2)\n",
        "plt.errorbar(t, data_num_x1, yerr=std_num_x1, marker=\"o\", label=\"model1:\"+str(neuron_covered(model_layer_dict1)[1]))\n",
        "plt.errorbar(t, data_num_x2, yerr=std_num_x2, marker=\"s\", label=\"model2:\"+str(neuron_covered(model_layer_dict2)[1]))\n",
        "plt.errorbar(t, data_num_x3, yerr=std_num_x3, marker=\"^\", label=\"model3:\"+str(neuron_covered(model_layer_dict3)[1]))\n",
        "ax.legend(loc=0)\n",
        "plt.legend(fontsize=18)\n",
        "plt.title(\"neuron coverage\", fontsize=18)\n",
        "ax.set_xlabel('step', fontsize=18)\n",
        "ax.set_ylabel('# covered neuron ', fontsize=18)\n",
        "plt.tick_params(labelsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJXfVtcaXd-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}